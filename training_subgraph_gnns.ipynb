{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YfOMRdZQAccz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.utils import subgraph\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alQx48NCAcdA",
        "outputId": "bc0eb827-ff7a-4dde-86cb-7073814de851"
      },
      "outputs": [],
      "source": [
        "# reading from second order neighbors file to build subgraphs in a list called sub_data_list\n",
        "torch.manual_seed(1234567)\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "folder_path = 'second_order_client_neighbors'\n",
        "sub_data_list = []\n",
        "client_number = []\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.gml'):\n",
        "      \n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        g = nx.read_gml(file_path)\n",
        "\n",
        "        subgraph_nodes = list(g.nodes)\n",
        "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
        "\n",
        "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
        "        print(sub_edge_index.shape)\n",
        "\n",
        "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
        "        sub_data_list.append(sub_data)\n",
        "        client_number.append(int(filename.split('.')[0].split('_')[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UyWFwhBzAcdE"
      },
      "outputs": [],
      "source": [
        "# reading from second order test graph to build test graph called test_data\n",
        "test_data = None\n",
        "\n",
        "g = nx.read_gml('drive/MyDrive/federated_gnns_project/second_order_test_graph.gml')\n",
        "subgraph_nodes = list(g.nodes)\n",
        "subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
        "sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
        "test_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtLYIvJ4AcdH",
        "outputId": "a821f11b-809e-4c71-8d00-ba109915cf65"
      },
      "outputs": [],
      "source": [
        "# readingin in the facebook network to build a neighbors dictionary for each node\n",
        "g = nx.read_gml('drive/MyDrive/federated_gnns_project/new_facebook_network.gml')\n",
        "neighbors = {}\n",
        "\n",
        "for node in g.nodes:\n",
        "    neighbors[node] = list(g.neighbors(node))\n",
        "\n",
        "print(neighbors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SGFOCtr5AcdI"
      },
      "outputs": [],
      "source": [
        "# read new_facebook_network.gml and create a fully connected graph\n",
        "\n",
        "neighbors_fully_connected = {}\n",
        "for node in g.nodes:\n",
        "    neighbors_fully_connected[node] = list(g.nodes)\n",
        "    neighbors_fully_connected[node].remove(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbB11oc-AcdJ",
        "outputId": "3e6b86f0-9313-435d-bc55-833081a8ab4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[59, 1433], edge_index=[2, 160], y=[59])\n",
            "torch.Size([59, 1433])\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(sub_data_list[0])\n",
        "print(sub_data_list[0].x.shape)\n",
        "print(type(client_number))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iJ77wSQ7AcdL"
      },
      "outputs": [],
      "source": [
        "#keep a list of training and validation loss per epoch for each subgraph\n",
        "train_losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6G6PWvkAcdQ"
      },
      "source": [
        "# Model Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D8sQXMCqAcdU"
      },
      "outputs": [],
      "source": [
        "# GCN model\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(num_features, 32)\n",
        "        self.conv2 = GCNConv(32, num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training) # p = 0.25\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ao21m0ESAcdZ"
      },
      "outputs": [],
      "source": [
        "#GAT model\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(num_features, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATConv(8 * 8, num_classes, heads=1, concat=False, dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJxzvEtpAcda"
      },
      "source": [
        "# Train, Test, Validation, and Intial Training Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aGKiQy5fAcda"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(sub_data, model, optimizer, criterion):\n",
        "      #put data on device\n",
        "      sub_data = sub_data.to(device)\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
        "      loss = criterion(out, sub_data.y)  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def train_batch(sub_data_loader, model, optimizer, criterion):\n",
        "    for i, data in enumerate(sub_data_loader):\n",
        "        x, edge_index, y, idx = data\n",
        "        nodes = list(idx)\n",
        "        sub_edge_index, _ = subgraph(nodes, edge_index[0], relabel_nodes=True)\n",
        "        x = x.to(device)\n",
        "        edge_index = edge_index.to(device)\n",
        "        y = y.to(device)\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x, sub_edge_index)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward(sub_edge_index)\n",
        "        optimizer.step()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def test(test_data, criterion, model):\n",
        "      test_data = test_data.to(device)\n",
        "      model.eval()\n",
        "      out = model(test_data.x, test_data.edge_index)\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred == test_data.y # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / len(test_data.y)  # Derive ratio of correct predictions.\n",
        "      test_loss = criterion(out, test_data.y)  # Compute validation loss\n",
        "\n",
        "      return test_loss, test_acc\n",
        "\n",
        "\n",
        "def validate(test_data, model, criterion):\n",
        "    test_data = test_data.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Do not compute gradients during this step\n",
        "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
        "        pred = out.argmax(dim=1)  # Get predicted classes\n",
        "        val_correct = pred == test_data.y # Compare with ground-truth\n",
        "        val_loss = criterion(out, test_data.y)  # Compute validation loss\n",
        "        val_acc = int(val_correct.sum()) / int(len(test_data.y))  # Compute validation accuracy\n",
        "    return val_loss.item(), val_acc  # Return validation loss and accuracy\n",
        "\n",
        "# initial training doesn't account for communication\n",
        "def initial_training(epochs, learning_rate):\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    dictionary_t_1 = {}\n",
        "    dictionary_t = {}\n",
        "\n",
        "    for i in range(len(sub_data_list)):\n",
        "        sub_data = sub_data_list[i]\n",
        "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        # Training loop for each epoch (adjust the range as needed)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
        "            val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "        test_loss, test_acc = test(test_data, criterion, model)\n",
        "        test_losses.append(test_loss.item())\n",
        "        test_accs.append(test_acc)\n",
        "        row = i // 10\n",
        "        col = i % 10\n",
        "\n",
        "        model_weights = model.state_dict()\n",
        "        client_number_num = client_number[i]\n",
        "        dictionary_t_1[client_number_num] = model_weights\n",
        "\n",
        "    return dictionary_t_1, test_losses, test_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrgYUGQxAcdc"
      },
      "source": [
        "## Aggregation Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FwM-941VAcdc"
      },
      "outputs": [],
      "source": [
        "def fed_avg(models):\n",
        "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
        "    for k in global_model.keys():\n",
        "        global_model[k] = torch.stack([model[k].float() for model in models], 0).mean(0)\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1M9xrwXIAcdd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def weighted_fed_avg(models, accuracies):\n",
        "    #model and accuracies are dictionaries\n",
        "    accuracies = np.exp(accuracies)\n",
        "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
        "    for k in global_model.keys():\n",
        "        weighted_sum = 0\n",
        "        for i in range(len(models)):\n",
        "            weighted_sum += accuracies[i] * models[i][k].float()\n",
        "        global_model[k] = weighted_sum / sum(accuracies)\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LSdz44VIAcdd"
      },
      "outputs": [],
      "source": [
        "#rank based weighted average\n",
        "\n",
        "def rank_based_weighted_avg(models, accuracies):\n",
        "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
        "    accuracies = np.array(accuracies)\n",
        "    sorted_indices = np.argsort(accuracies)\n",
        "    for k in global_model.keys():\n",
        "        weighted_sum = 0\n",
        "        for i in range(len(models)):\n",
        "            weighted_sum += (len(models) - np.where(sorted_indices == i)[0][0]) * models[i][k].float()\n",
        "        global_model[k] = weighted_sum / sum(range(1, len(models) + 1))\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Hi2ovsgpcvaF"
      },
      "outputs": [],
      "source": [
        "def exponential_weighted_fed_avg(models, accuracies):\n",
        "    accuracies = np.exp(accuracies) / np.sum(np.exp(accuracies))\n",
        "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
        "    for k in global_model.keys():\n",
        "        weighted_sum = 0\n",
        "        for i in range(len(models)):\n",
        "            weighted_sum += accuracies[i] * models[i][k].float()\n",
        "        global_model[k] = weighted_sum / sum(accuracies)\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cE9sYKcmcxQ2"
      },
      "outputs": [],
      "source": [
        "def normalized_fed_avg(models, accuracies):\n",
        "    global_model = copy.deepcopy(models[0])\n",
        "    normalized_accuracies = [float(i)/sum(accuracies) for i in accuracies]\n",
        "    for k in global_model.keys():\n",
        "        weighted_sum = 0\n",
        "        for i in range(len(models)):\n",
        "            weighted_sum += normalized_accuracies[i] * models[i][k].float()\n",
        "        global_model[k] = weighted_sum\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7lTq-VvpAcde"
      },
      "outputs": [],
      "source": [
        "#threshold based weighted average\n",
        "\n",
        "def threshold_based_weighted_avg(models, accuracies, threshold):\n",
        "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
        "    accuracies_copy = copy.deepcopy(accuracies)\n",
        "    accuracies = np.array(accuracies)\n",
        "    accuracies[accuracies < threshold] = 0\n",
        "    #if all accuracies are below threshold, set threshold to current client's accuracy, which is first\n",
        "    if np.sum(accuracies) == 0:\n",
        "        threshold = accuracies_copy[0]\n",
        "        accuracies_copy = np.array(accuracies_copy)\n",
        "        accuracies_copy[accuracies_copy < threshold] = 0\n",
        "        accuracies = accuracies_copy\n",
        "    for k in global_model.keys():\n",
        "        weighted_sum = 0\n",
        "        for i in range(len(models)):\n",
        "            weighted_sum += accuracies[i] * models[i][k].float()\n",
        "        global_model[k] = weighted_sum / sum(accuracies)\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "spjtKs-FAcde"
      },
      "outputs": [],
      "source": [
        "def greedy_averaging(models, accuracies):\n",
        "    #sort models by accuracy in descending order\n",
        "    accuracies = np.array(accuracies)\n",
        "    sorted_indices = np.argsort(accuracies)[::-1]\n",
        "    sorted_models = []\n",
        "    for i in range(len(models)):\n",
        "        sorted_models.append(models[sorted_indices[i]])\n",
        "    #start with the first model\n",
        "    global_model = copy.deepcopy(sorted_models[0])\n",
        "    #load weights into model\n",
        "    model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    model.load_state_dict(global_model)\n",
        "    test_accuracy = test(test_data, criterion, model)[1]\n",
        "    #now, average with the next model, if accuracy improves, keep it, otherwise, discard it\n",
        "    for i in range(1, len(models)):\n",
        "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        new_weights = global_model.copy()\n",
        "        for k in global_model.keys():\n",
        "            new_weights[k] = (global_model[k] + sorted_models[i][k]) / 2\n",
        "        model.load_state_dict(sorted_models[i])\n",
        "        new_test_accuracy = test(test_data, criterion, model)[1]\n",
        "        if new_test_accuracy > test_accuracy:\n",
        "            global_model = new_weights\n",
        "            test_accuracy = new_test_accuracy\n",
        "\n",
        "    return global_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvbEiCbAcdf"
      },
      "source": [
        "## Communication Mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydLYBWwcAcdf"
      },
      "source": [
        "Broadcast Communication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "t1PexjltAcdf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate):\n",
        "    # make a copy of dictionary_t_1\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
        "    dictionary_t = {}\n",
        "    t_1_accuracies = {}\n",
        "    for k in range(1, rounds + 1):\n",
        "\n",
        "    # get the neighbprs of each client\n",
        "        for i in range(len(sub_data_list)):\n",
        "            sub_data = sub_data_list[i]\n",
        "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "\n",
        "            # Training loop for each epoch (adjust the range as needed)\n",
        "            for epoch in range(1, epochs + 1):\n",
        "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
        "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            test_loss, test_acc = test(test_data, criterion, model)\n",
        "            if k == rounds:\n",
        "                test_losses.append(test_loss.item())\n",
        "                test_accs.append(test_acc)\n",
        "\n",
        "            # add the model weights to the t -1 dictionary\n",
        "            model_weights = model.state_dict()\n",
        "            client_number_num = client_number[i]\n",
        "            dictionary_t_1[client_number_num] = model_weights\n",
        "            t_1_accuracies[client_number_num] = test_acc\n",
        "\n",
        "        for i in range(100):\n",
        "            client_number_num = client_number[i]\n",
        "            # go through neighbors of client_number\n",
        "            string_client_num = str(client_number_num)\n",
        "            client_neighbors = neighbors[string_client_num]\n",
        "            neighbors_state_dicts = []\n",
        "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
        "            accuracies = []\n",
        "            accuracies.append(t_1_accuracies[client_number_num])\n",
        "            for j in range(len(client_neighbors)):\n",
        "                # get model weights of neighbor\n",
        "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
        "                neighbors_state_dicts.append(neighbor_model)\n",
        "                accuracies.append(t_1_accuracies[int(client_neighbors[j])])\n",
        "\n",
        "            #call fed_avg\n",
        "            average_state_dict = {}\n",
        "            average_state_dict = greedy_averaging(neighbors_state_dicts, accuracies)\n",
        "            dictionary_t[client_number_num] = average_state_dict\n",
        "\n",
        "        dictionary_t_1 = dictionary_t\n",
        "\n",
        "    return test_losses, test_accs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RQGCiV4NAcdg"
      },
      "outputs": [],
      "source": [
        "def gossip_communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate):\n",
        "    # make a copy of dictionary_t_1\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
        "    dictionary_t = {}\n",
        "    t_1_accuracies = {}\n",
        "    for k in range(1, rounds + 1):\n",
        "\n",
        "    # get the neighbprs of each client\n",
        "        for i in range(len(sub_data_list)):\n",
        "            sub_data = sub_data_list[i]\n",
        "\n",
        "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "\n",
        "            # Training loop for each epoch (adjust the range as needed)\n",
        "            for epoch in range(1, epochs + 1):\n",
        "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
        "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            test_loss, test_acc = test(test_data, criterion, model)\n",
        "            if k == rounds:\n",
        "                test_losses.append(test_loss.item())\n",
        "                test_accs.append(test_acc)\n",
        "\n",
        "            # add the model weights to the t -1 dictionary\n",
        "            model_weights = model.state_dict()\n",
        "            client_number_num = client_number[i]\n",
        "            dictionary_t_1[client_number_num] = model_weights\n",
        "            t_1_accuracies[client_number_num] = test_acc\n",
        "\n",
        "        for i in range(100):\n",
        "            #each client sends its weights to a random neighbor, and that neighbor averages its weights with the received weights\n",
        "            client_number_num = client_number[i]\n",
        "            string_client_num = str(client_number_num)\n",
        "            client_neighbors = neighbors[string_client_num]\n",
        "\n",
        "            #pick a random neighbor\n",
        "            random_neighbor = np.random.choice(client_neighbors)\n",
        "            random_neighbor = int(random_neighbor)\n",
        "            random_neighbor_state_dict_prev = dictionary_t_1[random_neighbor]\n",
        "            average_state_dict = {}\n",
        "            average_state_dict = fed_avg([dictionary_t_1[client_number_num], random_neighbor_state_dict_prev])\n",
        "            models = [dictionary_t_1[client_number_num], random_neighbor_state_dict_prev]\n",
        "            t_1_accuracies_list = [t_1_accuracies[client_number_num], t_1_accuracies[random_neighbor]]\n",
        "            average_state_dict = fed_avg(models)\n",
        "            dictionary_t_1[client_number_num] = average_state_dict\n",
        "            dictionary_t[client_number_num] = average_state_dict\n",
        "\n",
        "        dictionary_t_1 = dictionary_t\n",
        "\n",
        "    return test_losses, test_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U9w7fc5Acdh"
      },
      "source": [
        "# Fully Connected Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytTtO4lqAcdh"
      },
      "source": [
        "## 1 epoch, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9UKVDGEAcdh",
        "outputId": "45c5c839-2725-407e-cc1b-67b5c47858c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  1.950941253900528\n",
            "mean test accuracy before communication:  0.15015974440894567\n",
            "mean test loss after communication:  2.0524680721759796\n",
            "mean test accuracy after communication:  0.1924281150159743\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 1, 100)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5AiagtEAcdi"
      },
      "source": [
        "## 5 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfB7l7dLAcdi",
        "outputId": "f18862e9-5a9e-4410-c5d7-d16783328d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.114197174310684\n",
            "mean test accuracy before communication:  0.15220447284345034\n",
            "mean test loss after communication:  2.6148978340625764\n",
            "mean test accuracy after communication:  0.25000000000000006\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 5, 100)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33dsYcSPAcdj"
      },
      "source": [
        "## 10 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMrRhAiJAcdj",
        "outputId": "7dc71d99-6a66-45b2-80d7-7cff6dcc0957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.7938966619968415\n",
            "mean test accuracy before communication:  0.15690095846645355\n",
            "mean test loss after communication:  2.931734937429428\n",
            "mean test accuracy after communication:  0.29412140575079876\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 10, 100)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1QD0VDmAcdk"
      },
      "source": [
        "# Our Social Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyOBqMXAAcdk"
      },
      "source": [
        "## 1 epoch, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2dOtAMdAcdl",
        "outputId": "ae386205-315a-4bd2-8797-b569b32adbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  1.9492018187046052\n",
            "mean test accuracy before communication:  0.15316293929712457\n",
            "mean test loss after communication:  1.930002419948578\n",
            "mean test accuracy after communication:  0.19610223642172536\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyQbShS2Acdl"
      },
      "source": [
        "## 5 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgtQRPNJQKnu"
      },
      "source": [
        "### Broadcast Communication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-8L6XrtQeQY",
        "outputId": "b3351d6c-e2ef-4b52-bbc6-72631f70442c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.407359801530838\n",
            "mean test accuracy before communication:  0.15399361022364202\n",
            "mean test loss after communication:  2.557976485490799\n",
            "mean test accuracy after communication:  0.32514376996805117\n"
          ]
        }
      ],
      "source": [
        "#Using fedAvg technique \n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGBbBtBsREeG",
        "outputId": "2bbde68b-274a-4ff7-c677-baaa527e6908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.3787487030029295\n",
            "mean test accuracy before communication:  0.15389776357827464\n",
            "mean test loss after communication:  2.421589039564133\n",
            "mean test accuracy after communication:  0.3638977635782748\n"
          ]
        }
      ],
      "source": [
        "#Using weighted fedAvg\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3MjnHcAcdm",
        "outputId": "3a9a8046-b377-451d-c7ac-3331ec79332e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.408725882768631\n",
            "mean test accuracy before communication:  0.15600638977635767\n",
            "mean test loss after communication:  2.1719933092594146\n",
            "mean test accuracy after communication:  0.4841214057507986\n"
          ]
        }
      ],
      "source": [
        "#Using threshold Based Avg\n",
        "#Setting threshold to current client's most recent accuracy\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMak5g7XAcd1",
        "outputId": "780b8705-0e58-47b2-f090-4450562f9f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.411843087673187\n",
            "mean test accuracy before communication:  0.15476038338658138\n",
            "mean test loss after communication:  1.9223486149311066\n",
            "mean test accuracy after communication:  0.4947603833865817\n"
          ]
        }
      ],
      "source": [
        "#Setting threshold to current client's most recent accuracy + 0.05\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbdF5zpFAcd5",
        "outputId": "d179aa19-e930-427f-d936-e422022c954d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.398931953907013\n",
            "mean test accuracy before communication:  0.15402555910543117\n",
            "mean test loss after communication:  2.1533005011081694\n",
            "mean test accuracy after communication:  0.4891693290734826\n"
          ]
        }
      ],
      "source": [
        "#Greedy Averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hSSb4zKQF58"
      },
      "source": [
        "### Gossip Communication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlVmEx9BiteY",
        "outputId": "2b067ebd-08e2-4e25-cf67-b7eba6868255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test accuracy after communication:  0.3056230031948883\n",
            "mean test loss after communication:  2.9699373984336854\n"
          ]
        }
      ],
      "source": [
        "# gossip and exponential averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "test_losses, test_accs = gossip_communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q1cL9QblQ1w",
        "outputId": "f4868396-9c20-4f45-c22b-7b9196b3d9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test accuracy after communication:  0.3449840255591053\n",
            "mean test loss after communication:  2.6528512930870054\n"
          ]
        }
      ],
      "source": [
        "# gossip and normalized averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "test_losses, test_accs = gossip_communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZYokN0ejjQK"
      },
      "outputs": [],
      "source": [
        "# gossip and federated averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "test_losses, test_accs = gossip_communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRvMkyg0Acd5"
      },
      "source": [
        "## 10 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHXbhv9BAcd6",
        "outputId": "d26b11f4-8333-4f59-da08-4e251a964c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  3.3138426327705384\n",
            "mean test accuracy before communication:  0.16789137380191682\n",
            "mean test loss after communication:  2.671199848651886\n",
            "mean test accuracy after communication:  0.4253354632587859\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(10, 0.01)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN1CSPvqAcd7"
      },
      "source": [
        "## 20 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "544btYt6Acd7",
        "outputId": "92bcdc87-37d7-47c2-f1d4-7aae9a19bbcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  3.4152511596679687\n",
            "mean test accuracy before communication:  0.1779233226837061\n",
            "mean test loss after communication:  3.4955796611309053\n",
            "mean test accuracy after communication:  0.2935463258785943\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(20)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 20, 100)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf7TOBfQAcd8"
      },
      "source": [
        "## 1 epochs, 10 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8Hp_N4vAcd8",
        "outputId": "018c65f4-7310-48d8-eb26-e096cf21ed8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  1.9489406883716582\n",
            "mean test accuracy before communication:  0.1485623003194888\n",
            "mean test loss after communication:  1.9430880868434905\n",
            "mean test accuracy after communication:  0.1542811501597442\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 10)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGKRP_wMAcd9"
      },
      "source": [
        "## 5 epochs, 10 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0x1pql7Acd9",
        "outputId": "f0b76c45-2f0c-461f-81d3-197bd6fff81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.146751263141632\n",
            "mean test accuracy before communication:  0.1514057507987219\n",
            "mean test loss after communication:  2.396341060400009\n",
            "mean test accuracy after communication:  0.15214057507987205\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 10)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWQYr_n7Acd-"
      },
      "source": [
        "## 10 epochs, 10 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhfzRtKFAcd-",
        "outputId": "35f9181e-1eba-430c-b7f9-216b533fe0bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test loss before communication:  2.69692032456398\n",
            "mean test accuracy before communication:  0.1590095846645366\n",
            "mean test loss after communication:  3.162060570716858\n",
            "mean test accuracy after communication:  0.17827476038338652\n"
          ]
        }
      ],
      "source": [
        "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
        "# print average test loss and average test accs\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss before communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
        "\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCUErv_nAcd_"
      },
      "source": [
        "## Fully Connected Graph Results\n",
        "### (Training with original subgraphs)\n",
        "\n",
        "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
        "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
        "| 1      | 100                  | 15.07%                     | 14.29%                    | 1.947                  | 2.083                 |\n",
        "| 5      | 100                  | 14.89%                     | 15.49%                    | 2.021                  | 2.943                 |\n",
        "| 10     | 100                  | 14.73%                     | 14.90%                    | 2.387                  | 5.010                 |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9LCiNytAceA"
      },
      "source": [
        "## Social Network Graph Results\n",
        "### (Training with original subgraphs)\n",
        "\n",
        "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
        "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
        "| 1      | 100                  | 15.13%                     | 14.31%                    | 1.947                  | 1.996                 |\n",
        "| 1      | 10                   | 15.40%                     | 15.12%                    | 1.946                  | 1.945                 |\n",
        "| 5      | 100                  | 14.38%                     | 16.16%                    | 2.028                  | 2.730                 |\n",
        "| 5      | 10                   | 14.52%                     | 14.49%                    | 2.014                  | 2.282                 |\n",
        "| 10     | 100                  | 14.74%                     | 16.07%                    | 2.321                  | 4.402                 |\n",
        "| 10     | 10                   | 14.69%                     | 15.01%                    | 2.349                  | 3.084                 |\n",
        "| 20     | 100                  | 15.39%                     | 18.50%                    | 3.101                  | 4.654                 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIPky_8UAceA"
      },
      "source": [
        "## Fully Connected Graph Results\n",
        "### (Training with second order subgraphs)\n",
        "\n",
        "\n",
        "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
        "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
        "| 1      | 100                  | 15.02%                     | 19.24%                    | 1.951                  | 2.052                 |\n",
        "| 5      | 100                  | 15.22%                     | 31.80%                    | 2.114                 | 2.614                |\n",
        "| 10     | 100                  | 15.69%                     | 29.41%                    | 2.794                 | 2.932              |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA-0xjYPAceB"
      },
      "source": [
        "## Social Network Graphs Results\n",
        "### (Training with second order subgraphs)\n",
        "\n",
        "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
        "|--------|----------------------|----------------------------|---------------------------|-----------------------|-----------------------|\n",
        "| 1      | 100                  | 0.1532                     | 0.1961                    | 1.9492                | 1.9300                |\n",
        "| 5      | 100                  | 0.1523                     | 0.3180                    | 2.1628                | 2.2851                |\n",
        "| 10     | 100                  | 0.1593                     | 0.3135                    | 2.7872                | 2.9388                |\n",
        "| 20     | 100                  | 0.1779                     | 0.2935                    | 3.4153                | 3.4956                |\n",
        "| 1      | 10                   | 0.1486                     | 0.1543                    | 1.9489                | 1.9431                |\n",
        "| 5      | 10                   | 0.1514                     | 0.1521                    | 2.1468                | 2.3963                |\n",
        "| 10     | 10                   | 0.1590                     | 0.1783                    | 2.6969                | 3.1621                |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_qjt3S9AceB"
      },
      "source": [
        "# Centralized Training on Entire Cora Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSq4W82dAceC"
      },
      "outputs": [],
      "source": [
        "# need a dataset class to use the dataloader to set batch size\n",
        "\n",
        "class GraphDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, graph_data):\n",
        "        self.graph_data = graph_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph_data.x[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        print(idx)\n",
        "        x = self.graph_data.x[idx,:]\n",
        "        y = self.graph_data.y[idx]\n",
        "        edge_index = self.graph_data.edge_index\n",
        "        return x, edge_index, y, idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bdAc_4hAceC"
      },
      "outputs": [],
      "source": [
        "# training set up for training the centralized model on the entire cora dataset\n",
        "\n",
        "from torchcontrib.optim import SWA\n",
        "import os\n",
        "import networkx as nx\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "cora_graph_training = nx.read_gml('cora_graph_training.gml')\n",
        "test_graph = test_data\n",
        "\n",
        "graph_nodes = list(cora_graph_training.nodes)\n",
        "graph_nodes = [int(node) for node in graph_nodes]  # Convert to integer if they are not\n",
        "\n",
        "graph_edge_index, _ = subgraph(graph_nodes, data.edge_index, relabel_nodes=True)\n",
        "graph_data = Data(x=data.x[graph_nodes], edge_index=graph_edge_index, y=data.y[graph_nodes])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_test(graph_data, epochs, dataset, test_data, device):\n",
        "    model  = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
        "    base_opt = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-4)\n",
        "    optimizer = SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.05)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    epochs = 10\n",
        "    # Training loop for each epoch (adjust the range as needed)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(graph_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
        "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "\n",
        "    optimizer.swap_swa_sgd()\n",
        "    test_loss, test_acc = test(test_data, criterion, model)\n",
        "    print(\"Centralized learning test accuracy: \", test_acc)\n",
        "\n",
        "train_test(graph_data, 10, dataset, test_data, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gi0nZ1xAceD"
      },
      "source": [
        "## Centralized Learning with Different Batch Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1dcOH68AceD"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "def train_test_batches(graph_data, epochs, dataset, test_data, device, batch_size):\n",
        "    model = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    epochs = 10\n",
        "    # Training loop for each epoch (adjust the range as needed)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_batches(graph_data, model, optimizer, criterion, batch_size)  # Assuming 'train' returns a loss\n",
        "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "\n",
        "    test_loss, test_acc = test(test_data, criterion, model)\n",
        "    print(\"Batch size: \", batch_size)\n",
        "    print(\"Centralized learning test accuracy: \", test_acc)\n",
        "\n",
        "def train_batches(graph_data, model, optimizer, criterion, batch_size):\n",
        "    graph_dataset = GraphDataset(graph_data)\n",
        "    graph_data_loader = DataLoader(graph_dataset, batch_size=batch_size, shuffle=True)\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for i, data in enumerate(graph_data_loader):\n",
        "      x, edge_index, y, idx = data\n",
        "      nodes = list(idx)\n",
        "      sub_edge_index, _ = subgraph(nodes, edge_index[0], relabel_nodes=True)\n",
        "      optimizer.zero_grad()\n",
        "      out = model(x, sub_edge_index)\n",
        "      loss = criterion(out, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss/(i+1)\n",
        "\n",
        "print()\n",
        "batch_sizes = [10, 16, 32]\n",
        "for batch_size in batch_sizes:\n",
        "    train_test_batches(graph_data, 10, dataset, test_data, device, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9DTFBuuAceE"
      },
      "source": [
        "# Testing our Social Network\n",
        "\n",
        "### Adam Optimizer, changing learning rates\n",
        "### 1 epoch, 100 communication rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx2Iljf7AceE",
        "outputId": "9fd3acc7-df84-4eac-ebd3-3217fc9ad874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning rate:  0.1\n",
            "mean test accuracy after communication:  0.14613418530351427\n",
            "mean test loss after communication:  4.274308376312256\n",
            "\n",
            "learning rate:  0.01\n",
            "mean test accuracy after communication:  0.1946964856230031\n",
            "mean test loss after communication:  1.9461461317539215\n",
            "\n",
            "learning rate:  0.001\n",
            "mean test accuracy after communication:  0.1764536741214057\n",
            "mean test loss after communication:  1.944579039812088\n",
            "\n",
            "learning rate:  0.0001\n",
            "mean test accuracy after communication:  0.16022364217252363\n",
            "mean test loss after communication:  1.9454831516742705\n",
            "\n",
            "learning rate:  1e-05\n",
            "mean test accuracy after communication:  0.11699680511182108\n",
            "mean test loss after communication:  1.9458110272884368\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(1, learning_rate)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100, learning_rate)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"learning rate: \", learning_rate)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZV_1kvwAceF"
      },
      "source": [
        "### 5 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUluJL37AceF",
        "outputId": "14bc4d3a-f7da-4c8d-d6e9-17bf0c814c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning rate:  0.01\n",
            "mean test accuracy after communication:  0.2996166134185303\n",
            "mean test loss after communication:  2.341976307630539\n",
            "\n",
            "learning rate:  0.001\n",
            "mean test accuracy after communication:  0.21172523961661324\n",
            "mean test loss after communication:  1.9647659862041473\n",
            "\n",
            "learning rate:  0.0001\n",
            "mean test accuracy after communication:  0.24108626198083066\n",
            "mean test loss after communication:  1.9449313080310822\n",
            "\n",
            "learning rate:  1e-05\n",
            "mean test accuracy after communication:  0.22539936102236421\n",
            "mean test loss after communication:  1.94551837682724\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(5, learning_rate)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, learning_rate)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"learning rate: \", learning_rate)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses) # print(f\"{mean_test_losses:.4f},{}\\n\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0e0CRxaAceF"
      },
      "source": [
        "### 10 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOrzlboxAceG",
        "outputId": "355c7ebe-6d11-4926-b29e-5650d6bda21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning rate:  0.01\n",
            "mean test accuracy after communication:  0.30837060702875396\n",
            "mean test loss after communication:  2.900534151792526\n",
            "\n",
            "learning rate:  0.001\n",
            "mean test accuracy after communication:  0.23664536741214054\n",
            "mean test loss after communication:  1.9392705142498017\n",
            "\n",
            "learning rate:  0.0001\n",
            "mean test accuracy after communication:  0.20805111821086253\n",
            "mean test loss after communication:  1.9413844859600067\n",
            "\n",
            "learning rate:  1e-05\n",
            "mean test accuracy after communication:  0.20466453674121404\n",
            "mean test loss after communication:  1.945243377685547\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for learning_rate in learning_rates:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(10, learning_rate)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100, learning_rate)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"learning rate: \", learning_rate)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHQonltGAceG",
        "outputId": "bad00b9e-0e88-4b67-f2f6-019770fb0855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min nodes:  21\n"
          ]
        }
      ],
      "source": [
        "min_nodes = 1000000\n",
        "for subgraph in sub_data_list:\n",
        "    if subgraph.num_nodes < min_nodes:\n",
        "        min_nodes = subgraph.num_nodes\n",
        "print(\"min nodes: \", min_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix0OvoLNAceH"
      },
      "outputs": [],
      "source": [
        "# redefining initial training method and communication method to include batch size as a parameter\n",
        "def initial_training(epochs, learning_rate, batch_size):\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    dictionary_t_1 = {}\n",
        "    dictionary_t = {}\n",
        "\n",
        "    for i in range(len(sub_data_list)):\n",
        "        sub_data = sub_data_list[i]\n",
        "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        # Training loop for each epoch (adjust the range as needed)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train_loss = train_batches(sub_data, model, optimizer, criterion, batch_size)  # Assuming 'train' returns a loss\n",
        "            val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "        test_loss, test_acc = test(test_data, criterion, model)\n",
        "        test_losses.append(test_loss.item())\n",
        "        test_accs.append(test_acc)\n",
        "        row = i // 10\n",
        "        col = i % 10\n",
        "\n",
        "        model_weights = model.state_dict()\n",
        "        client_number_num = client_number[i]\n",
        "        dictionary_t_1[client_number_num] = model_weights\n",
        "    return dictionary_t_1, test_losses, test_accs\n",
        "\n",
        "def communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate, batch_size):\n",
        "    # make a copy of dictionary_t_1\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "\n",
        "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
        "    dictionary_t = {}\n",
        "    for k in range(1, rounds + 1):\n",
        "\n",
        "    # get the neighbprs of each client\n",
        "        for i in range(len(sub_data_list)):\n",
        "            sub_data = sub_data_list[i]\n",
        "\n",
        "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "\n",
        "            # Training loop for each epoch (adjust the range as needed)\n",
        "            for epoch in range(1, epochs + 1):\n",
        "                train_loss = train_batches(sub_data, model, optimizer, criterion, batch_size)  # Assuming 'train' returns a loss\n",
        "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "            test_loss, test_acc = test(test_data, criterion, model)\n",
        "            if k == rounds:\n",
        "                test_losses.append(test_loss.item())\n",
        "                test_accs.append(test_acc)\n",
        "            # add the model weights to the t -1 dictionary\n",
        "            model_weights = model.state_dict()\n",
        "            client_number_num = client_number[i]\n",
        "            dictionary_t_1[client_number_num] = model_weights\n",
        "\n",
        "        for i in range(100):\n",
        "            client_number_num = client_number[i]\n",
        "            # go through neighbors of client_number\n",
        "            string_client_num = str(client_number_num)\n",
        "            client_neighbors = neighbors[string_client_num]\n",
        "\n",
        "            neighbors_state_dicts = []\n",
        "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
        "            for j in range(len(client_neighbors)):\n",
        "                # get model weights of neighbor\n",
        "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
        "                neighbors_state_dicts.append(neighbor_model)\n",
        "\n",
        "            #call some aggregation technique\n",
        "            average_state_dict = {}\n",
        "            average_state_dict = fed_avg(neighbors_state_dicts)\n",
        "            dictionary_t[client_number_num] = average_state_dict\n",
        "\n",
        "        dictionary_t_1 = dictionary_t\n",
        "    return test_losses, test_accs\n",
        "\n",
        "\n",
        "# separate training method to train data in batches\n",
        "def train_batches(graph_data, model, optimizer, criterion, batch_size):\n",
        "    graph_dataset = GraphDataset(graph_data)\n",
        "    graph_data_loader = DataLoader(graph_dataset, batch_size=batch_size, shuffle=True)\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for i, data in enumerate(graph_data_loader):\n",
        "      x, edge_index, y, idx = data\n",
        "      nodes = list(idx)\n",
        "      sub_edge_index, _ = subgraph(nodes, edge_index[0], relabel_nodes=True)\n",
        "      optimizer.zero_grad()\n",
        "      out = model(x, sub_edge_index)\n",
        "      loss = criterion(out, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "    return total_loss/(i+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G452liryAceJ"
      },
      "source": [
        "## Using Adam Optimizer, lr = 0.01, and varying batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvsG3BPRAceJ",
        "outputId": "50c6e284-7286-432e-ac5a-e25d2cc4003b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/malvikavaidya/Documents/UT_Austin/Senior/federated_gnns_project/venv/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch size:  21\n",
            "mean test accuracy after communication:  0.20945686900958468\n",
            "mean test loss after communication:  2.5040859603881835\n",
            "\n",
            "batch size:  16\n",
            "mean test accuracy after communication:  0.19996805111821092\n",
            "mean test loss after communication:  2.6467595398426056\n",
            "\n",
            "batch size:  32\n",
            "mean test accuracy after communication:  0.2327476038338659\n",
            "mean test loss after communication:  2.3432733058929442\n",
            "\n",
            "batch size:  64\n",
            "mean test accuracy after communication:  0.2380191693290735\n",
            "mean test loss after communication:  2.2191815042495726\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_sizes = [21, 16, 32, 64]\n",
        "\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(1, 0.01 , batch_size)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100, 0.01, batch_size)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"batch size: \", batch_size)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo5Z7SXiAceK"
      },
      "source": [
        "### 5 epochs, 100 rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6CcNMHOAceK",
        "outputId": "6cb81a6e-62ba-4ad0-8b29-2309fd2386e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch size:  32\n",
            "mean test accuracy after communication:  0.23769968051118212\n",
            "mean test loss after communication:  2.8651879513263703\n",
            "\n",
            "batch size:  64\n",
            "mean test accuracy after communication:  0.2750479233226837\n",
            "mean test loss after communication:  2.5840364789962766\n",
            "\n",
            "batch size:  100\n",
            "mean test accuracy after communication:  0.32028753993610204\n",
            "mean test loss after communication:  2.2876565039157866\n",
            "\n",
            "batch size:  128\n",
            "mean test accuracy after communication:  0.3300958466453674\n",
            "mean test loss after communication:  2.2211943471431734\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_sizes = [32, 64, 100, 128]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01 , batch_size)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01, batch_size)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"batch size: \", batch_size)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS1AGio2AceL",
        "outputId": "c8e0a2f3-f042-400e-a05a-0ea6e13f40ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch size:  16\n",
            "mean test accuracy after communication:  0.22290734824281155\n",
            "mean test loss after communication:  3.594715747833252\n",
            "\n",
            "batch size:  32\n",
            "mean test accuracy after communication:  0.23463258785942492\n",
            "mean test loss after communication:  3.3052269291877745\n",
            "\n",
            "batch size:  64\n",
            "mean test accuracy after communication:  0.2616293929712461\n",
            "mean test loss after communication:  3.078837525844574\n",
            "\n",
            "batch size:  100\n",
            "mean test accuracy after communication:  0.28284345047923337\n",
            "mean test loss after communication:  2.9073844003677367\n",
            "\n",
            "batch size:  128\n",
            "mean test accuracy after communication:  0.2906389776357827\n",
            "mean test loss after communication:  2.9034778940677644\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_sizes = [16, 32, 64, 100, 128]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(10, 0.01 , batch_size)\n",
        "\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100, 0.01, batch_size)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    print(\"batch size: \", batch_size)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyt2l9zOAceM"
      },
      "source": [
        "# Differential Privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA_fcK8QAceM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DifferentiallyPrivateGCN(nn.Module):\n",
        "    def __init__(self, gcn_model, lr, noise_multiplier):\n",
        "        super(DifferentiallyPrivateGCN, self).__init__()\n",
        "        self.gcn_model = gcn_model\n",
        "        self.lr = lr\n",
        "        self.noise_multiplier = noise_multiplier\n",
        "        self.optimizer = torch.optim.Adam(self.gcn_model.parameters(), lr=self.lr, weight_decay=5e-4)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.gcn_model(x, edge_index)\n",
        "\n",
        "    def train_step(self, x, edge_index, y):\n",
        "        self.optimizer.zero_grad()\n",
        "        output = self.forward(x, edge_index)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        for param in self.gcn_model.parameters():\n",
        "            noise = torch.randn_like(param.grad) * self.noise_multiplier\n",
        "            param.grad.add_(noise)\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return output, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Updated training and communication methods to account for differential privacy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7OMB8bXAceN"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def test(test_data, criterion, model):\n",
        "      test_data = test_data.to(device)\n",
        "      model.eval()\n",
        "      out = model(test_data.x, test_data.edge_index)\n",
        "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
        "      test_correct = pred == test_data.y # Check against ground-truth labels.\n",
        "      test_acc = int(test_correct.sum()) / len(test_data.y)  # Derive ratio of correct predictions.\n",
        "      test_loss = criterion(out, test_data.y)  # Compute validation loss\n",
        "\n",
        "      return test_loss, test_acc\n",
        "\n",
        "\n",
        "def validate(test_data, model, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_data = test_data.to(device)\n",
        "\n",
        "    with torch.no_grad():  # Do not compute gradients during this step\n",
        "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
        "        pred = out.argmax(dim=1)  # Get predicted classes\n",
        "        val_correct = pred == test_data.y # Compare with ground-truth\n",
        "        val_loss = criterion(out, test_data.y)  # Compute validation loss\n",
        "        val_acc = int(val_correct.sum()) / int(len(test_data.y))  # Compute validation accuracy\n",
        "    return val_loss.item(), val_acc\n",
        "\n",
        "\n",
        "def initial_training(epochs, learning_rate):\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    dictionary_t_1 = {}\n",
        "    dictionary_t = {}\n",
        "\n",
        "    for i in range(len(sub_data_list)):\n",
        "        sub_data = sub_data_list[i]\n",
        "        gcn_model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "        model = DifferentiallyPrivateGCN(gcn_model, learning_rate, 0.01)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        # Training loop for each epoch (adjust the range as needed)\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            model.train()  # Set the model to training mode\n",
        "            sub_data = sub_data.to(device)\n",
        "            output, loss = model.train_step(sub_data.x, sub_data.edge_index, sub_data.y)\n",
        "            train_losses.append(loss.item())\n",
        "            val_loss, _ = validate(test_data, model, criterion)  # Assuming 'validate' returns a loss and something else (like accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "            \n",
        "        test_loss, test_acc = test(test_data, criterion, model)\n",
        "        test_losses.append(test_loss.item())\n",
        "        test_accs.append(test_acc)\n",
        "        model_weights =  model.gcn_model.state_dict()\n",
        "        client_number_num = client_number[i]\n",
        "        dictionary_t_1[client_number_num] = model_weights\n",
        "\n",
        "    return dictionary_t_1, test_losses, test_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnCUdNv2AceO"
      },
      "outputs": [],
      "source": [
        "def communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate):\n",
        "    # make a copy of dictionary_t_1\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
        "    dictionary_t = {}\n",
        "    t_1_accuracies = {}\n",
        "\n",
        "    for k in range(1, rounds + 1):\n",
        "\n",
        "    # get the neighbprs of each client\n",
        "        for i in range(len(sub_data_list)):\n",
        "            sub_data = sub_data_list[i]\n",
        "\n",
        "            gcn_model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
        "            state_dict = dictionary_t_1[client_number[i]]\n",
        "            gcn_model.load_state_dict(state_dict)\n",
        "            model = DifferentiallyPrivateGCN(gcn_model, learning_rate, 0.01)\n",
        "            criterion = torch.nn.CrossEntropyLoss()\n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "            for epoch in range(1, epochs + 1):\n",
        "\n",
        "                model.train()\n",
        "                output, loss = model.train_step(sub_data.x, sub_data.edge_index, sub_data.y)\n",
        "                train_losses.append(loss.item())\n",
        "                val_loss, _ = validate(test_data, model, criterion)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            test_loss, test_acc = test(test_data, criterion, model)\n",
        "            if k == rounds:\n",
        "                test_losses.append(test_loss.item())\n",
        "                test_accs.append(test_acc)\n",
        "\n",
        "            # add the model weights to the t -1 dictionary\n",
        "            model_weights =  model.gcn_model.state_dict()\n",
        "            client_number_num = client_number[i]\n",
        "            dictionary_t_1[client_number_num] = model_weights\n",
        "            t_1_accuracies[client_number_num] = test_acc\n",
        "\n",
        "        for i in range(100):\n",
        "            client_number_num = client_number[i]\n",
        "            # go through neighbors of client_number\n",
        "            string_client_num = str(client_number_num)\n",
        "            client_neighbors = neighbors[string_client_num]\n",
        "\n",
        "            neighbors_state_dicts = []\n",
        "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
        "            accuracies = []\n",
        "            accuracies.append(t_1_accuracies[client_number_num])\n",
        "            for j in range(len(client_neighbors)):\n",
        "                # get model weights of neighbor\n",
        "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
        "                neighbors_state_dicts.append(neighbor_model)\n",
        "                accuracies.append(t_1_accuracies[int(client_neighbors[j])])\n",
        "\n",
        "            #call some aggregation technique\n",
        "            average_state_dict = {}\n",
        "            average_state_dict = exponential_weighted_fed_avg(neighbors_state_dicts, accuracies)\n",
        "            dictionary_t[client_number_num] = average_state_dict\n",
        "\n",
        "        dictionary_t_1 = dictionary_t\n",
        "\n",
        "    return test_losses, test_accs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training using Differential Privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AolRxLf5cd5-",
        "outputId": "e9d89a69-1269-47e4-e76e-f9cb8cb1ef21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test accuracy after communication:  0.6625878594249202\n",
            "mean test loss after communication:  1.139604046344757\n"
          ]
        }
      ],
      "source": [
        "# differential privacy and exponential averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwgpa2Xhc89W",
        "outputId": "717df0a0-cce9-4289-9aaf-b94daab3711a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean test accuracy after communication:  0.65814696485623\n",
            "mean test loss after communication:  1.1924089205265045\n"
          ]
        }
      ],
      "source": [
        "# differential privacy and normalized averaging\n",
        "dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, 0.01)\n",
        "mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEYkyMv7AceP"
      },
      "outputs": [],
      "source": [
        "communication_rounds = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZTI7_QXAceP",
        "outputId": "29561ccd-18f4-4365-ab84-9a4078ea3a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round:  1\n",
            "mean test accuracy after communication:  0.15159744408945675\n",
            "mean test loss after communication:  2.4348197722435\n",
            "round:  5\n",
            "mean test accuracy after communication:  0.23798722044728446\n",
            "mean test loss after communication:  1.890577154159546\n",
            "round:  10\n",
            "mean test accuracy after communication:  0.32920127795527165\n",
            "mean test loss after communication:  1.7388195419311523\n",
            "round:  20\n",
            "mean test accuracy after communication:  0.5144408945686904\n",
            "mean test loss after communication:  1.4288203847408294\n",
            "round:  30\n",
            "mean test accuracy after communication:  0.5555910543130993\n",
            "mean test loss after communication:  1.4035931396484376\n",
            "round:  40\n",
            "mean test accuracy after communication:  0.5715335463258784\n",
            "mean test loss after communication:  1.4454518449306488\n",
            "round:  50\n",
            "mean test accuracy after communication:  0.5746006389776357\n",
            "mean test loss after communication:  1.3649107885360718\n",
            "round:  60\n",
            "mean test accuracy after communication:  0.6522683706070288\n",
            "mean test loss after communication:  1.1720077800750732\n",
            "round:  70\n",
            "mean test accuracy after communication:  0.693290734824281\n",
            "mean test loss after communication:  1.1230378991365433\n",
            "round:  80\n",
            "mean test accuracy after communication:  0.685335463258786\n",
            "mean test loss after communication:  1.1869358086586\n",
            "round:  90\n",
            "mean test accuracy after communication:  0.7462300319488822\n",
            "mean test loss after communication:  0.9768103450536728\n",
            "round:  100\n"
          ]
        }
      ],
      "source": [
        "mean_accs_list = []\n",
        "for round in communication_rounds:\n",
        "    print(\"round: \", round)\n",
        "    dictionary_t_1, test_losses, test_accs = initial_training(5, 0.01)\n",
        "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, round, 0.01)\n",
        "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
        "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
        "    mean_accs_list.append(mean_test_accs)\n",
        "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
        "    print(\"mean test loss after communication: \", mean_test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O8h-eOoAceP",
        "outputId": "f5b46afe-4a61-44e1-b44d-1aec4c3c1e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.1532587859424919, 0.14533546325878577, 0.1467412140575078, 0.1557188498402554, 0.19044728434504798, 0.3314376996805111, 0.45261980830670934, 0.5071246006389777, 0.5819169329073481, 0.6315015974440897, 0.6581789137380193, 0.6551757188498404]\n"
          ]
        }
      ],
      "source": [
        "print(mean_accs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3s2qpriAceQ"
      },
      "outputs": [],
      "source": [
        "threshold_accs= [0.15418530351437687, 0.20492012779552715, 0.2885303514376998, 0.47063897763578266, 0.5449840255591053, 0.5782747603833865, 0.6622044728434509, 0.6706070287539937, 0.69444089456869, 0.7167412140575081, 0.6636421725239617, 0.7298402555910544]\n",
        "fed_avg_accs = [0.15603833865814687, 0.14603833865814678, 0.1497124600638976, 0.15562300319488803, 0.18904153354632583, 0.2844728434504793, 0.4249520766773161, 0.5192012779552715, 0.5854952076677317, 0.6473482428115015, 0.6533865814696486, 0.658594249201278]\n",
        "weighted_avg_accs = [0.1532587859424919, 0.14533546325878577, 0.1467412140575078, 0.1557188498402554, 0.19044728434504798, 0.3314376996805111, 0.45261980830670934, 0.5071246006389777, 0.5819169329073481, 0.6315015974440897, 0.6581789137380193, 0.6551757188498404]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKK-3sxgAceR",
        "outputId": "c429918e-f6a5-4dcc-8f58-43733d267e9e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plotting the test accuracies\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.plot(communication_rounds, fed_avg_accs)\n",
        "plt.plot(communication_rounds, weighted_avg_accs)\n",
        "plt.plot(communication_rounds, threshold_accs)\n",
        "\n",
        "\n",
        "plt.legend([\"FedAvg\", \"Weighted Avg\", \"Threshold Weighted Avg\"])\n",
        "plt.grid()\n",
        "plt.title(\"Average Test Accuracies over Communication Rounds with Gradient Noise\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0wUQteYAceR",
        "outputId": "c76e9dfc-d2d6-4012-883f-8e9611e7a48a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARPklEQVR4nO3de4yldX3H8fdHFgULlYUd6YqElYtajLLUDd5bBVS8RLA1RNpYiNq1iViNWEtpYr3UZm0VYqvVohBpq1C8EKhaERGLVLEOunLbKLAuwhZhYEGgVXSXb/84z9jDOLPnzJ3fzPuVPJnn/nzPb5/5zLO/8zznpKqQJLXnEYtdgCRpZgxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeDSIkpyf5IDF7sOtckA15zqAml8eDDJT/um/2AG+/taktfPR60PB1W1R1VtXuw61KYVi12Alpaq2mN8PMkW4PVV9ZXFq2h+JVlRVdsXuw4tT16Ba0EkeUSSU5PclOSuJOcn2btbtluSf+nm35Pk20n2TfJe4HnAh7or+A9Nse9PJ/lxkp8kuTzJU/qW7Z7kA0lu7pZfkWT3btlzk3yjO+YtSU7q5j/kqj/JSUmu6JuuJG9McgNwQzfvg90+7k1yVZLn9a2/S5LTutd+X7d8/759HdyNPyrJ+5P8KMntST7aV+uqJJ/vat2W5OtJ/P1d5jwBtFDeBBwH/A7wOOBu4MPdshOBxwD7A/sAfwz8tKr+Avg6cHLX1XDyFPv+d+AQ4LHAd4BP9i17P/B04NnA3sDbgQeTHNBt9/fACLAW2DiN13Mc8Azg0G76290+9gY+BXw6yW7dsrcCJwAvBX4deC3wv5PscwPwxG4/BwP7Ae/olp0C3NrVui9wGuDnYCx3VeXgMC8DsAU4uhvfBBzVt2w18At63XivBb4BPG2SfXyNXjfMsMfci16wPYbeBcpPgcMmWe/PgQum2MdDjgmcBFzRN13AkQPquHv8uMD3gWOnWK/ohXWA/wEO6lv2LOCH3fi7gQuBgxf739Xh4TN4Ba6FcgBwQdcFcA+9QN9B72ryn4GLgfOS/HeSv0my6zA77bonNnTdE/fS+6MBsKobdgNummTT/aeYP6xbJtTxtiSbum6ae+j9AVk1jWONAI8Gruproy918wH+FrgR+HKSzUlOnUXtWiIMcC2UW4CXVNVefcNuVbW1qn5RVe+qqkPpdXW8HPjDbrtB3QS/DxwLHE0vNNd08wPcCfwMOGiKeiabD70r4Uf3Tf/GJOv8sq6uv/vtwPHAyqraC/hJV8OgY427k97/Fp7S1z6Pqe5N4aq6r6pOqaoDgVcAb01y1IB9aokzwLVQPgq8t+t7JslIkmO78RckeWqSXYB76XWtPNhtdzuws/uk9wQeAO6iF7p/Pb6gqh4EzgZOT/K47mr9WUkeRa+f/OgkxydZkWSfJGu7TTcCv5vk0d0bjK8b8Nr2BLYDY8CKJO+g19c97uPAe5Ickp6nJdmnfwddrR8Dzkjy2K5d9kvy4m785UkOThJ6fxx29LWRlikDXAvlg8BF9LoA7gOupPcmIPSucD9DL7w3Af9Br1tlfLtXJbk7yd9Nst9/Am4GtgLXd/vt9zbgGnpvMm4D3gc8oqp+RO9NxVO6+RuBw7ptzgB+Tu+Pxzk89E3RyVxMr7vjB10tP+OhXSynA+cDX+5e41nA7pPs58/odZNc2XUHfQV4UrfskG76fuCbwD9U1WUD6tISlyrfyJakFnkFLkmNMsAlqVEGuCQ1ygCXpEYt6IdZrVq1qtasWbOQh5Sk5l111VV3VtXIxPkLGuBr1qxhdHR0IQ8pSc1LcvNk8+1CkaRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRi3ok5iSBLDm1C8synG3bHjZohx3vngFLkmNMsAlqVEDAzzJbkn+K8n3klyX5F3d/Cck+VaSG5P8a5JHzn+5kqRxw1yBPwAcWVWHAWuBY5I8k96Xw55RVQcDdzP4m7slSXNoYIBXz/3d5K7dUMCR9L5JHHrf3H3cfBQoSZrcUH3gSXZJshG4A7gEuAm4p6q2d6vcCuw3xbbrk4wmGR0bG5uDkiVJMGSAV9WOqloLPB44AnjysAeoqjOral1VrRsZ+ZUvlJAkzdC07kKpqnuAy4BnAXslGb+P/PHA1rktTZK0M8PchTKSZK9ufHfghcAmekH+qm61E4EL56lGSdIkhnkSczVwTpJd6AX++VX1+STXA+cl+Svgu8BZ81inJGmCgQFeVVcDh08yfzO9/nBJ0iLwSUxJapQfZiVp2VisD9GC+fkgLa/AJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUwABPsn+Sy5Jcn+S6JG/u5r8zydYkG7vhpfNfriRp3Ioh1tkOnFJV30myJ3BVkku6ZWdU1fvnrzxJ0lQGBnhV3Qbc1o3fl2QTsN98FyZJ2rlp9YEnWQMcDnyrm3VykquTnJ1k5RTbrE8ymmR0bGxsdtVKkn5p6ABPsgfwWeAtVXUv8BHgIGAtvSv0D0y2XVWdWVXrqmrdyMjI7CuWJAFDBniSXemF9yer6nMAVXV7Ve2oqgeBjwFHzF+ZkqSJhrkLJcBZwKaqOr1v/uq+1V4JXDv35UmSpjLMXSjPAV4DXJNkYzfvNOCEJGuBArYAb5iH+iRJUxjmLpQrgEyy6ItzX44kaVg+iSlJjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUwABPsn+Sy5Jcn+S6JG/u5u+d5JIkN3Q/V85/uZKkccNcgW8HTqmqQ4FnAm9McihwKnBpVR0CXNpNS5IWyMAAr6rbquo73fh9wCZgP+BY4JxutXOA4+apRknSJKbVB55kDXA48C1g36q6rVv0Y2DfKbZZn2Q0yejY2NhsapUk9Rk6wJPsAXwWeEtV3du/rKoKqMm2q6ozq2pdVa0bGRmZVbGSpP83VIAn2ZVeeH+yqj7Xzb49yepu+WrgjvkpUZI0mWHuQglwFrCpqk7vW3QRcGI3fiJw4dyXJ0mayooh1nkO8BrgmiQbu3mnARuA85O8DrgZOH5eKpQkTWpggFfVFUCmWHzU3JYjSRqWT2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaNTDAk5yd5I4k1/bNe2eSrUk2dsNL57dMSdJEw1yBfwI4ZpL5Z1TV2m744tyWJUkaZGCAV9XlwLYFqEWSNA2z6QM/OcnVXRfLyjmrSJI0lJkG+EeAg4C1wG3AB6ZaMcn6JKNJRsfGxmZ4OEnSRDMK8Kq6vap2VNWDwMeAI3ay7plVta6q1o2MjMy0TknSBDMK8CSr+yZfCVw71bqSpPmxYtAKSc4Fng+sSnIr8JfA85OsBQrYArxh/kqUJE1mYIBX1QmTzD5rHmqRJE2DT2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGjXwQR5JS9OaU7+w2CVolrwCl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1amCAJzk7yR1Jru2bt3eSS5Lc0P1cOb9lSpImGuYK/BPAMRPmnQpcWlWHAJd205KkBTQwwKvqcmDbhNnHAud04+cAx81tWZKkQWbaB75vVd3Wjf8Y2HeqFZOsTzKaZHRsbGyGh5MkTTTrNzGrqoDayfIzq2pdVa0bGRmZ7eEkSZ2ZBvjtSVYDdD/vmLuSJEnDmGmAXwSc2I2fCFw4N+VIkoY1zG2E5wLfBJ6U5NYkrwM2AC9McgNwdDctSVpAKwatUFUnTLHoqDmuRZI0DT6JKUmNGngFLml+rTn1C4tdghrlFbgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGuWHWelhZbE+2GnLhpctynGl2fAKXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXK2wgl/F5KtckrcElqlAEuSY2aVRdKki3AfcAOYHtVrZuLoiRJg81FH/gLqurOOdiPJGka7EKRpEbNNsAL+HKSq5Ksn2yFJOuTjCYZHRsbm+XhJEnjZhvgz62q3wJeArwxyW9PXKGqzqyqdVW1bmRkZJaHkySNm1WAV9XW7ucdwAXAEXNRlCRpsBkHeJJfS7Ln+DjwIuDauSpMkrRzs7kLZV/ggiTj+/lUVX1pTqqSJA004wCvqs3AYXNYiyRpGryNUJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQovxNTv8Lvh5Ta4BW4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhrVzIdZLccPWNqy4WWLXYKkhzGvwCWpUQa4JDXKAJekRs0qwJMck+T7SW5McupcFSVJGmzGAZ5kF+DDwEuAQ4ETkhw6V4VJknZuNlfgRwA3VtXmqvo5cB5w7NyUJUkaZDa3Ee4H3NI3fSvwjIkrJVkPrO8m70/y/WkcYxVw54wrbFze98vRZd0OfWyHHtuhp6l26Pt9nokDJps57/eBV9WZwJkz2TbJaFWtm+OSmmM79NgOPbZDj+0wuy6UrcD+fdOP7+ZJkhbAbAL828AhSZ6Q5JHAq4GL5qYsSdIgM+5CqartSU4GLgZ2Ac6uquvmrLKeGXW9LEG2Q4/t0GM79Cz7dkhVLXYNkqQZ8ElMSWqUAS5JjVqUAB/0CH6Sk5KMJdnYDa/vW7ajb37Tb5oO81EESY5Pcn2S65J8qm/+iUlu6IYTF67quTfLdlgy5wMM9btxRt/r/UGSe/qWLZtzYkA7LKlzYqeqakEHem943gQcCDwS+B5w6IR1TgI+NMX29y90zYvYDocA3wVWdtOP7X7uDWzufq7sxlcu9mta6HZYSufDsG0xYf030bt5YNmdE1O1w1I7JwYNi3EF7iP4PcO0wx8BH66quwGq6o5u/ouBS6pqW7fsEuCYBap7rs2mHZaa6f5unACc240vt3OiX387LCuLEeCTPYK/3yTr/V6Sq5N8Jkn/A0O7JRlNcmWS4+az0Hk2TDs8EXhikv/sXu8x09i2FbNpB1g65wNM4981yQHAE4CvTnfbBsymHWBpnRM79XD9SrV/A86tqgeSvAE4BziyW3ZAVW1NciDw1STXVNVNi1bp/FpBr/vg+fSedL08yVMXtaLFMWk7VNU9LK/zod+rgc9U1Y7FLmSRTdYOy+acWIwr8IGP4FfVXVX1QDf5ceDpfcu2dj83A18DDp/PYufRMB9FcCtwUVX9oqp+CPyAXpAtpY8xmE07LKXzAab37/pqHtptsNzOiXET22GpnRM7t9Cd7vSupjbT+2/P+BsUT5mwzuq+8VcCV3bjK4FHdeOrgBvYyZsbD+dhyHY4Bjin7/XeAuxD742qH3btsbIb33uxX9MitMOSOR+GbYtuvScDW+gexOvmLatzYiftsKTOiUHDgneh1BSP4Cd5NzBaVRcBf5LkFcB2YBu9u1IAfhP4xyQP0vvfw4aqun6hX8NcGLIdLgZelOR6YAfwp1V1F0CS99D7PBqAd1fVtoV/FbM3m3ZI8myWyPkAQ7cF9K46z6supbptty2zcwImaQeWUEYMw0fpJalRPokpSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1Kj/g8ZK+rimAMUOwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot test accuracies\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(test_accs)\n",
        "plt.title(\"Test accuracies\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ar3LbaYAceS"
      },
      "source": [
        "On Centralized Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fxFsU9OAceS",
        "outputId": "6d9a9651-55b3-4b8d-986f-c84cad22ac28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Centralized learning test accuracy:  0.3226837060702875\n"
          ]
        }
      ],
      "source": [
        "# testing differential privacy model on centralized learning to see whether a similar improvement occurs\n",
        "\n",
        "from torchcontrib.optim import SWA\n",
        "import os\n",
        "import networkx as nx\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "cora_graph_training = nx.read_gml('cora_graph_training.gml')\n",
        "test_graph = test_data\n",
        "\n",
        "graph_nodes = list(cora_graph_training.nodes)\n",
        "graph_nodes = [int(node) for node in graph_nodes]  # Convert to integer if they are not\n",
        "\n",
        "graph_edge_index, _ = subgraph(graph_nodes, data.edge_index, relabel_nodes=True)\n",
        "graph_data = Data(x=data.x[graph_nodes], edge_index=graph_edge_index, y=data.y[graph_nodes])\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_test(graph_data, epochs, dataset, test_data, device):\n",
        "    model  = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
        "    private_model = DifferentiallyPrivateGCN(model, 0.01, 0.01)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    epochs = 10\n",
        "    # Training loop for each epoch (adjust the range as needed)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        output, loss = private_model.train_step(graph_data.x, graph_data.edge_index, graph_data.y)\n",
        "        train_losses.append(loss.item())\n",
        "        val_loss, _ = validate(test_data, private_model, criterion)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    test_loss, test_acc = test(test_data, criterion, private_model)\n",
        "    print(\"Centralized learning test accuracy: \", test_acc)\n",
        "\n",
        "train_test(graph_data, 10, dataset, test_data, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
