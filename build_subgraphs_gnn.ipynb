{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "folder_path = 'second_order_client_neighbors'\n",
    "sub_data_list = []\n",
    "client_number = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.gml'):\n",
    "      \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        g = nx.read_gml(file_path)\n",
    "\n",
    "        subgraph_nodes = list(g.nodes)\n",
    "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "        sub_data_list.append(sub_data)\n",
    "        client_number.append(int(filename.split('.')[0].split('_')[1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = None\n",
    "\n",
    "g = nx.read_gml('second_order_test_graph.gml')\n",
    "subgraph_nodes = list(g.nodes)\n",
    "subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "test_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'828': ['713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '849', '718', '754', '760', '739', '856', '764', '687', '840', '847', '770', '797', '814', '727', '731', '708', '698', '817', '792', '845', '838', '848', '835', '807', '711', '779', '706', '772', '741', '709', '778', '737', '844', '693'], '713': ['828', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '760', '787', '840', '847', '814', '731', '708', '698', '738', '817', '734', '845', '701', '848', '748', '706', '777', '772', '818', '778', '831', '833', '722', '844', '736', '794', '693'], '705': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '703', '784', '752', '728', '820', '842', '800', '819', '726', '773', '829', '780', '810', '849', '718', '754', '760', '739', '787', '764', '847', '770', '814', '731', '738', '845', '835', '807', '758', '803', '748', '755', '809', '720', '706', '772', '741', '778', '737', '831', '722', '844', '693', '763'], '719': ['828', '713', '705', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '810', '696', '849', '718', '760', '787', '764', '840', '847', '814', '727', '731', '708', '698', '817', '734', '845', '848', '755', '720', '706', '772', '737', '722', '768', '794'], '805': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '703', '695', '815', '752', '728', '842', '800', '819', '774', '726', '766', '829', '780', '810', '696', '718', '754', '760', '739', '764', '687', '840', '847', '814', '727', '731', '738', '817', '792', '734', '838', '807', '706', '772', '709', '818', '737', '831', '844'], '824': ['828', '713', '705', '719', '805', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '819', '774', '726', '773', '766', '829', '780', '696', '849', '754', '760', '739', '764', '840', '847', '770', '727', '708', '792', '838', '848', '835', '779', '777', '709', '737', '844', '693'], '745': ['828', '713', '705', '719', '805', '824', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '829', '810', '696', '718', '760', '787', '847', '814', '731', '698', '738', '817', '845', '758', '711', '755', '720', '706', '795', '737', '722', '794'], '747': ['828', '713', '705', '719', '805', '745', '823', '830', '697', '688', '703', '815', '752', '728', '820', '800', '819', '774', '773', '780', '810', '696', '849', '718', '754', '739', '856', '764', '687', '840', '770', '797', '708', '698', '792', '838', '701', '848', '807', '793', '758', '803', '748', '783', '809', '741', '831', '730', '763', '765'], '823': ['828', '713', '705', '719', '805', '824', '745', '747', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '815', '752', '728', '820', '800', '819', '774', '726', '773', '766', '780', '810', '696', '718', '754', '760', '739', '787', '856', '764', '687', '840', '708', '698', '792', '838', '848', '835', '807', '779', '741', '709', '693', '765'], '694': ['828', '713', '705', '719', '805', '824', '745', '823', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '780', '810', '696', '754', '760', '847', '727', '731', '738', '845', '848', '711', '706', '795', '772', '737', '831', '722'], '830': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '695', '815', '752', '820', '800', '819', '774', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '847', '727', '731', '817', '792', '845', '838', '701', '748', '777', '709', '778', '737', '844'], '781': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '697', '724', '827', '853', '834', '703', '695', '784', '815', '752', '728', '842', '800', '726', '773', '829', '810', '849', '718', '760', '787', '764', '770', '814', '731', '708', '738', '817', '701', '793', '758', '755', '783', '809', '720', '772', '741', '794'], '697': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '834', '695', '815', '820', '842', '800', '819', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '727', '731', '708', '698', '701', '848', '835', '748', '777', '772', '709', '818', '844', '693', '765'], '724': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '827', '688', '853', '834', '695', '784', '752', '820', '842', '819', '726', '773', '766', '829', '696', '754', '760', '814', '731', '708', '738', '734', '701', '848', '711', '795', '777', '778', '736', '794'], '827': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '853', '834', '703', '784', '752', '842', '800', '819', '773', '766', '810', '849', '718', '760', '787', '764', '797', '814', '731', '708', '817', '758', '755', '783', '809', '772', '741'], '688': ['828', '713', '719', '805', '824', '747', '823', '694', '830', '697', '724', '853', '834', '695', '815', '752', '800', '819', '774', '726', '766', '780', '696', '849', '754', '739', '856', '687', '840', '847', '770', '727', '792', '734', '845', '701', '777', '772', '771'], '853': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '724', '827', '688', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '810', '696', '847', '814', '727', '731', '738', '734', '711', '706', '795', '831', '722'], '834': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '695', '784', '815', '752', '820', '842', '800', '819', '726', '773', '766', '829', '780', '810', '696', '718', '760', '847', '814', '731', '701', '706', '778', '844', '693'], '703': ['828', '705', '719', '805', '824', '747', '823', '694', '781', '827', '815', '728', '820', '819', '718', '754', '739', '787', '856', '764', '687', '797', '698', '817', '792', '845', '838', '835', '807', '793', '758', '748', '779', '809', '741', '709', '831', '730', '765'], '695': ['713', '719', '805', '824', '745', '694', '830', '781', '697', '724', '688', '853', '834', '784', '815', '752', '842', '726', '766', '829', '780', '810', '696', '718', '754', '760', '840', '847', '738', '734', '701', '711', '706', '777', '778', '844', '794', '693'], '784': ['828', '713', '705', '719', '824', '745', '694', '781', '724', '827', '853', '834', '695', '752', '842', '800', '774', '726', '773', '766', '829', '810', '696', '760', '727', '731', '738', '734', '711', '706', '795', '722', '794'], '815': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '688', '853', '834', '703', '695', '752', '819', '726', '773', '766', '780', '810', '718', '754', '856', '847', '731', '792', '845', '838', '835', '706', '737'], '752': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '853', '834', '695', '784', '815', '820', '842', '800', '774', '726', '773', '766', '829', '810', '847', '727', '731', '738', '711', '706', '831'], '728': ['828', '705', '719', '805', '824', '747', '823', '781', '703', '820', '819', '774', '773', '780', '754', '739', '787', '856', '764', '687', '797', '817', '792', '838', '835', '807', '803', '783', '779', '809', '741', '737', '730', '765'], '820': ['828', '705', '719', '824', '745', '747', '823', '694', '830', '697', '724', '853', '834', '703', '752', '728', '774', '726', '773', '766', '849', '760', '687', '770', '797', '845', '848', '803', '783', '795', '741', '737', '831', '722', '763'], '842': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '697', '724', '827', '853', '834', '695', '784', '752', '800', '773', '829', '810', '696', '760', '814', '727', '738', '734', '701', '711', '795', '794'], '800': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '830', '781', '697', '827', '688', '853', '834', '784', '752', '842', '774', '766', '810', '760', '856', '814', '727', '708', '698', '845', '772', '741'], '819': ['828', '713', '705', '719', '805', '824', '747', '823', '830', '697', '724', '827', '688', '834', '703', '815', '728', '774', '780', '739', '856', '687', '840', '708', '698', '817', '792', '838', '848', '835', '807', '709', '778'], '774': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '688', '853', '784', '752', '728', '820', '800', '819', '773', '810', '696', '739', '856', '687', '840', '731', '708', '698', '738', '701', '807', '720'], '726': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '688', '853', '834', '695', '784', '815', '752', '820', '773', '766', '780', '754', '760', '731', '845', '701', '778', '844', '693'], '773': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '724', '827', '853', '834', '784', '815', '752', '728', '820', '842', '774', '726', '829', '780', '810', '696', '754', '847', '731', '706', '737', '831'], '766': ['828', '713', '719', '805', '824', '823', '694', '830', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '820', '800', '726', '780', '810', '849', '760', '847', '727', '731', '734', '711', '771'], '829': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '724', '853', '834', '695', '784', '752', '842', '773', '696', '760', '847', '814', '738', '734', '711', '795', '777', '822', '722'], '780': ['828', '713', '705', '805', '824', '747', '823', '694', '830', '697', '688', '834', '695', '815', '728', '819', '726', '773', '766', '696', '754', '739', '687', '840', '792', '845', '838', '701', '835', '803', '779', '777', '765'], '810': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '781', '827', '853', '834', '695', '784', '815', '752', '842', '800', '774', '773', '766', '856', '847', '814', '731', '698', '711', '706'], '696': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '697', '724', '688', '853', '834', '695', '784', '842', '774', '773', '829', '780', '739', '840', '727', '738', '845', '711', '795', '778'], '849': ['828', '705', '719', '824', '747', '830', '781', '697', '827', '688', '820', '766', '787', '770', '797', '727', '708', '734', '845', '793', '758', '748', '755', '783', '730', '763'], '718': ['828', '705', '719', '805', '745', '747', '823', '781', '827', '834', '703', '695', '815', '787', '764', '687', '770', '797', '814', '817', '793', '758', '803', '748', '809', '720', '730'], '754': ['828', '705', '805', '824', '747', '823', '694', '830', '697', '724', '688', '703', '695', '815', '728', '726', '773', '780', '739', '840', '792', '838', '701', '848', '835', '779', '777', '709'], '760': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '834', '695', '784', '820', '842', '800', '726', '766', '829', '814', '708', '738', '734', '701', '794'], '739': ['828', '705', '805', '824', '747', '823', '688', '703', '728', '819', '774', '780', '696', '754', '787', '764', '687', '840', '797', '792', '807', '793', '758', '720', '777', '709'], '787': ['713', '705', '719', '745', '823', '781', '827', '703', '728', '849', '718', '739', '764', '797', '814', '817', '793', '758', '803', '748', '755', '783', '809', '720', '730', '763'], '856': ['828', '747', '823', '830', '697', '688', '703', '815', '728', '800', '819', '774', '810', '687', '840', '708', '698', '838', '807', '772', '765'], '764': ['828', '705', '719', '805', '824', '747', '823', '781', '827', '703', '728', '718', '739', '787', '687', '797', '817', '838', '807', '793', '748', '783', '779', '809', '720', '730'], '687': ['828', '805', '747', '823', '830', '697', '688', '703', '728', '820', '819', '774', '780', '718', '739', '856', '764', '797', '817', '838', '807', '783', '779', '777', '730', '765'], '840': ['828', '713', '719', '805', '824', '747', '823', '830', '697', '688', '695', '819', '774', '780', '696', '754', '739', '856', '708', '698', '838', '848', '803', '779', '709'], '847': ['828', '713', '705', '719', '805', '824', '745', '694', '830', '688', '853', '834', '695', '815', '752', '773', '766', '829', '810', '727', '731', '734', '711', '706'], '770': ['828', '705', '824', '747', '781', '688', '820', '849', '718', '797', '727', '734', '845', '803', '748', '783', '777', '772', '741', '763'], '797': ['828', '747', '827', '703', '728', '820', '849', '718', '739', '787', '764', '687', '770', '708', '817', '793', '748', '755', '783', '809', '831', '730', '763'], '814': ['828', '713', '705', '719', '805', '745', '781', '724', '827', '853', '834', '842', '800', '829', '810', '718', '760', '787', '708', '758', '755', '772'], '727': ['828', '719', '805', '824', '694', '830', '697', '688', '853', '784', '752', '842', '800', '766', '696', '849', '847', '770', '845', '848', '711'], '731': ['828', '713', '705', '719', '805', '745', '694', '830', '781', '697', '724', '827', '853', '834', '784', '815', '752', '774', '726', '773', '766', '810', '847', '706'], '708': ['828', '713', '719', '824', '747', '823', '781', '697', '724', '827', '800', '819', '774', '849', '760', '856', '840', '797', '814', '755', '730'], '698': ['828', '713', '719', '745', '747', '823', '697', '703', '800', '819', '774', '810', '856', '840', '803', '772'], '738': ['713', '705', '805', '745', '694', '781', '724', '853', '695', '784', '752', '842', '774', '829', '696', '760', '711', '795', '722', '794'], '817': ['828', '713', '719', '805', '745', '830', '781', '827', '703', '728', '819', '718', '787', '764', '687', '797', '793', '758', '748', '783', '809'], '792': ['828', '805', '824', '747', '823', '830', '688', '703', '815', '728', '819', '780', '754', '739', '838', '835', '807', '803', '779', '765'], '734': ['713', '719', '805', '724', '688', '853', '695', '784', '842', '766', '829', '849', '760', '847', '770', '803', '778', '693'], '845': ['828', '713', '705', '719', '745', '694', '830', '688', '703', '815', '820', '800', '726', '780', '696', '849', '770', '727', '701', '755', '772'], '838': ['828', '805', '824', '747', '823', '830', '703', '815', '728', '819', '780', '754', '856', '764', '687', '840', '792', '835', '807', '779', '709'], '701': ['713', '747', '830', '781', '697', '724', '688', '834', '695', '842', '774', '726', '780', '754', '760', '845', '777', '778', '794'], '848': ['828', '713', '719', '824', '747', '823', '694', '697', '724', '820', '819', '754', '840', '727', '709', '844'], '835': ['828', '705', '824', '823', '697', '703', '815', '728', '819', '780', '754', '792', '838', '779', '741', '709', '765'], '807': ['828', '705', '805', '747', '823', '703', '728', '819', '774', '739', '856', '764', '687', '792', '838', '779', '741', '765'], '793': ['747', '781', '703', '849', '718', '739', '787', '764', '797', '817', '758', '748', '755', '783', '809', '720'], '758': ['705', '745', '747', '781', '827', '703', '849', '718', '739', '787', '814', '817', '793', '748', '755', '783', '809'], '711': ['828', '745', '694', '724', '853', '695', '784', '752', '842', '766', '829', '810', '696', '847', '727', '738', '795', '722'], '803': ['705', '747', '728', '820', '780', '718', '787', '840', '770', '698', '792', '734', '720', '730', '763'], '748': ['713', '705', '747', '830', '697', '703', '849', '718', '787', '764', '770', '797', '817', '793', '758', '779', '831'], '755': ['705', '719', '745', '781', '827', '849', '787', '797', '814', '708', '845', '793', '758', '783', '809', '720'], '783': ['747', '781', '827', '728', '820', '849', '787', '764', '687', '770', '797', '817', '793', '758', '755', '809', '730'], '779': ['828', '824', '823', '703', '728', '780', '754', '764', '687', '840', '792', '838', '835', '807', '748', '777', '765'], '809': ['705', '747', '781', '827', '703', '728', '718', '787', '764', '797', '817', '793', '758', '755', '783', '720'], '720': ['705', '719', '745', '781', '774', '718', '739', '787', '764', '793', '803', '755', '809', '730'], '706': ['828', '713', '705', '719', '805', '745', '694', '853', '834', '695', '784', '815', '752', '773', '810', '847', '731'], '795': ['745', '694', '724', '853', '784', '820', '842', '829', '696', '738', '711', '794'], '777': ['713', '824', '830', '697', '724', '688', '695', '829', '780', '754', '739', '687', '770', '701', '779', '709'], '772': ['828', '713', '705', '719', '805', '694', '781', '697', '827', '688', '800', '856', '770', '814', '698', '845'], '741': ['828', '705', '747', '823', '781', '827', '703', '728', '820', '800', '770', '835', '807', '763'], '709': ['828', '805', '824', '823', '830', '697', '703', '819', '754', '739', '840', '838', '848', '835', '777'], '818': ['713', '805', '697', '822', '806', '839', '771', '732', '736', '714'], '778': ['828', '713', '705', '830', '724', '834', '695', '819', '726', '696', '734', '701', '844', '693'], '737': ['828', '705', '719', '805', '824', '745', '694', '830', '815', '728', '820', '773', '722'], '831': ['713', '705', '805', '747', '694', '853', '703', '752', '820', '773', '797', '748'], '833': ['713', '806', '768', '736'], '822': ['829', '818', '806', '839', '768', '732', '714'], '806': ['818', '833', '822', '839', '771', '732', '714'], '730': ['747', '703', '728', '849', '718', '787', '764', '687', '797', '708', '803', '783', '720', '763'], '839': ['818', '822', '806', '771', '768', '732', '714'], '771': ['688', '766', '818', '806', '839', '732', '714'], '722': ['713', '705', '719', '745', '694', '853', '784', '820', '829', '738', '711', '737', '768'], '844': ['828', '713', '705', '805', '824', '830', '697', '834', '695', '726', '848', '778', '693'], '768': ['719', '833', '822', '839', '722'], '732': ['818', '822', '806', '839', '771', '714'], '736': ['713', '724', '818', '833'], '794': ['713', '719', '745', '781', '724', '695', '784', '842', '760', '738', '701', '795'], '693': ['828', '713', '705', '824', '823', '697', '834', '695', '726', '734', '778', '844'], '763': ['705', '747', '820', '849', '787', '770', '797', '803', '741', '730'], '765': ['747', '823', '697', '703', '728', '780', '856', '687', '792', '835', '807', '779'], '714': ['818', '822', '806', '839', '771', '732']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.read_gml('new_facebook_network.gml')\n",
    "neighbors = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors[node] = list(g.neighbors(node))\n",
    "\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new_facebook_network.gml and create a fully connected graph\n",
    "\n",
    "neighbors_fully_connected = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors_fully_connected[node] = list(g.nodes)\n",
    "    neighbors_fully_connected[node].remove(node)\n",
    "\n",
    "    \n",
    "# print(neighbors_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[188, 1433], edge_index=[2, 746], y=[188])\n",
      "torch.Size([188, 1433])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(sub_data_list[0])\n",
    "print(sub_data_list[0].x.shape)\n",
    "print(type(client_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a  list of training and validation loss per epoch for each subgraph\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def transductive_split(data, train_percent=0.8, val_percent=0.1):\n",
    "    \"\"\"\n",
    "    Split graph data into training, validation, and testing sets for transductive learning.\n",
    "    :param data: PyG Data object\n",
    "    :param train_percent: Percentage of nodes to be used for training\n",
    "    :param val_percent: Percentage of nodes to be used for validation\n",
    "    :return: data object with train_mask, val_mask, and test_mask attributes added\n",
    "    \"\"\"\n",
    "    # set a seed for reproducibility\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    train_size = int(train_percent * num_nodes)\n",
    "    val_size = int(val_percent * num_nodes)\n",
    "\n",
    "    # Create a random permutation of node indices\n",
    "    perm = torch.randperm(num_nodes)\n",
    "\n",
    "    # Create masks for training, validation, and testing nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[perm[:train_size]] = True\n",
    "    val_mask[perm[train_size:train_size + val_size]] = True\n",
    "    test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "    # Add masks to data object\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the subgraphs into train test and val \n",
    "# for i in range(0, 100):\n",
    "#     sub_data = sub_data_list[i]\n",
    "#     sub_data = transductive_split(sub_data)\n",
    "\n",
    "\n",
    "# print(torch.sum(sub_data_list[4].train_mask).item())  # Number of training nodes\n",
    "# print(torch.sum(sub_data_list[4].val_mask).item())    # Number of validation nodes\n",
    "# print(torch.sum(sub_data_list[4].test_mask).item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training) # p = 0.25\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots(10, 10, figsize=(50, 50))\n",
    "\n",
    "def train(sub_data, model, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out, sub_data.y)  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      return loss\n",
    "\n",
    "def test(test_data, criterion, model):\n",
    "      model.eval()\n",
    "      out = model(test_data.x, test_data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred == test_data.y # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / len(test_data.y)  # Derive ratio of correct predictions.\n",
    "      test_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "      \n",
    "      return test_loss, test_acc\n",
    "\n",
    "\n",
    "def validate(test_data, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Do not compute gradients during this step\n",
    "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get predicted classes\n",
    "        val_correct = pred == test_data.y # Compare with ground-truth\n",
    "        val_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "        val_acc = int(val_correct.sum()) / int(len(test_data.y))  # Compute validation accuracy\n",
    "    return val_loss.item(), val_acc  # Return validation loss and accuracy\n",
    "\n",
    "\n",
    "def initial_training(epochs, learning_rate):\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    dictionary_t_1 = {}\n",
    "    dictionary_t = {}\n",
    "\n",
    "    for i in range(len(sub_data_list)):\n",
    "        sub_data = sub_data_list[i]\n",
    "        \n",
    "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_losses = [] \n",
    "        val_losses = []    \n",
    "\n",
    "        # Training loop for each epoch (adjust the range as needed)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "            val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "        \n",
    "        test_loss, test_acc = test(test_data, criterion, model)\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accs.append(test_acc)\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "\n",
    "        model_weights = model.state_dict()\n",
    "        client_number_num = client_number[i]\n",
    "        dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return dictionary_t_1, test_losses, test_accs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.721001105308533\n",
      "mean test accuracy before communication:  0.1594249201277954\n"
     ]
    }
   ],
   "source": [
    "dictionary_t_1, test_losses, test_accs = initial_training(10, 0.01)\n",
    "\n",
    "# average test loss and accuracy before communication \n",
    "\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
    "    for k in global_model.keys():\n",
    "        global_model[k] = torch.stack([model[k].float() for model in models], 0).mean(0)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate):\n",
    "    # make a copy of dictionary_t_1\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
    "    dictionary_t = {}\n",
    "    for k in range(1, rounds + 1):\n",
    "\n",
    "    # get the neighbprs of each client\n",
    "        for i in range(len(sub_data_list)):\n",
    "            sub_data = sub_data_list[i]\n",
    "            \n",
    "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_losses = [] \n",
    "            val_losses = []    \n",
    "\n",
    "            # Training loop for each epoch (adjust the range as needed)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "            \n",
    "            test_loss, test_acc = test(test_data, criterion, model)\n",
    "            if k == rounds:\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        \n",
    "            # add the model weights to the t -1 dictionary\n",
    "            model_weights = model.state_dict()\n",
    "            client_number_num = client_number[i]\n",
    "            dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "\n",
    "        for i in range(100):\n",
    "            client_number_num = client_number[i]\n",
    "            # go through neighbors of client_number\n",
    "            string_client_num = str(client_number_num)\n",
    "            client_neighbors = neighbors[string_client_num]\n",
    "            \n",
    "            neighbors_state_dicts = []\n",
    "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
    "            for j in range(len(client_neighbors)):\n",
    "                # get model weights of neighbor\n",
    "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
    "                neighbors_state_dicts.append(neighbor_model)\n",
    "            \n",
    "            #call fed_avg\n",
    "            average_state_dict = {}\n",
    "            average_state_dict = fed_avg(neighbors_state_dicts)\n",
    "            # average weights of client and neighbors\n",
    "            # average_state_dict = {}\n",
    "            # for param in neighbors_state_dicts[0]:\n",
    "            #     # num parameters\n",
    "            #     num_neighbors = len(neighbors_state_dicts)\n",
    "            #     sum_param = 0\n",
    "            #     for neighbor in range(num_neighbors):\n",
    "            #         sum_param += neighbors_state_dicts[neighbor][param]\n",
    "            #     average_param = sum_param / num_neighbors\n",
    "            #     average_state_dict[param] = average_param\n",
    "                \n",
    "                \n",
    "            dictionary_t[client_number_num] = average_state_dict    \n",
    "            \n",
    "        dictionary_t_1 = dictionary_t\n",
    "\n",
    "    return test_losses, test_accs\n",
    " \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss after communication:  3.252580723762512\n",
      "mean test accuracy after communication:  0.17035143769968042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "\n",
    "# average test loss and accuracy after communication\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "\n",
    "#mean of test_accs\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a distriution of the accuracies of test_losses and test_accs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.950941253900528\n",
      "mean test accuracy before communication:  0.15015974440894567\n",
      "mean test loss after communication:  2.0524680721759796\n",
      "mean test accuracy after communication:  0.1924281150159743\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.114197174310684\n",
      "mean test accuracy before communication:  0.15220447284345034\n",
      "mean test loss after communication:  2.6148978340625764\n",
      "mean test accuracy after communication:  0.25000000000000006\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.7938966619968415\n",
      "mean test accuracy before communication:  0.15690095846645355\n",
      "mean test loss after communication:  2.931734937429428\n",
      "mean test accuracy after communication:  0.29412140575079876\n"
     ]
    }
   ],
   "source": [
    "# 01 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.9492018187046052\n",
      "mean test accuracy before communication:  0.15316293929712457\n",
      "mean test loss after communication:  1.930002419948578\n",
      "mean test accuracy after communication:  0.19610223642172536\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.162765134572983\n",
      "mean test accuracy before communication:  0.15233226837060687\n",
      "mean test loss after communication:  2.285061997175217\n",
      "mean test accuracy after communication:  0.3179872204472844\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.7871898126602175\n",
      "mean test accuracy before communication:  0.1592651757188497\n",
      "mean test loss after communication:  2.938849595785141\n",
      "mean test accuracy after communication:  0.31345047923322694\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  3.4152511596679687\n",
      "mean test accuracy before communication:  0.1779233226837061\n",
      "mean test loss after communication:  3.4955796611309053\n",
      "mean test accuracy after communication:  0.2935463258785943\n"
     ]
    }
   ],
   "source": [
    "# 20 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(20)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 20, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.9489406883716582\n",
      "mean test accuracy before communication:  0.1485623003194888\n",
      "mean test loss after communication:  1.9430880868434905\n",
      "mean test accuracy after communication:  0.1542811501597442\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.146751263141632\n",
      "mean test accuracy before communication:  0.1514057507987219\n",
      "mean test loss after communication:  2.396341060400009\n",
      "mean test accuracy after communication:  0.15214057507987205\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.69692032456398\n",
      "mean test accuracy before communication:  0.1590095846645366\n",
      "mean test loss after communication:  3.162060570716858\n",
      "mean test accuracy after communication:  0.17827476038338652\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Graph Results\n",
    "### (Training with original subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.07%                     | 14.29%                    | 1.947                  | 2.083                 |\n",
    "| 5      | 100                  | 14.89%                     | 15.49%                    | 2.021                  | 2.943                 |\n",
    "| 10     | 100                  | 14.73%                     | 14.90%                    | 2.387                  | 5.010                 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Graph Results\n",
    "### (Training with original subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.13%                     | 14.31%                    | 1.947                  | 1.996                 |\n",
    "| 1      | 10                   | 15.40%                     | 15.12%                    | 1.946                  | 1.945                 |\n",
    "| 5      | 100                  | 14.38%                     | 16.16%                    | 2.028                  | 2.730                 |\n",
    "| 5      | 10                   | 14.52%                     | 14.49%                    | 2.014                  | 2.282                 |\n",
    "| 10     | 100                  | 14.74%                     | 16.07%                    | 2.321                  | 4.402                 |\n",
    "| 10     | 10                   | 14.69%                     | 15.01%                    | 2.349                  | 3.084                 |\n",
    "| 20     | 100                  | 15.39%                     | 18.50%                    | 3.101                  | 4.654                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Graph Results\n",
    "### (Training with second order subgraphs)\n",
    "\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.02%                     | 19.24%                    | 1.951                  | 2.052                 |\n",
    "| 5      | 100                  | 15.22%                     | 31.80%                    | 2.114                 | 2.614                |\n",
    "| 10     | 100                  | 15.69%                     | 29.41%                    | 2.794                 | 2.932              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Graphs Results\n",
    "### (Training with second order subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "|--------|----------------------|----------------------------|---------------------------|-----------------------|-----------------------|\n",
    "| 1      | 100                  | 0.1532                     | 0.1961                    | 1.9492                | 1.9300                |\n",
    "| 5      | 100                  | 0.1523                     | 0.3180                    | 2.1628                | 2.2851                |\n",
    "| 10     | 100                  | 0.1593                     | 0.3135                    | 2.7872                | 2.9388                |\n",
    "| 20     | 100                  | 0.1779                     | 0.2935                    | 3.4153                | 3.4956                |\n",
    "| 1      | 10                   | 0.1486                     | 0.1543                    | 1.9489                | 1.9431                |\n",
    "| 5      | 10                   | 0.1514                     | 0.1521                    | 2.1468                | 2.3963                |\n",
    "| 10     | 10                   | 0.1590                     | 0.1783                    | 2.6969                | 3.1621                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized Training on Entire Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized learning test accuracy:  0.6198083067092651\n"
     ]
    }
   ],
   "source": [
    "# get cora_graph_training \n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "cora_graph_training = nx.read_gml('cora_graph_training.gml')\n",
    "test_graph = test_data\n",
    "\n",
    "\n",
    "graph_nodes = list(cora_graph_training.nodes)\n",
    "graph_nodes = [int(node) for node in graph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "graph_edge_index, _ = subgraph(graph_nodes, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "graph_data = Data(x=data.x[graph_nodes], edge_index=graph_edge_index, y=data.y[graph_nodes])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "\n",
    "def train_test(graph_data, epochs, dataset, test_data, device):\n",
    "    model = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    epochs = 10\n",
    "    # Training loop for each epoch (adjust the range as needed)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(graph_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy) \n",
    "\n",
    "    test_loss, test_acc = test(test_data, criterion, model)\n",
    "    \n",
    "    # print(\"Centralized learning test loss: \", test_loss)\n",
    "    print(\"Centralized learning test accuracy: \", test_acc)\n",
    "\n",
    "train_test(graph_data, 10, dataset, test_data, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized Learning with Different Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graph_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/malvikavaidya/Documents/UT_Austin/Senior/federated_gnns_project/build_subgraphs_gnn.ipynb Cell 48\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malvikavaidya/Documents/UT_Austin/Senior/federated_gnns_project/build_subgraphs_gnn.ipynb#Y111sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m batch_sizes \u001b[39m=\u001b[39m [\u001b[39m10\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/malvikavaidya/Documents/UT_Austin/Senior/federated_gnns_project/build_subgraphs_gnn.ipynb#Y111sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_size \u001b[39min\u001b[39;00m batch_sizes:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/malvikavaidya/Documents/UT_Austin/Senior/federated_gnns_project/build_subgraphs_gnn.ipynb#Y111sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     train_test_batches(graph_data, \u001b[39m10\u001b[39m, dataset, test_data, device, batch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_data' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "def train_test_batches(graph_data, epochs, dataset, test_data, device, batch_size):\n",
    "    model = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    epochs = 10\n",
    "    # Training loop for each epoch (adjust the range as needed)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_batches(graph_data, model, optimizer, criterion, batch_size)  # Assuming 'train' returns a loss\n",
    "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy) \n",
    "\n",
    "    test_loss, test_acc = test(test_data, criterion, model)\n",
    "    \n",
    "    # print(\"Centralized learning test loss: \", test_loss)\n",
    "    print(\"Batch size: \", batch_size)\n",
    "    print(\"Centralized learning test accuracy: \", test_acc)\n",
    "\n",
    "def train_batches(graph_data, model, optimizer, criterion, batch_size):\n",
    "    graph_dataset = [graph_data.x, graph_data.edge_index, graph_data.y]\n",
    "    # print(graph_dataset[0].x.shape)\n",
    "    graph_data_loader = DataLoader(graph_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # print(len(graph_data_loader.dataset))\n",
    "    \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for data in graph_data_loader:\n",
    "      print(data.x.shape)\n",
    "      optimizer.zero_grad() \n",
    "      out = model(data.x, data.edge_index) \n",
    "      loss = criterion(out, data.y)  \n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      total_loss += loss.item()\n",
    "      \n",
    "    return total_loss/len(graph_data_loader)\n",
    "\n",
    "print()\n",
    "batch_sizes = [10, 16, 32]\n",
    "for batch_size in batch_sizes:\n",
    "    train_test_batches(graph_data, 10, dataset, test_data, device, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Social Network\n",
    "\n",
    "### Adam Optimizer, changing learning rates\n",
    "### 1 epoch, 100 communication rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.1\n",
      "mean test accuracy after communication:  0.14613418530351427\n",
      "mean test loss after communication:  4.274308376312256\n",
      "\n",
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.1946964856230031\n",
      "mean test loss after communication:  1.9461461317539215\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.1764536741214057\n",
      "mean test loss after communication:  1.944579039812088\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.16022364217252363\n",
      "mean test loss after communication:  1.9454831516742705\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.11699680511182108\n",
      "mean test loss after communication:  1.9458110272884368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(1, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.2996166134185303\n",
      "mean test loss after communication:  2.341976307630539\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.21172523961661324\n",
      "mean test loss after communication:  1.9647659862041473\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.24108626198083066\n",
      "mean test loss after communication:  1.9449313080310822\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.22539936102236421\n",
      "mean test loss after communication:  1.94551837682724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(5, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses) # print(f\"{mean_test_losses:.4f},{}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.30837060702875396\n",
      "mean test loss after communication:  2.900534151792526\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.23664536741214054\n",
      "mean test loss after communication:  1.9392705142498017\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.20805111821086253\n",
      "mean test loss after communication:  1.9413844859600067\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.20466453674121404\n",
      "mean test loss after communication:  1.945243377685547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(10, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Adam Optimizer, lr = , and varying batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
