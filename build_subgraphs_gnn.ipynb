{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "folder_path = 'client_subgraphs'\n",
    "sub_data_list = []\n",
    "client_number = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.gml'):\n",
    "      \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        g = nx.read_gml(file_path)\n",
    "\n",
    "        subgraph_nodes = list(g.nodes)\n",
    "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "        sub_data_list.append(sub_data)\n",
    "        client_number.append(int(filename.split('.')[0].split('_')[1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'828': ['713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '849', '718', '754', '760', '739', '856', '764', '687', '840', '847', '770', '797', '814', '727', '731', '708', '698', '817', '792', '845', '838', '848', '835', '807', '711', '779', '706', '772', '741', '709', '778', '737', '844', '693'], '713': ['828', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '760', '787', '840', '847', '814', '731', '708', '698', '738', '817', '734', '845', '701', '848', '748', '706', '777', '772', '818', '778', '831', '833', '722', '844', '736', '794', '693'], '705': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '703', '784', '752', '728', '820', '842', '800', '819', '726', '773', '829', '780', '810', '849', '718', '754', '760', '739', '787', '764', '847', '770', '814', '731', '738', '845', '835', '807', '758', '803', '748', '755', '809', '720', '706', '772', '741', '778', '737', '831', '722', '844', '693', '763'], '719': ['828', '713', '705', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '810', '696', '849', '718', '760', '787', '764', '840', '847', '814', '727', '731', '708', '698', '817', '734', '845', '848', '755', '720', '706', '772', '737', '722', '768', '794'], '805': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '703', '695', '815', '752', '728', '842', '800', '819', '774', '726', '766', '829', '780', '810', '696', '718', '754', '760', '739', '764', '687', '840', '847', '814', '727', '731', '738', '817', '792', '734', '838', '807', '706', '772', '709', '818', '737', '831', '844'], '824': ['828', '713', '705', '719', '805', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '819', '774', '726', '773', '766', '829', '780', '696', '849', '754', '760', '739', '764', '840', '847', '770', '727', '708', '792', '838', '848', '835', '779', '777', '709', '737', '844', '693'], '745': ['828', '713', '705', '719', '805', '824', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '829', '810', '696', '718', '760', '787', '847', '814', '731', '698', '738', '817', '845', '758', '711', '755', '720', '706', '795', '737', '722', '794'], '747': ['828', '713', '705', '719', '805', '745', '823', '830', '697', '688', '703', '815', '752', '728', '820', '800', '819', '774', '773', '780', '810', '696', '849', '718', '754', '739', '856', '764', '687', '840', '770', '797', '708', '698', '792', '838', '701', '848', '807', '793', '758', '803', '748', '783', '809', '741', '831', '730', '763', '765'], '823': ['828', '713', '705', '719', '805', '824', '745', '747', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '815', '752', '728', '820', '800', '819', '774', '726', '773', '766', '780', '810', '696', '718', '754', '760', '739', '787', '856', '764', '687', '840', '708', '698', '792', '838', '848', '835', '807', '779', '741', '709', '693', '765'], '694': ['828', '713', '705', '719', '805', '824', '745', '823', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '780', '810', '696', '754', '760', '847', '727', '731', '738', '845', '848', '711', '706', '795', '772', '737', '831', '722'], '830': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '695', '815', '752', '820', '800', '819', '774', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '847', '727', '731', '817', '792', '845', '838', '701', '748', '777', '709', '778', '737', '844'], '781': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '697', '724', '827', '853', '834', '703', '695', '784', '815', '752', '728', '842', '800', '726', '773', '829', '810', '849', '718', '760', '787', '764', '770', '814', '731', '708', '738', '817', '701', '793', '758', '755', '783', '809', '720', '772', '741', '794'], '697': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '834', '695', '815', '820', '842', '800', '819', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '727', '731', '708', '698', '701', '848', '835', '748', '777', '772', '709', '818', '844', '693', '765'], '724': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '827', '688', '853', '834', '695', '784', '752', '820', '842', '819', '726', '773', '766', '829', '696', '754', '760', '814', '731', '708', '738', '734', '701', '848', '711', '795', '777', '778', '736', '794'], '827': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '853', '834', '703', '784', '752', '842', '800', '819', '773', '766', '810', '849', '718', '760', '787', '764', '797', '814', '731', '708', '817', '758', '755', '783', '809', '772', '741'], '688': ['828', '713', '719', '805', '824', '747', '823', '694', '830', '697', '724', '853', '834', '695', '815', '752', '800', '819', '774', '726', '766', '780', '696', '849', '754', '739', '856', '687', '840', '847', '770', '727', '792', '734', '845', '701', '777', '772', '771'], '853': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '724', '827', '688', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '810', '696', '847', '814', '727', '731', '738', '734', '711', '706', '795', '831', '722'], '834': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '695', '784', '815', '752', '820', '842', '800', '819', '726', '773', '766', '829', '780', '810', '696', '718', '760', '847', '814', '731', '701', '706', '778', '844', '693'], '703': ['828', '705', '719', '805', '824', '747', '823', '694', '781', '827', '815', '728', '820', '819', '718', '754', '739', '787', '856', '764', '687', '797', '698', '817', '792', '845', '838', '835', '807', '793', '758', '748', '779', '809', '741', '709', '831', '730', '765'], '695': ['713', '719', '805', '824', '745', '694', '830', '781', '697', '724', '688', '853', '834', '784', '815', '752', '842', '726', '766', '829', '780', '810', '696', '718', '754', '760', '840', '847', '738', '734', '701', '711', '706', '777', '778', '844', '794', '693'], '784': ['828', '713', '705', '719', '824', '745', '694', '781', '724', '827', '853', '834', '695', '752', '842', '800', '774', '726', '773', '766', '829', '810', '696', '760', '727', '731', '738', '734', '711', '706', '795', '722', '794'], '815': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '688', '853', '834', '703', '695', '752', '819', '726', '773', '766', '780', '810', '718', '754', '856', '847', '731', '792', '845', '838', '835', '706', '737'], '752': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '853', '834', '695', '784', '815', '820', '842', '800', '774', '726', '773', '766', '829', '810', '847', '727', '731', '738', '711', '706', '831'], '728': ['828', '705', '719', '805', '824', '747', '823', '781', '703', '820', '819', '774', '773', '780', '754', '739', '787', '856', '764', '687', '797', '817', '792', '838', '835', '807', '803', '783', '779', '809', '741', '737', '730', '765'], '820': ['828', '705', '719', '824', '745', '747', '823', '694', '830', '697', '724', '853', '834', '703', '752', '728', '774', '726', '773', '766', '849', '760', '687', '770', '797', '845', '848', '803', '783', '795', '741', '737', '831', '722', '763'], '842': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '697', '724', '827', '853', '834', '695', '784', '752', '800', '773', '829', '810', '696', '760', '814', '727', '738', '734', '701', '711', '795', '794'], '800': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '830', '781', '697', '827', '688', '853', '834', '784', '752', '842', '774', '766', '810', '760', '856', '814', '727', '708', '698', '845', '772', '741'], '819': ['828', '713', '705', '719', '805', '824', '747', '823', '830', '697', '724', '827', '688', '834', '703', '815', '728', '774', '780', '739', '856', '687', '840', '708', '698', '817', '792', '838', '848', '835', '807', '709', '778'], '774': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '688', '853', '784', '752', '728', '820', '800', '819', '773', '810', '696', '739', '856', '687', '840', '731', '708', '698', '738', '701', '807', '720'], '726': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '688', '853', '834', '695', '784', '815', '752', '820', '773', '766', '780', '754', '760', '731', '845', '701', '778', '844', '693'], '773': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '724', '827', '853', '834', '784', '815', '752', '728', '820', '842', '774', '726', '829', '780', '810', '696', '754', '847', '731', '706', '737', '831'], '766': ['828', '713', '719', '805', '824', '823', '694', '830', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '820', '800', '726', '780', '810', '849', '760', '847', '727', '731', '734', '711', '771'], '829': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '724', '853', '834', '695', '784', '752', '842', '773', '696', '760', '847', '814', '738', '734', '711', '795', '777', '822', '722'], '780': ['828', '713', '705', '805', '824', '747', '823', '694', '830', '697', '688', '834', '695', '815', '728', '819', '726', '773', '766', '696', '754', '739', '687', '840', '792', '845', '838', '701', '835', '803', '779', '777', '765'], '810': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '781', '827', '853', '834', '695', '784', '815', '752', '842', '800', '774', '773', '766', '856', '847', '814', '731', '698', '711', '706'], '696': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '697', '724', '688', '853', '834', '695', '784', '842', '774', '773', '829', '780', '739', '840', '727', '738', '845', '711', '795', '778'], '849': ['828', '705', '719', '824', '747', '830', '781', '697', '827', '688', '820', '766', '787', '770', '797', '727', '708', '734', '845', '793', '758', '748', '755', '783', '730', '763'], '718': ['828', '705', '719', '805', '745', '747', '823', '781', '827', '834', '703', '695', '815', '787', '764', '687', '770', '797', '814', '817', '793', '758', '803', '748', '809', '720', '730'], '754': ['828', '705', '805', '824', '747', '823', '694', '830', '697', '724', '688', '703', '695', '815', '728', '726', '773', '780', '739', '840', '792', '838', '701', '848', '835', '779', '777', '709'], '760': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '834', '695', '784', '820', '842', '800', '726', '766', '829', '814', '708', '738', '734', '701', '794'], '739': ['828', '705', '805', '824', '747', '823', '688', '703', '728', '819', '774', '780', '696', '754', '787', '764', '687', '840', '797', '792', '807', '793', '758', '720', '777', '709'], '787': ['713', '705', '719', '745', '823', '781', '827', '703', '728', '849', '718', '739', '764', '797', '814', '817', '793', '758', '803', '748', '755', '783', '809', '720', '730', '763'], '856': ['828', '747', '823', '830', '697', '688', '703', '815', '728', '800', '819', '774', '810', '687', '840', '708', '698', '838', '807', '772', '765'], '764': ['828', '705', '719', '805', '824', '747', '823', '781', '827', '703', '728', '718', '739', '787', '687', '797', '817', '838', '807', '793', '748', '783', '779', '809', '720', '730'], '687': ['828', '805', '747', '823', '830', '697', '688', '703', '728', '820', '819', '774', '780', '718', '739', '856', '764', '797', '817', '838', '807', '783', '779', '777', '730', '765'], '840': ['828', '713', '719', '805', '824', '747', '823', '830', '697', '688', '695', '819', '774', '780', '696', '754', '739', '856', '708', '698', '838', '848', '803', '779', '709'], '847': ['828', '713', '705', '719', '805', '824', '745', '694', '830', '688', '853', '834', '695', '815', '752', '773', '766', '829', '810', '727', '731', '734', '711', '706'], '770': ['828', '705', '824', '747', '781', '688', '820', '849', '718', '797', '727', '734', '845', '803', '748', '783', '777', '772', '741', '763'], '797': ['828', '747', '827', '703', '728', '820', '849', '718', '739', '787', '764', '687', '770', '708', '817', '793', '748', '755', '783', '809', '831', '730', '763'], '814': ['828', '713', '705', '719', '805', '745', '781', '724', '827', '853', '834', '842', '800', '829', '810', '718', '760', '787', '708', '758', '755', '772'], '727': ['828', '719', '805', '824', '694', '830', '697', '688', '853', '784', '752', '842', '800', '766', '696', '849', '847', '770', '845', '848', '711'], '731': ['828', '713', '705', '719', '805', '745', '694', '830', '781', '697', '724', '827', '853', '834', '784', '815', '752', '774', '726', '773', '766', '810', '847', '706'], '708': ['828', '713', '719', '824', '747', '823', '781', '697', '724', '827', '800', '819', '774', '849', '760', '856', '840', '797', '814', '755', '730'], '698': ['828', '713', '719', '745', '747', '823', '697', '703', '800', '819', '774', '810', '856', '840', '803', '772'], '738': ['713', '705', '805', '745', '694', '781', '724', '853', '695', '784', '752', '842', '774', '829', '696', '760', '711', '795', '722', '794'], '817': ['828', '713', '719', '805', '745', '830', '781', '827', '703', '728', '819', '718', '787', '764', '687', '797', '793', '758', '748', '783', '809'], '792': ['828', '805', '824', '747', '823', '830', '688', '703', '815', '728', '819', '780', '754', '739', '838', '835', '807', '803', '779', '765'], '734': ['713', '719', '805', '724', '688', '853', '695', '784', '842', '766', '829', '849', '760', '847', '770', '803', '778', '693'], '845': ['828', '713', '705', '719', '745', '694', '830', '688', '703', '815', '820', '800', '726', '780', '696', '849', '770', '727', '701', '755', '772'], '838': ['828', '805', '824', '747', '823', '830', '703', '815', '728', '819', '780', '754', '856', '764', '687', '840', '792', '835', '807', '779', '709'], '701': ['713', '747', '830', '781', '697', '724', '688', '834', '695', '842', '774', '726', '780', '754', '760', '845', '777', '778', '794'], '848': ['828', '713', '719', '824', '747', '823', '694', '697', '724', '820', '819', '754', '840', '727', '709', '844'], '835': ['828', '705', '824', '823', '697', '703', '815', '728', '819', '780', '754', '792', '838', '779', '741', '709', '765'], '807': ['828', '705', '805', '747', '823', '703', '728', '819', '774', '739', '856', '764', '687', '792', '838', '779', '741', '765'], '793': ['747', '781', '703', '849', '718', '739', '787', '764', '797', '817', '758', '748', '755', '783', '809', '720'], '758': ['705', '745', '747', '781', '827', '703', '849', '718', '739', '787', '814', '817', '793', '748', '755', '783', '809'], '711': ['828', '745', '694', '724', '853', '695', '784', '752', '842', '766', '829', '810', '696', '847', '727', '738', '795', '722'], '803': ['705', '747', '728', '820', '780', '718', '787', '840', '770', '698', '792', '734', '720', '730', '763'], '748': ['713', '705', '747', '830', '697', '703', '849', '718', '787', '764', '770', '797', '817', '793', '758', '779', '831'], '755': ['705', '719', '745', '781', '827', '849', '787', '797', '814', '708', '845', '793', '758', '783', '809', '720'], '783': ['747', '781', '827', '728', '820', '849', '787', '764', '687', '770', '797', '817', '793', '758', '755', '809', '730'], '779': ['828', '824', '823', '703', '728', '780', '754', '764', '687', '840', '792', '838', '835', '807', '748', '777', '765'], '809': ['705', '747', '781', '827', '703', '728', '718', '787', '764', '797', '817', '793', '758', '755', '783', '720'], '720': ['705', '719', '745', '781', '774', '718', '739', '787', '764', '793', '803', '755', '809', '730'], '706': ['828', '713', '705', '719', '805', '745', '694', '853', '834', '695', '784', '815', '752', '773', '810', '847', '731'], '795': ['745', '694', '724', '853', '784', '820', '842', '829', '696', '738', '711', '794'], '777': ['713', '824', '830', '697', '724', '688', '695', '829', '780', '754', '739', '687', '770', '701', '779', '709'], '772': ['828', '713', '705', '719', '805', '694', '781', '697', '827', '688', '800', '856', '770', '814', '698', '845'], '741': ['828', '705', '747', '823', '781', '827', '703', '728', '820', '800', '770', '835', '807', '763'], '709': ['828', '805', '824', '823', '830', '697', '703', '819', '754', '739', '840', '838', '848', '835', '777'], '818': ['713', '805', '697', '822', '806', '839', '771', '732', '736', '714'], '778': ['828', '713', '705', '830', '724', '834', '695', '819', '726', '696', '734', '701', '844', '693'], '737': ['828', '705', '719', '805', '824', '745', '694', '830', '815', '728', '820', '773', '722'], '831': ['713', '705', '805', '747', '694', '853', '703', '752', '820', '773', '797', '748'], '833': ['713', '806', '768', '736'], '822': ['829', '818', '806', '839', '768', '732', '714'], '806': ['818', '833', '822', '839', '771', '732', '714'], '730': ['747', '703', '728', '849', '718', '787', '764', '687', '797', '708', '803', '783', '720', '763'], '839': ['818', '822', '806', '771', '768', '732', '714'], '771': ['688', '766', '818', '806', '839', '732', '714'], '722': ['713', '705', '719', '745', '694', '853', '784', '820', '829', '738', '711', '737', '768'], '844': ['828', '713', '705', '805', '824', '830', '697', '834', '695', '726', '848', '778', '693'], '768': ['719', '833', '822', '839', '722'], '732': ['818', '822', '806', '839', '771', '714'], '736': ['713', '724', '818', '833'], '794': ['713', '719', '745', '781', '724', '695', '784', '842', '760', '738', '701', '795'], '693': ['828', '713', '705', '824', '823', '697', '834', '695', '726', '734', '778', '844'], '763': ['705', '747', '820', '849', '787', '770', '797', '803', '741', '730'], '765': ['747', '823', '697', '703', '728', '780', '856', '687', '792', '835', '807', '779'], '714': ['818', '822', '806', '839', '771', '732']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.read_gml('new_facebook_network.gml')\n",
    "neighbors = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors[node] = list(g.neighbors(node))\n",
    "\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new_facebook_network.gml and create a fully connected graph\n",
    "\n",
    "neighbors_fully_connected = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors_fully_connected[node] = list(g.nodes)\n",
    "    neighbors_fully_connected[node].remove(node)\n",
    "\n",
    "    \n",
    "# print(neighbors_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[18, 1433], edge_index=[2, 58], y=[18])\n",
      "torch.Size([18, 1433])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(sub_data_list[0])\n",
    "print(sub_data_list[0].x.shape)\n",
    "print(type(client_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a  list of training and validation loss per epoch for each subgraph\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def transductive_split(data, train_percent=0.8, val_percent=0.1):\n",
    "    \"\"\"\n",
    "    Split graph data into training, validation, and testing sets for transductive learning.\n",
    "    :param data: PyG Data object\n",
    "    :param train_percent: Percentage of nodes to be used for training\n",
    "    :param val_percent: Percentage of nodes to be used for validation\n",
    "    :return: data object with train_mask, val_mask, and test_mask attributes added\n",
    "    \"\"\"\n",
    "    # set a seed for reproducibility\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    train_size = int(train_percent * num_nodes)\n",
    "    val_size = int(val_percent * num_nodes)\n",
    "\n",
    "    # Create a random permutation of node indices\n",
    "    perm = torch.randperm(num_nodes)\n",
    "\n",
    "    # Create masks for training, validation, and testing nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[perm[:train_size]] = True\n",
    "    val_mask[perm[train_size:train_size + val_size]] = True\n",
    "    test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "    # Add masks to data object\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# splitting the subgraphs into train test and val \n",
    "for i in range(0, 100):\n",
    "    sub_data = sub_data_list[i]\n",
    "    sub_data = transductive_split(sub_data)\n",
    "\n",
    "\n",
    "print(torch.sum(sub_data_list[4].train_mask).item())  # Number of training nodes\n",
    "print(torch.sum(sub_data_list[4].val_mask).item())    # Number of validation nodes\n",
    "print(torch.sum(sub_data_list[4].test_mask).item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training) # p = 0.25\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots(10, 10, figsize=(50, 50))\n",
    "\n",
    "def train(sub_data, model, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[sub_data.train_mask], sub_data.y[sub_data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      return loss\n",
    "\n",
    "def test(sub_data, criterion, model):\n",
    "      model.eval()\n",
    "      out = model(sub_data.x, sub_data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[sub_data.test_mask] == sub_data.y[sub_data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(sub_data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      test_loss = criterion(out[sub_data.test_mask], sub_data.y[sub_data.test_mask])  # Compute validation loss\n",
    "      \n",
    "      return test_loss, test_acc\n",
    "\n",
    "\n",
    "def validate(sub_data, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Do not compute gradients during this step\n",
    "        out = model(sub_data.x, sub_data.edge_index)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get predicted classes\n",
    "        val_correct = pred[sub_data.val_mask] == sub_data.y[sub_data.val_mask]  # Compare with ground-truth\n",
    "        val_loss = criterion(out[sub_data.val_mask], sub_data.y[sub_data.val_mask])  # Compute validation loss\n",
    "        val_acc = int(val_correct.sum()) / int(sub_data.val_mask.sum())  # Compute validation accuracy\n",
    "    return val_loss.item(), val_acc  # Return validation loss and accuracy\n",
    "\n",
    "\n",
    "def initial_training(epochs):\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    dictionary_t_1 = {}\n",
    "    dictionary_t = {}\n",
    "\n",
    "    for i in range(len(sub_data_list)):\n",
    "        sub_data = sub_data_list[i]\n",
    "        \n",
    "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_losses = [] \n",
    "        val_losses = []    \n",
    "\n",
    "        # Training loop for each epoch (adjust the range as needed)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "            val_loss, _ = validate(sub_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "        \n",
    "        test_loss, test_acc = test(sub_data, criterion, model)\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accs.append(test_acc)\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "\n",
    "        model_weights = model.state_dict()\n",
    "        client_number_num = client_number[i]\n",
    "        dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return dictionary_t_1, test_losses, test_accs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7417732518678531\n",
      "mean test accuracy before communication:  0.7801666666666668\n"
     ]
    }
   ],
   "source": [
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "\n",
    "# average test loss and accuracy before communication \n",
    "\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
    "    for k in global_model.keys():\n",
    "        global_model[k] = torch.stack([model[k].float() for model in models], 0).mean(0)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communication(dictionary_t_1_og, neighbors, epochs, rounds):\n",
    "    # make a copy of dictionary_t_1\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
    "    dictionary_t = {}\n",
    "    for k in range(1, rounds + 1):\n",
    "\n",
    "    # get the neighbprs of each client\n",
    "        for i in range(len(sub_data_list)):\n",
    "            sub_data = sub_data_list[i]\n",
    "            \n",
    "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_losses = [] \n",
    "            val_losses = []    \n",
    "\n",
    "            # Training loop for each epoch (adjust the range as needed)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "                val_loss, _ = validate(sub_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "            \n",
    "            test_loss, test_acc = test(sub_data, criterion, model)\n",
    "            if k == rounds:\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        \n",
    "            # add the model weights to the t -1 dictionary\n",
    "            model_weights = model.state_dict()\n",
    "            client_number_num = client_number[i]\n",
    "            dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "\n",
    "        for i in range(100):\n",
    "            client_number_num = client_number[i]\n",
    "            # go through neighbors of client_number\n",
    "            string_client_num = str(client_number_num)\n",
    "            client_neighbors = neighbors[string_client_num]\n",
    "            \n",
    "            neighbors_state_dicts = []\n",
    "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
    "            for j in range(len(client_neighbors)):\n",
    "                # get model weights of neighbor\n",
    "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
    "                neighbors_state_dicts.append(neighbor_model)\n",
    "            \n",
    "            #call fed_avg\n",
    "            average_state_dict = {}\n",
    "            average_state_dict = fed_avg(neighbors_state_dicts)\n",
    "            # average weights of client and neighbors\n",
    "            # average_state_dict = {}\n",
    "            # for param in neighbors_state_dicts[0]:\n",
    "            #     # num parameters\n",
    "            #     num_neighbors = len(neighbors_state_dicts)\n",
    "            #     sum_param = 0\n",
    "            #     for neighbor in range(num_neighbors):\n",
    "            #         sum_param += neighbors_state_dicts[neighbor][param]\n",
    "            #     average_param = sum_param / num_neighbors\n",
    "            #     average_state_dict[param] = average_param\n",
    "                \n",
    "                \n",
    "            dictionary_t[client_number_num] = average_state_dict    \n",
    "            \n",
    "        dictionary_t_1 = dictionary_t\n",
    "\n",
    "    return test_losses, test_accs\n",
    " \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss after communication:  0.786219062373566\n",
      "mean test accuracy after communication:  0.7576666666666668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "\n",
    "# average test loss and accuracy after communication\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "\n",
    "#mean of test_accs\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmoUlEQVR4nO3dfVjUdb7/8RcIDBTMIHJfmOhmmHdd4VHJzNWliMpjidlWx8x0rUQ35WytnrbQ2sRjbVq7aluZbufSdRc3PcfqaEbeZIEp6lnLck0xLQJvSkBcboTP749+zDYBm4PwwaHn47rmuuI73/nOez6i8+w7M+BnjDECAACwxL+9BwAAAD8sxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAfMfmzZvl5+enzZs3t/coQIdEfADtwM/P75wurfHkd+bMGc2ePZsnUgAXjID2HgD4Ifqv//ovj69fffVVbdy4sdH2Xr16nfd9nTlzRnPmzJEk/fjHPz7v4/0QXHfddfr73/+uoKCg9h4F6JCID6Ad/Nu//ZvH1wUFBdq4cWOj7fh+lZWVuvjii1v1mP7+/goODm7VYwL4B152AS5Q9fX1WrhwoXr37q3g4GDFxMTo/vvv19dff+2x386dO5WWlqbIyEiFhIQoMTFR9913nyTp8OHDioqKkiTNmTPH/XLO7Nmzm73fr776Sr/4xS/Ut29fhYaGyul0Kj09Xf/3f//XaN+qqirNnj1bPXv2VHBwsOLi4jR69GgdPHjQ43E899xz6tu3r4KDgxUVFaUbb7xRO3fudM/o5+en5cuXNzr+d2edPXu2/Pz8tG/fPt11113q3Lmzrr32WknSX//6V917773q3r27goODFRsbq/vuu08nT55sdNwvvvhCEydOVHx8vBwOhxITE/Xggw+qpqZGUvPv+di+fbtuvPFGuVwuXXTRRRo2bJjee+89j30qKio0ffp0devWTQ6HQ9HR0br++uu1a9euZtcc+KHhzAdwgbr//vu1fPlyTZgwQT//+c9VVFSk3/3ud9q9e7fee+89BQYG6tixY7rhhhsUFRWlmTNnKjw8XIcPH9Zrr70mSYqKitKSJUv04IMP6rbbbtPo0aMlSf369Wv2fg8dOqS1a9fq9ttvV2JiokpLS/X73/9ew4YN0759+xQfHy9Jqqur0y233KK8vDz99Kc/1UMPPaSKigpt3LhRH374oXr06CFJmjhxopYvX6709HRNmjRJZ8+e1bvvvquCggINGDCgRWtz++236/LLL9fcuXNljJEkbdy4UYcOHdKECRMUGxurjz76SC+++KI++ugjFRQUyM/PT5JUXFysgQMH6tSpU5o8ebKSkpL0xRdfaPXq1Tpz5kyzL7W88847Sk9PV3JysrKzs+Xv769ly5ZpxIgRevfddzVw4EBJ0gMPPKDVq1dr6tSpuvLKK3Xy5Elt27ZNH3/8sa6++uoWPV6gwzEA2l1mZqb59l/Hd99910gyK1as8Nhv/fr1HtvXrFljJJkdO3Y0e+zjx48bSSY7O/ucZqmqqjJ1dXUe24qKiozD4TBPPPGEe9srr7xiJJlnn3220THq6+uNMca88847RpL5+c9/3uw+RUVFRpJZtmxZo32+O3d2draRZO68885G+545c6bRtj/+8Y9Gktm6dat72z333GP8/f2bXLOGmTZt2mQkmU2bNrm3X3755SYtLc29T8N9JiYmmuuvv969zeVymczMzEbHBvAPvOwCXIByc3Plcrl0/fXX68SJE+5LcnKyQkNDtWnTJklSeHi4JOn1119XbW1tq9y3w+GQv/83/zTU1dXp5MmTCg0N1RVXXOHx0sFf/vIXRUZGatq0aY2O0XCW4S9/+Yv8/PyUnZ3d7D4t8cADDzTaFhIS4v7vqqoqnThxQoMHD5Yk99z19fVau3atRo4c2eRZl+Zm2rNnjw4cOKC77rpLJ0+edP95VFZW6ic/+Ym2bt2q+vp6Sd/8mWzfvl3FxcUtfnxAR0d8ABegAwcOqKysTNHR0YqKivK4nD59WseOHZMkDRs2TBkZGZozZ44iIyM1atQoLVu2TNXV1S2+7/r6ei1YsECXX365HA6HIiMjFRUVpb/+9a8qKytz73fw4EFdccUVCgho/tXbgwcPKj4+XhERES2epymJiYmNtn311Vd66KGHFBMTo5CQEEVFRbn3a5j7+PHjKi8vV58+fby6vwMHDkiSxo8f3+jP4+WXX1Z1dbX7PubPn68PP/xQCQkJGjhwoGbPnq1Dhw6dz8MFOhze8wFcgOrr6xUdHa0VK1Y0eX3Dm0j9/Py0evVqFRQUaN26ddqwYYPuu+8+/eY3v1FBQYFCQ0O9vu+5c+fqscce03333acnn3xSERER8vf31/Tp093/d9+amjvbUFdX1+xtvn2Wo8HYsWP1/vvv6+GHH9ZVV12l0NBQ1dfX68YbbzzvuRtu//TTT+uqq65qcp+GtR47dqyGDh2qNWvW6K233tLTTz+t//zP/9Rrr72m9PT085oD6CiID+AC1KNHD7399tsaMmRIk0+03zV48GANHjxYTz31lFauXKm7775bq1at0qRJk7x+eWP16tUaPny4li5d6rH91KlTioyM9Jhx+/btqq2tVWBgYLOPY8OGDfrqq6+aPfvRuXNn9/G/7bPPPjvnmb/++mvl5eVpzpw5evzxx93bG85YNIiKipLT6dSHH354zseW5H7zrNPpVGpq6vfuHxcXpylTpmjKlCk6duyYrr76aj311FPEB/D/8bILcAEaO3as6urq9OSTTza67uzZs+4n6q+//tr9aY8GDf9n3vDSy0UXXSSp8ZN7czp16tTomLm5ufriiy88tmVkZOjEiRP63e9+1+gYDbfPyMiQMcb9Q86a2sfpdCoyMlJbt271uH7x4sXnNG/DzN8+ZoOFCxd6fO3v769bb71V69atc3/Ut6mZvis5OVk9evTQM888o9OnTze6/vjx45K+OVvz7ZemJCk6Olrx8fHn9VIY0NFw5gO4AA0bNkz333+/cnJytGfPHt1www0KDAzUgQMHlJubq+eee05jxozRH/7wBy1evFi33XabevTooYqKCr300ktyOp266aabJH3zEsWVV16pP/3pT+rZs6ciIiLUp0+fZt/3cMstt+iJJ57QhAkTdM0112jv3r1asWKFunfv7rHfPffco1dffVVZWVn64IMPNHToUFVWVurtt9/WlClTNGrUKA0fPlzjxo3T888/rwMHDrhfAnn33Xc1fPhwTZ06VZI0adIkzZs3T5MmTdKAAQO0detW/e1vfzvn9XI6nbruuus0f/581dbW6pJLLtFbb72loqKiRvvOnTtXb731loYNG6bJkyerV69e+vLLL5Wbm6tt27a538T7bf7+/nr55ZeVnp6u3r17a8KECbrkkkv0xRdfaNOmTXI6nVq3bp0qKip06aWXasyYMerfv79CQ0P19ttva8eOHfrNb35zzo8H6PDa8ZM2AP6/737UtsGLL75okpOTTUhIiAkLCzN9+/Y1jzzyiCkuLjbGGLNr1y5z5513mq5duxqHw2Gio6PNLbfcYnbu3OlxnPfff98kJyeboKCg7/3YbVVVlfn3f/93ExcXZ0JCQsyQIUNMfn6+GTZsmBk2bJjHvmfOnDGPPvqoSUxMNIGBgSY2NtaMGTPGHDx40L3P2bNnzdNPP22SkpJMUFCQiYqKMunp6aawsNDjOBMnTjQul8uEhYWZsWPHmmPHjjX7Udvjx483mvvzzz83t912mwkPDzcul8vcfvvtpri4uMnH+9lnn5l77rnHREVFGYfDYbp3724yMzNNdXW1MabxR20b7N6924wePdp06dLFOBwOc9lll5mxY8eavLw8Y4wx1dXV5uGHHzb9+/c3YWFh5uKLLzb9+/c3ixcvbna9gR8iP2OaOc8IAADQBnjPBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGDVBfdDxurr61VcXKywsLDz+q2XAADAHmOMKioqFB8f7/7N2M254OKjuLhYCQkJ7T0GAABogaNHj+rSSy/9p/tccPERFhYm6ZvhnU5nO08DAADORXl5uRISEtzP4//MBRcfDS+1OJ1O4gMAAB9zLm+Z4A2nAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFUB7T0AAAC+rNvMN9p7BK8dnndzu94/Zz4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABglVfxMXv2bPn5+XlckpKS3NdXVVUpMzNTXbp0UWhoqDIyMlRaWtrqQwMAAN/l9ZmP3r1768svv3Rftm3b5r5uxowZWrdunXJzc7VlyxYVFxdr9OjRrTowAADwbQFe3yAgQLGxsY22l5WVaenSpVq5cqVGjBghSVq2bJl69eqlgoICDR48+PynBQAAPs/rMx8HDhxQfHy8unfvrrvvvltHjhyRJBUWFqq2tlapqanufZOSktS1a1fl5+c3e7zq6mqVl5d7XAAAQMflVXwMGjRIy5cv1/r167VkyRIVFRVp6NChqqioUElJiYKCghQeHu5xm5iYGJWUlDR7zJycHLlcLvclISGhRQ8EAAD4Bq9edklPT3f/d79+/TRo0CBddtll+vOf/6yQkJAWDTBr1ixlZWW5vy4vLydAAADowM7ro7bh4eHq2bOnPv30U8XGxqqmpkanTp3y2Ke0tLTJ94g0cDgccjqdHhcAANBxnVd8nD59WgcPHlRcXJySk5MVGBiovLw89/X79+/XkSNHlJKSct6DAgCAjsGrl11+8YtfaOTIkbrssstUXFys7OxsderUSXfeeadcLpcmTpyorKwsRUREyOl0atq0aUpJSeGTLgAAwM2r+Pj8889155136uTJk4qKitK1116rgoICRUVFSZIWLFggf39/ZWRkqLq6WmlpaVq8eHGbDA4AAHyTnzHGtPcQ31ZeXi6Xy6WysjLe/wEAuOB1m/lGe4/gtcPzbm71Y3rz/M3vdgEAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwKrzio958+bJz89P06dPd2+rqqpSZmamunTpotDQUGVkZKi0tPR85wQAAB1Ei+Njx44d+v3vf69+/fp5bJ8xY4bWrVun3NxcbdmyRcXFxRo9evR5DwoAADqGFsXH6dOndffdd+ull15S586d3dvLysq0dOlSPfvssxoxYoSSk5O1bNkyvf/++yooKGi1oQEAgO9qUXxkZmbq5ptvVmpqqsf2wsJC1dbWemxPSkpS165dlZ+f3+SxqqurVV5e7nEBAAAdV4C3N1i1apV27dqlHTt2NLqupKREQUFBCg8P99geExOjkpKSJo+Xk5OjOXPmeDsGAADwUV6d+Th69KgeeughrVixQsHBwa0ywKxZs1RWVua+HD16tFWOCwAALkxexUdhYaGOHTumq6++WgEBAQoICNCWLVv0/PPPKyAgQDExMaqpqdGpU6c8bldaWqrY2Ngmj+lwOOR0Oj0uAACg4/LqZZef/OQn2rt3r8e2CRMmKCkpSb/85S+VkJCgwMBA5eXlKSMjQ5K0f/9+HTlyRCkpKa03NQAA8FlexUdYWJj69Onjse3iiy9Wly5d3NsnTpyorKwsRUREyOl0atq0aUpJSdHgwYNbb2oAAOCzvH7D6fdZsGCB/P39lZGRoerqaqWlpWnx4sWtfTcAAMBH+RljTHsP8W3l5eVyuVwqKyvj/R8AgAtet5lvtPcIXjs87+ZWP6Y3z9/8bhcAAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVexceSJUvUr18/OZ1OOZ1OpaSk6H//93/d11dVVSkzM1NdunRRaGioMjIyVFpa2upDAwAA3+VVfFx66aWaN2+eCgsLtXPnTo0YMUKjRo3SRx99JEmaMWOG1q1bp9zcXG3ZskXFxcUaPXp0mwwOAAB8k58xxpzPASIiIvT0009rzJgxioqK0sqVKzVmzBhJ0ieffKJevXopPz9fgwcPPqfjlZeXy+VyqaysTE6n83xGAwCgzXWb+UZ7j+C1w/NubvVjevP83eL3fNTV1WnVqlWqrKxUSkqKCgsLVVtbq9TUVPc+SUlJ6tq1q/Lz85s9TnV1tcrLyz0uAACg4/I6Pvbu3avQ0FA5HA498MADWrNmja688kqVlJQoKChI4eHhHvvHxMSopKSk2ePl5OTI5XK5LwkJCV4/CAAA4Du8jo8rrrhCe/bs0fbt2/Xggw9q/Pjx2rdvX4sHmDVrlsrKytyXo0ePtvhYAADgwhfg7Q2CgoL0ox/9SJKUnJysHTt26LnnntMdd9yhmpoanTp1yuPsR2lpqWJjY5s9nsPhkMPh8H5yAADgk87753zU19erurpaycnJCgwMVF5envu6/fv368iRI0pJSTnfuwEAAB2EV2c+Zs2apfT0dHXt2lUVFRVauXKlNm/erA0bNsjlcmnixInKyspSRESEnE6npk2bppSUlHP+pAsAAOj4vIqPY8eO6Z577tGXX34pl8ulfv36acOGDbr++uslSQsWLJC/v78yMjJUXV2ttLQ0LV68uE0GBwAAvum8f85Ha+PnfAAAfAk/5+MbVn7OBwAAQEsQHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWOVVfOTk5Ohf/uVfFBYWpujoaN16663av3+/xz5VVVXKzMxUly5dFBoaqoyMDJWWlrbq0AAAwHd5FR9btmxRZmamCgoKtHHjRtXW1uqGG25QZWWle58ZM2Zo3bp1ys3N1ZYtW1RcXKzRo0e3+uAAAMA3BXiz8/r16z2+Xr58uaKjo1VYWKjrrrtOZWVlWrp0qVauXKkRI0ZIkpYtW6ZevXqpoKBAgwcPbr3JAQCATzqv93yUlZVJkiIiIiRJhYWFqq2tVWpqqnufpKQkde3aVfn5+U0eo7q6WuXl5R4XAADQcbU4Purr6zV9+nQNGTJEffr0kSSVlJQoKChI4eHhHvvGxMSopKSkyePk5OTI5XK5LwkJCS0dCQAA+IAWx0dmZqY+/PBDrVq16rwGmDVrlsrKytyXo0ePntfxAADAhc2r93w0mDp1ql5//XVt3bpVl156qXt7bGysampqdOrUKY+zH6WlpYqNjW3yWA6HQw6HoyVjAAAAH+TVmQ9jjKZOnao1a9bonXfeUWJiosf1ycnJCgwMVF5ennvb/v37deTIEaWkpLTOxAAAwKd5deYjMzNTK1eu1H//938rLCzM/T4Ol8ulkJAQuVwuTZw4UVlZWYqIiJDT6dS0adOUkpLCJ10AAIAkL+NjyZIlkqQf//jHHtuXLVume++9V5K0YMEC+fv7KyMjQ9XV1UpLS9PixYtbZVgAAOD7vIoPY8z37hMcHKxFixZp0aJFLR4KAAB0XPxuFwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMCqgPYeAMAPS7eZb7T3CF47PO/m9h4B6FA48wEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVnkdH1u3btXIkSMVHx8vPz8/rV271uN6Y4wef/xxxcXFKSQkRKmpqTpw4EBrzQsAAHyc1/FRWVmp/v37a9GiRU1eP3/+fD3//PN64YUXtH37dl188cVKS0tTVVXVeQ8LAAB8X4C3N0hPT1d6enqT1xljtHDhQv3qV7/SqFGjJEmvvvqqYmJitHbtWv30pz89v2kBAIDPa9X3fBQVFamkpESpqanubS6XS4MGDVJ+fn6Tt6murlZ5ebnHBQAAdFytGh8lJSWSpJiYGI/tMTEx7uu+KycnRy6Xy31JSEhozZEAAMAFpt0/7TJr1iyVlZW5L0ePHm3vkQAAQBtq1fiIjY2VJJWWlnpsLy0tdV/3XQ6HQ06n0+MCAAA6rlaNj8TERMXGxiovL8+9rby8XNu3b1dKSkpr3hUAAPBRXn/a5fTp0/r000/dXxcVFWnPnj2KiIhQ165dNX36dP3617/W5ZdfrsTERD322GOKj4/Xrbfe2ppzAwAAH+V1fOzcuVPDhw93f52VlSVJGj9+vJYvX65HHnlElZWVmjx5sk6dOqVrr71W69evV3BwcOtNDQAAfJafMca09xDfVl5eLpfLpbKyMt7/AXRA3Wa+0d4j/GAcnndze4/wg+CL39Nt8b3hzfN3u3/aBQAA/LAQHwAAwCriAwAAWEV8AAAAq4gPAABgldcftfV1vCsZAID2xZkPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAqwLaewDgQtFt5hvtPYLXDs+7ub1HAFqVL/49hPc48wEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIrf7YI2we9nANoffw9xoeLMBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKxqs/hYtGiRunXrpuDgYA0aNEgffPBBW90VAADwIW0SH3/605+UlZWl7Oxs7dq1S/3791daWpqOHTvWFncHAAB8SJvEx7PPPquf/exnmjBhgq688kq98MILuuiii/TKK6+0xd0BAAAf0uo/Xr2mpkaFhYWaNWuWe5u/v79SU1OVn5/faP/q6mpVV1e7vy4rK5MklZeXt/ZokqT66jNtcty21FZr0ZZ8cZ19Ed8bAFqiLf7taDimMeZ79231+Dhx4oTq6uoUExPjsT0mJkaffPJJo/1zcnI0Z86cRtsTEhJaezSf5VrY3hPgQsX3BoCWaMt/OyoqKuRyuf7pPu3+i+VmzZqlrKws99f19fX66quv1KVLF/n5+bXqfZWXlyshIUFHjx6V0+ls1WPjH1hnO1hnO1hne1hrO9pqnY0xqqioUHx8/Pfu2+rxERkZqU6dOqm0tNRje2lpqWJjYxvt73A45HA4PLaFh4e39lgenE4n39gWsM52sM52sM72sNZ2tMU6f98Zjwat/obToKAgJScnKy8vz72tvr5eeXl5SklJae27AwAAPqZNXnbJysrS+PHjNWDAAA0cOFALFy5UZWWlJkyY0BZ3BwAAfEibxMcdd9yh48eP6/HHH1dJSYmuuuoqrV+/vtGbUG1zOBzKzs5u9DIPWhfrbAfrbAfrbA9rbceFsM5+5lw+EwMAANBK+N0uAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKzqcPGxaNEidevWTcHBwRo0aJA++OCDf7p/bm6ukpKSFBwcrL59++rNN9+0NKlv82adX3rpJQ0dOlSdO3dW586dlZqa+r1/LviGt9/PDVatWiU/Pz/deuutbTtgB+HtOp86dUqZmZmKi4uTw+FQz549+bfjHHi7zgsXLtQVV1yhkJAQJSQkaMaMGaqqqrI0rW/aunWrRo4cqfj4ePn5+Wnt2rXfe5vNmzfr6quvlsPh0I9+9CMtX768zeeU6UBWrVplgoKCzCuvvGI++ugj87Of/cyEh4eb0tLSJvd/7733TKdOncz8+fPNvn37zK9+9SsTGBho9u7da3ly3+LtOt91111m0aJFZvfu3ebjjz829957r3G5XObzzz+3PLlv8XadGxQVFZlLLrnEDB061IwaNcrOsD7M23Wurq42AwYMMDfddJPZtm2bKSoqMps3bzZ79uyxPLlv8XadV6xYYRwOh1mxYoUpKioyGzZsMHFxcWbGjBmWJ/ctb775pnn00UfNa6+9ZiSZNWvW/NP9Dx06ZC666CKTlZVl9u3bZ37729+aTp06mfXr17fpnB0qPgYOHGgyMzPdX9fV1Zn4+HiTk5PT5P5jx441N998s8e2QYMGmfvvv79N5/R13q7zd509e9aEhYWZP/zhD201YofQknU+e/asueaaa8zLL79sxo8fT3ycA2/XecmSJaZ79+6mpqbG1ogdgrfrnJmZaUaMGOGxLSsrywwZMqRN5+xIziU+HnnkEdO7d2+PbXfccYdJS0trw8mM6TAvu9TU1KiwsFCpqanubf7+/kpNTVV+fn6Tt8nPz/fYX5LS0tKa3R8tW+fvOnPmjGpraxUREdFWY/q8lq7zE088oejoaE2cONHGmD6vJev8P//zP0pJSVFmZqZiYmLUp08fzZ07V3V1dbbG9jktWedrrrlGhYWF7pdmDh06pDfffFM33XSTlZl/KNrrebBNfrx6ezhx4oTq6uoa/Qj3mJgYffLJJ03epqSkpMn9S0pK2mxOX9eSdf6uX/7yl4qPj2/0DY9/aMk6b9u2TUuXLtWePXssTNgxtGSdDx06pHfeeUd333233nzzTX366aeaMmWKamtrlZ2dbWNsn9OSdb7rrrt04sQJXXvttTLG6OzZs3rggQf0H//xHzZG/sFo7nmwvLxcf//73xUSEtIm99thznzAN8ybN0+rVq3SmjVrFBwc3N7jdBgVFRUaN26cXnrpJUVGRrb3OB1afX29oqOj9eKLLyo5OVl33HGHHn30Ub3wwgvtPVqHsnnzZs2dO1eLFy/Wrl279Nprr+mNN97Qk08+2d6joRV0mDMfkZGR6tSpk0pLSz22l5aWKjY2tsnbxMbGerU/WrbODZ555hnNmzdPb7/9tvr169eWY/o8b9f54MGDOnz4sEaOHOneVl9fL0kKCAjQ/v371aNHj7Yd2ge15Ps5Li5OgYGB6tSpk3tbr169VFJSopqaGgUFBbXpzL6oJev82GOPady4cZo0aZIkqW/fvqqsrNTkyZP16KOPyt+f/3duDc09DzqdzjY76yF1oDMfQUFBSk5OVl5enntbfX298vLylJKS0uRtUlJSPPaXpI0bNza7P1q2zpI0f/58Pfnkk1q/fr0GDBhgY1Sf5u06JyUlae/evdqzZ4/78q//+q8aPny49uzZo4SEBJvj+4yWfD8PGTJEn376qTvuJOlvf/ub4uLiCI9mtGSdz5w50ygwGoLP8PtQW027PQ+26dtZLVu1apVxOBxm+fLlZt++fWby5MkmPDzclJSUGGOMGTdunJk5c6Z7//fee88EBASYZ555xnz88ccmOzubj9qeA2/Xed68eSYoKMisXr3afPnll+5LRUVFez0En+DtOn8Xn3Y5N96u85EjR0xYWJiZOnWq2b9/v3n99ddNdHS0+fWvf91eD8EneLvO2dnZJiwszPzxj380hw4dMm+99Zbp0aOHGTt2bHs9BJ9QUVFhdu/ebXbv3m0kmWeffdbs3r3bfPbZZ8YYY2bOnGnGjRvn3r/ho7YPP/yw+fjjj82iRYv4qG1L/Pa3vzVdu3Y1QUFBZuDAgaagoMB93bBhw8z48eM99v/zn/9sevbsaYKCgkzv3r3NG2+8YXli3+TNOl922WVGUqNLdna2/cF9jLffz99GfJw7b9f5/fffN4MGDTIOh8N0797dPPXUU+bs2bOWp/Y93qxzbW2tmT17tunRo4cJDg42CQkJZsqUKebrr7+2P7gP2bRpU5P/3jas7fjx482wYcMa3eaqq64yQUFBpnv37mbZsmVtPqefMZy/AgAA9nSY93wAAADfQHwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGDV/wPfmzF4axshuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a distriution of the accuracies of test_losses and test_accs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.7589816641807556\n",
      "mean test accuracy before communication:  0.6988333333333333\n",
      "mean test loss after communication:  1.712848001718521\n",
      "mean test accuracy after communication:  0.18033333333333332\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.0435598593950273\n",
      "mean test accuracy before communication:  0.7726666666666668\n",
      "mean test loss after communication:  0.8551287712156772\n",
      "mean test accuracy after communication:  0.6762777777777776\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7600278131337836\n",
      "mean test accuracy before communication:  0.7993333333333336\n",
      "mean test loss after communication:  0.7369266142822744\n",
      "mean test accuracy after communication:  0.7988333333333334\n"
     ]
    }
   ],
   "source": [
    "# 01 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.7469488608837127\n",
      "mean test accuracy before communication:  0.7307777777777779\n",
      "mean test loss after communication:  1.7391189473867417\n",
      "mean test accuracy after communication:  0.18033333333333332\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.0787764324247837\n",
      "mean test accuracy before communication:  0.7865555555555557\n",
      "mean test loss after communication:  0.9264291336201131\n",
      "mean test accuracy after communication:  0.7293333333333334\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7845644587208517\n",
      "mean test accuracy before communication:  0.786\n",
      "mean test loss after communication:  0.7951719699541718\n",
      "mean test accuracy after communication:  0.7826666666666666\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(20)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 20, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
