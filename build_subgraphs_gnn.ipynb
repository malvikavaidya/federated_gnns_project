{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "folder_path = 'client_subgraphs'\n",
    "sub_data_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.gml'):\n",
    "      \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        g = nx.read_gml(file_path)\n",
    "\n",
    "        subgraph_nodes = list(g.nodes)\n",
    "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "        sub_data_list.append(sub_data)\n",
    "\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     if filename.endswith('.gml'):\n",
    "#         # Read GML file using networkx\n",
    "#         file_path = os.path.join(folder_path, filename)\n",
    "#         g = nx.read_gml(file_path)\n",
    "\n",
    "#         # Convert networkx graph to PyTorch Geometric data\n",
    "#         sub_data = from_networkx(g)\n",
    "#         # Ensure node features and labels are set (this will depend on how data is stored in the GML file)\n",
    "\n",
    "#         # Example: Set dummy features and labels if not present\n",
    "#         if sub_data.x is None:\n",
    "#             num_nodes = sub_data.num_nodes\n",
    "#             sub_data.x = torch.randn((num_nodes, data.num_node_features))  # Replace with actual node features\n",
    "#         if sub_data.y is None:\n",
    "#             sub_data.y = torch.randint(0, dataset.num_classes, (sub_data.num_nodes,))  # Replace with actual labels\n",
    "        \n",
    "#         sub_data_list.append(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[17, 1433], edge_index=[2, 58], y=[17])\n"
     ]
    }
   ],
   "source": [
    "print(sub_data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot subgraph 0 to make sure it looks right\n",
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "# from torch_geometric.utils import to_networkx\n",
    "\n",
    "# G = to_networkx(sub_data_list[82], to_undirected=False)\n",
    "# plt.figure(figsize=(20,20))\n",
    "# nx.draw(G, with_labels=True, node_size=15, node_color='g', edge_color='b')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First convolutional layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and validation\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a  list of training and validation loss per epoch for each subgraph\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train_val_split(data):\n",
    "        #handle labels with only one sample\n",
    "    # `data.x` contains the node features and `data.y` contains the labels\n",
    "\n",
    "    # Count the occurrences of each label in the dataset\n",
    "    label_counts = torch.bincount(data.y)\n",
    "\n",
    "    # Find the labels that appear only once (single occurrence)\n",
    "    single_occurrence_labels = torch.nonzero(label_counts == 1).flatten()\n",
    "\n",
    "    # Initialize empty lists to store samples\n",
    "    single_sample_label = []\n",
    "    other_label = []\n",
    "\n",
    "    # Separate samples based on labels\n",
    "    for i, label in enumerate(data.y):\n",
    "        if label in single_occurrence_labels:\n",
    "            single_sample_label.append(i)\n",
    "        else:\n",
    "            other_label.append(i)\n",
    "\n",
    "    # Convert the lists of sample indices into tensors\n",
    "    single_sample_label = torch.tensor(single_sample_label)\n",
    "    other_label = torch.tensor(other_label)\n",
    "\n",
    "    # Extract the corresponding node features and labels\n",
    "    single_sample_x = data.x[single_sample_label]\n",
    "    single_sample_y = data.y[single_sample_label]\n",
    "    other_x = data.x[other_label]\n",
    "    other_y = data.y[other_label]\n",
    "    \n",
    "    other_x_train, other_x_test, other_y_train, other_y_test = train_test_split(other_x, other_y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Add single_sample_x and single_sample_y to the training set\n",
    "    combined_x_train = torch.cat((other_x_train, single_sample_x), dim=0)\n",
    "    combined_y_train = torch.cat((other_y_train, single_sample_y), dim=0)\n",
    "    \n",
    "    return combined_x_train, combined_y_train, other_x_test, other_y_test\n",
    "                    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nidhi\\Documents\\UT_Austin\\Senior\\ML in Real World Networks\\Project\\federated_gnns_project\\build_subgraphs_gnn.ipynb Cell 9\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sub_data \u001b[39m=\u001b[39m sub_data_list[i]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#split sub_data.x and sub_data.y into train and validation, but keep the same edge_index\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_x, train_y, val_x, val_y \u001b[39m=\u001b[39m train_val_split(sub_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sub_data_train \u001b[39m=\u001b[39m Data(x\u001b[39m=\u001b[39mtrain_x, edge_index\u001b[39m=\u001b[39msub_data\u001b[39m.\u001b[39medge_index, y\u001b[39m=\u001b[39mtrain_y)\n",
      "\u001b[1;32mc:\\Users\\nidhi\\Documents\\UT_Austin\\Senior\\ML in Real World Networks\\Project\\federated_gnns_project\\build_subgraphs_gnn.ipynb Cell 9\u001b[0m line \u001b[0;36mtrain_val_split\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m other_label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(other_label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Extract the corresponding node features and labels\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m single_sample_x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mx[single_sample_label]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m single_sample_y \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my[single_sample_label]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Senior/ML%20in%20Real%20World%20Networks/Project/federated_gnns_project/build_subgraphs_gnn.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m other_x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx[other_label]\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100):\n",
    "    \n",
    "    sub_data = sub_data_list[i]\n",
    "    #split sub_data.x and sub_data.y into train and validation, but keep the same edge_index\n",
    "    train_x, train_y, val_x, val_y = train_val_split(sub_data)\n",
    "    continue\n",
    "    sub_data_train = Data(x=train_x, edge_index=sub_data.edge_index, y=train_y)\n",
    "    sub_data_val = Data(x=val_x, edge_index=sub_data.edge_index, y=val_y)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    \n",
    "    client_train_losses = []\n",
    "    client_val_losses = []\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        model = model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(sub_data_train)\n",
    "        loss = F.nll_loss(out, sub_data_train.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        client_train_losses.append(loss.item())\n",
    "        \n",
    "        #calculate validation loss\n",
    "        model = model.eval()\n",
    "        out_val = model(sub_data_val)\n",
    "        loss = F.nll_loss(out_val, sub_data_val.y)\n",
    "        client_val_losses.append(loss.item())\n",
    "        \n",
    "        \n",
    "    train_losses.append(client_train_losses)\n",
    "    val_losses.append(client_val_losses)\n",
    "    # print out metrics\n",
    "    #calculate final training accuracy\n",
    "    true_labels = sub_data_train.y\n",
    "    _, pred = out.max(1)\n",
    "    train_correct = pred.eq(true_labels).sum().item()\n",
    "    print(\"final training loss: \", loss.item(), \" for subgraph \", i)\n",
    "    print(\"final training accuracy: \", train_correct / len(true_labels), \" for subgraph \", i)\n",
    "    print()\n",
    "    #calculate validation accuracy and loss\n",
    "    true_labels = sub_data_val.y\n",
    "    _, pred = out_val.max(1)\n",
    "    val_correct = pred.eq(true_labels).sum().item()\n",
    "    \n",
    "    \n",
    "    print(\"final validation loss: \", loss.item(), \" for subgraph \", i)\n",
    "    print(\"final validation accuracy: \", val_correct / len(true_labels), \" for subgraph \", i)\n",
    "    print(\"------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
