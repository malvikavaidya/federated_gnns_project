{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234567)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "folder_path = 'client_subgraphs'\n",
    "sub_data_list = []\n",
    "client_number = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.gml'):\n",
    "      \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        g = nx.read_gml(file_path)\n",
    "\n",
    "        subgraph_nodes = list(g.nodes)\n",
    "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "        sub_data_list.append(sub_data)\n",
    "        client_number.append(int(filename.split('.')[0].split('_')[1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = None\n",
    "\n",
    "g = nx.read_gml('test_graph.gml')\n",
    "subgraph_nodes = list(g.nodes)\n",
    "subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "test_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'828': ['713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '849', '718', '754', '760', '739', '856', '764', '687', '840', '847', '770', '797', '814', '727', '731', '708', '698', '817', '792', '845', '838', '848', '835', '807', '711', '779', '706', '772', '741', '709', '778', '737', '844', '693'], '713': ['828', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '760', '787', '840', '847', '814', '731', '708', '698', '738', '817', '734', '845', '701', '848', '748', '706', '777', '772', '818', '778', '831', '833', '722', '844', '736', '794', '693'], '705': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '703', '784', '752', '728', '820', '842', '800', '819', '726', '773', '829', '780', '810', '849', '718', '754', '760', '739', '787', '764', '847', '770', '814', '731', '738', '845', '835', '807', '758', '803', '748', '755', '809', '720', '706', '772', '741', '778', '737', '831', '722', '844', '693', '763'], '719': ['828', '713', '705', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '810', '696', '849', '718', '760', '787', '764', '840', '847', '814', '727', '731', '708', '698', '817', '734', '845', '848', '755', '720', '706', '772', '737', '722', '768', '794'], '805': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '703', '695', '815', '752', '728', '842', '800', '819', '774', '726', '766', '829', '780', '810', '696', '718', '754', '760', '739', '764', '687', '840', '847', '814', '727', '731', '738', '817', '792', '734', '838', '807', '706', '772', '709', '818', '737', '831', '844'], '824': ['828', '713', '705', '719', '805', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '819', '774', '726', '773', '766', '829', '780', '696', '849', '754', '760', '739', '764', '840', '847', '770', '727', '708', '792', '838', '848', '835', '779', '777', '709', '737', '844', '693'], '745': ['828', '713', '705', '719', '805', '824', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '829', '810', '696', '718', '760', '787', '847', '814', '731', '698', '738', '817', '845', '758', '711', '755', '720', '706', '795', '737', '722', '794'], '747': ['828', '713', '705', '719', '805', '745', '823', '830', '697', '688', '703', '815', '752', '728', '820', '800', '819', '774', '773', '780', '810', '696', '849', '718', '754', '739', '856', '764', '687', '840', '770', '797', '708', '698', '792', '838', '701', '848', '807', '793', '758', '803', '748', '783', '809', '741', '831', '730', '763', '765'], '823': ['828', '713', '705', '719', '805', '824', '745', '747', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '815', '752', '728', '820', '800', '819', '774', '726', '773', '766', '780', '810', '696', '718', '754', '760', '739', '787', '856', '764', '687', '840', '708', '698', '792', '838', '848', '835', '807', '779', '741', '709', '693', '765'], '694': ['828', '713', '705', '719', '805', '824', '745', '823', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '780', '810', '696', '754', '760', '847', '727', '731', '738', '845', '848', '711', '706', '795', '772', '737', '831', '722'], '830': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '695', '815', '752', '820', '800', '819', '774', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '847', '727', '731', '817', '792', '845', '838', '701', '748', '777', '709', '778', '737', '844'], '781': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '697', '724', '827', '853', '834', '703', '695', '784', '815', '752', '728', '842', '800', '726', '773', '829', '810', '849', '718', '760', '787', '764', '770', '814', '731', '708', '738', '817', '701', '793', '758', '755', '783', '809', '720', '772', '741', '794'], '697': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '834', '695', '815', '820', '842', '800', '819', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '727', '731', '708', '698', '701', '848', '835', '748', '777', '772', '709', '818', '844', '693', '765'], '724': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '827', '688', '853', '834', '695', '784', '752', '820', '842', '819', '726', '773', '766', '829', '696', '754', '760', '814', '731', '708', '738', '734', '701', '848', '711', '795', '777', '778', '736', '794'], '827': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '853', '834', '703', '784', '752', '842', '800', '819', '773', '766', '810', '849', '718', '760', '787', '764', '797', '814', '731', '708', '817', '758', '755', '783', '809', '772', '741'], '688': ['828', '713', '719', '805', '824', '747', '823', '694', '830', '697', '724', '853', '834', '695', '815', '752', '800', '819', '774', '726', '766', '780', '696', '849', '754', '739', '856', '687', '840', '847', '770', '727', '792', '734', '845', '701', '777', '772', '771'], '853': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '724', '827', '688', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '810', '696', '847', '814', '727', '731', '738', '734', '711', '706', '795', '831', '722'], '834': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '695', '784', '815', '752', '820', '842', '800', '819', '726', '773', '766', '829', '780', '810', '696', '718', '760', '847', '814', '731', '701', '706', '778', '844', '693'], '703': ['828', '705', '719', '805', '824', '747', '823', '694', '781', '827', '815', '728', '820', '819', '718', '754', '739', '787', '856', '764', '687', '797', '698', '817', '792', '845', '838', '835', '807', '793', '758', '748', '779', '809', '741', '709', '831', '730', '765'], '695': ['713', '719', '805', '824', '745', '694', '830', '781', '697', '724', '688', '853', '834', '784', '815', '752', '842', '726', '766', '829', '780', '810', '696', '718', '754', '760', '840', '847', '738', '734', '701', '711', '706', '777', '778', '844', '794', '693'], '784': ['828', '713', '705', '719', '824', '745', '694', '781', '724', '827', '853', '834', '695', '752', '842', '800', '774', '726', '773', '766', '829', '810', '696', '760', '727', '731', '738', '734', '711', '706', '795', '722', '794'], '815': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '688', '853', '834', '703', '695', '752', '819', '726', '773', '766', '780', '810', '718', '754', '856', '847', '731', '792', '845', '838', '835', '706', '737'], '752': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '853', '834', '695', '784', '815', '820', '842', '800', '774', '726', '773', '766', '829', '810', '847', '727', '731', '738', '711', '706', '831'], '728': ['828', '705', '719', '805', '824', '747', '823', '781', '703', '820', '819', '774', '773', '780', '754', '739', '787', '856', '764', '687', '797', '817', '792', '838', '835', '807', '803', '783', '779', '809', '741', '737', '730', '765'], '820': ['828', '705', '719', '824', '745', '747', '823', '694', '830', '697', '724', '853', '834', '703', '752', '728', '774', '726', '773', '766', '849', '760', '687', '770', '797', '845', '848', '803', '783', '795', '741', '737', '831', '722', '763'], '842': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '697', '724', '827', '853', '834', '695', '784', '752', '800', '773', '829', '810', '696', '760', '814', '727', '738', '734', '701', '711', '795', '794'], '800': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '830', '781', '697', '827', '688', '853', '834', '784', '752', '842', '774', '766', '810', '760', '856', '814', '727', '708', '698', '845', '772', '741'], '819': ['828', '713', '705', '719', '805', '824', '747', '823', '830', '697', '724', '827', '688', '834', '703', '815', '728', '774', '780', '739', '856', '687', '840', '708', '698', '817', '792', '838', '848', '835', '807', '709', '778'], '774': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '688', '853', '784', '752', '728', '820', '800', '819', '773', '810', '696', '739', '856', '687', '840', '731', '708', '698', '738', '701', '807', '720'], '726': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '688', '853', '834', '695', '784', '815', '752', '820', '773', '766', '780', '754', '760', '731', '845', '701', '778', '844', '693'], '773': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '724', '827', '853', '834', '784', '815', '752', '728', '820', '842', '774', '726', '829', '780', '810', '696', '754', '847', '731', '706', '737', '831'], '766': ['828', '713', '719', '805', '824', '823', '694', '830', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '820', '800', '726', '780', '810', '849', '760', '847', '727', '731', '734', '711', '771'], '829': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '724', '853', '834', '695', '784', '752', '842', '773', '696', '760', '847', '814', '738', '734', '711', '795', '777', '822', '722'], '780': ['828', '713', '705', '805', '824', '747', '823', '694', '830', '697', '688', '834', '695', '815', '728', '819', '726', '773', '766', '696', '754', '739', '687', '840', '792', '845', '838', '701', '835', '803', '779', '777', '765'], '810': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '781', '827', '853', '834', '695', '784', '815', '752', '842', '800', '774', '773', '766', '856', '847', '814', '731', '698', '711', '706'], '696': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '697', '724', '688', '853', '834', '695', '784', '842', '774', '773', '829', '780', '739', '840', '727', '738', '845', '711', '795', '778'], '849': ['828', '705', '719', '824', '747', '830', '781', '697', '827', '688', '820', '766', '787', '770', '797', '727', '708', '734', '845', '793', '758', '748', '755', '783', '730', '763'], '718': ['828', '705', '719', '805', '745', '747', '823', '781', '827', '834', '703', '695', '815', '787', '764', '687', '770', '797', '814', '817', '793', '758', '803', '748', '809', '720', '730'], '754': ['828', '705', '805', '824', '747', '823', '694', '830', '697', '724', '688', '703', '695', '815', '728', '726', '773', '780', '739', '840', '792', '838', '701', '848', '835', '779', '777', '709'], '760': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '834', '695', '784', '820', '842', '800', '726', '766', '829', '814', '708', '738', '734', '701', '794'], '739': ['828', '705', '805', '824', '747', '823', '688', '703', '728', '819', '774', '780', '696', '754', '787', '764', '687', '840', '797', '792', '807', '793', '758', '720', '777', '709'], '787': ['713', '705', '719', '745', '823', '781', '827', '703', '728', '849', '718', '739', '764', '797', '814', '817', '793', '758', '803', '748', '755', '783', '809', '720', '730', '763'], '856': ['828', '747', '823', '830', '697', '688', '703', '815', '728', '800', '819', '774', '810', '687', '840', '708', '698', '838', '807', '772', '765'], '764': ['828', '705', '719', '805', '824', '747', '823', '781', '827', '703', '728', '718', '739', '787', '687', '797', '817', '838', '807', '793', '748', '783', '779', '809', '720', '730'], '687': ['828', '805', '747', '823', '830', '697', '688', '703', '728', '820', '819', '774', '780', '718', '739', '856', '764', '797', '817', '838', '807', '783', '779', '777', '730', '765'], '840': ['828', '713', '719', '805', '824', '747', '823', '830', '697', '688', '695', '819', '774', '780', '696', '754', '739', '856', '708', '698', '838', '848', '803', '779', '709'], '847': ['828', '713', '705', '719', '805', '824', '745', '694', '830', '688', '853', '834', '695', '815', '752', '773', '766', '829', '810', '727', '731', '734', '711', '706'], '770': ['828', '705', '824', '747', '781', '688', '820', '849', '718', '797', '727', '734', '845', '803', '748', '783', '777', '772', '741', '763'], '797': ['828', '747', '827', '703', '728', '820', '849', '718', '739', '787', '764', '687', '770', '708', '817', '793', '748', '755', '783', '809', '831', '730', '763'], '814': ['828', '713', '705', '719', '805', '745', '781', '724', '827', '853', '834', '842', '800', '829', '810', '718', '760', '787', '708', '758', '755', '772'], '727': ['828', '719', '805', '824', '694', '830', '697', '688', '853', '784', '752', '842', '800', '766', '696', '849', '847', '770', '845', '848', '711'], '731': ['828', '713', '705', '719', '805', '745', '694', '830', '781', '697', '724', '827', '853', '834', '784', '815', '752', '774', '726', '773', '766', '810', '847', '706'], '708': ['828', '713', '719', '824', '747', '823', '781', '697', '724', '827', '800', '819', '774', '849', '760', '856', '840', '797', '814', '755', '730'], '698': ['828', '713', '719', '745', '747', '823', '697', '703', '800', '819', '774', '810', '856', '840', '803', '772'], '738': ['713', '705', '805', '745', '694', '781', '724', '853', '695', '784', '752', '842', '774', '829', '696', '760', '711', '795', '722', '794'], '817': ['828', '713', '719', '805', '745', '830', '781', '827', '703', '728', '819', '718', '787', '764', '687', '797', '793', '758', '748', '783', '809'], '792': ['828', '805', '824', '747', '823', '830', '688', '703', '815', '728', '819', '780', '754', '739', '838', '835', '807', '803', '779', '765'], '734': ['713', '719', '805', '724', '688', '853', '695', '784', '842', '766', '829', '849', '760', '847', '770', '803', '778', '693'], '845': ['828', '713', '705', '719', '745', '694', '830', '688', '703', '815', '820', '800', '726', '780', '696', '849', '770', '727', '701', '755', '772'], '838': ['828', '805', '824', '747', '823', '830', '703', '815', '728', '819', '780', '754', '856', '764', '687', '840', '792', '835', '807', '779', '709'], '701': ['713', '747', '830', '781', '697', '724', '688', '834', '695', '842', '774', '726', '780', '754', '760', '845', '777', '778', '794'], '848': ['828', '713', '719', '824', '747', '823', '694', '697', '724', '820', '819', '754', '840', '727', '709', '844'], '835': ['828', '705', '824', '823', '697', '703', '815', '728', '819', '780', '754', '792', '838', '779', '741', '709', '765'], '807': ['828', '705', '805', '747', '823', '703', '728', '819', '774', '739', '856', '764', '687', '792', '838', '779', '741', '765'], '793': ['747', '781', '703', '849', '718', '739', '787', '764', '797', '817', '758', '748', '755', '783', '809', '720'], '758': ['705', '745', '747', '781', '827', '703', '849', '718', '739', '787', '814', '817', '793', '748', '755', '783', '809'], '711': ['828', '745', '694', '724', '853', '695', '784', '752', '842', '766', '829', '810', '696', '847', '727', '738', '795', '722'], '803': ['705', '747', '728', '820', '780', '718', '787', '840', '770', '698', '792', '734', '720', '730', '763'], '748': ['713', '705', '747', '830', '697', '703', '849', '718', '787', '764', '770', '797', '817', '793', '758', '779', '831'], '755': ['705', '719', '745', '781', '827', '849', '787', '797', '814', '708', '845', '793', '758', '783', '809', '720'], '783': ['747', '781', '827', '728', '820', '849', '787', '764', '687', '770', '797', '817', '793', '758', '755', '809', '730'], '779': ['828', '824', '823', '703', '728', '780', '754', '764', '687', '840', '792', '838', '835', '807', '748', '777', '765'], '809': ['705', '747', '781', '827', '703', '728', '718', '787', '764', '797', '817', '793', '758', '755', '783', '720'], '720': ['705', '719', '745', '781', '774', '718', '739', '787', '764', '793', '803', '755', '809', '730'], '706': ['828', '713', '705', '719', '805', '745', '694', '853', '834', '695', '784', '815', '752', '773', '810', '847', '731'], '795': ['745', '694', '724', '853', '784', '820', '842', '829', '696', '738', '711', '794'], '777': ['713', '824', '830', '697', '724', '688', '695', '829', '780', '754', '739', '687', '770', '701', '779', '709'], '772': ['828', '713', '705', '719', '805', '694', '781', '697', '827', '688', '800', '856', '770', '814', '698', '845'], '741': ['828', '705', '747', '823', '781', '827', '703', '728', '820', '800', '770', '835', '807', '763'], '709': ['828', '805', '824', '823', '830', '697', '703', '819', '754', '739', '840', '838', '848', '835', '777'], '818': ['713', '805', '697', '822', '806', '839', '771', '732', '736', '714'], '778': ['828', '713', '705', '830', '724', '834', '695', '819', '726', '696', '734', '701', '844', '693'], '737': ['828', '705', '719', '805', '824', '745', '694', '830', '815', '728', '820', '773', '722'], '831': ['713', '705', '805', '747', '694', '853', '703', '752', '820', '773', '797', '748'], '833': ['713', '806', '768', '736'], '822': ['829', '818', '806', '839', '768', '732', '714'], '806': ['818', '833', '822', '839', '771', '732', '714'], '730': ['747', '703', '728', '849', '718', '787', '764', '687', '797', '708', '803', '783', '720', '763'], '839': ['818', '822', '806', '771', '768', '732', '714'], '771': ['688', '766', '818', '806', '839', '732', '714'], '722': ['713', '705', '719', '745', '694', '853', '784', '820', '829', '738', '711', '737', '768'], '844': ['828', '713', '705', '805', '824', '830', '697', '834', '695', '726', '848', '778', '693'], '768': ['719', '833', '822', '839', '722'], '732': ['818', '822', '806', '839', '771', '714'], '736': ['713', '724', '818', '833'], '794': ['713', '719', '745', '781', '724', '695', '784', '842', '760', '738', '701', '795'], '693': ['828', '713', '705', '824', '823', '697', '834', '695', '726', '734', '778', '844'], '763': ['705', '747', '820', '849', '787', '770', '797', '803', '741', '730'], '765': ['747', '823', '697', '703', '728', '780', '856', '687', '792', '835', '807', '779'], '714': ['818', '822', '806', '839', '771', '732']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.read_gml('new_facebook_network.gml')\n",
    "neighbors = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors[node] = list(g.neighbors(node))\n",
    "\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new_facebook_network.gml and create a fully connected graph\n",
    "\n",
    "neighbors_fully_connected = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors_fully_connected[node] = list(g.nodes)\n",
    "    neighbors_fully_connected[node].remove(node)\n",
    "\n",
    "    \n",
    "# print(neighbors_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[17, 1433], edge_index=[2, 58], y=[17])\n",
      "torch.Size([17, 1433])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(sub_data_list[0])\n",
    "print(sub_data_list[0].x.shape)\n",
    "print(type(client_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a  list of training and validation loss per epoch for each subgraph\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def transductive_split(data, train_percent=0.8, val_percent=0.1):\n",
    "    \"\"\"\n",
    "    Split graph data into training, validation, and testing sets for transductive learning.\n",
    "    :param data: PyG Data object\n",
    "    :param train_percent: Percentage of nodes to be used for training\n",
    "    :param val_percent: Percentage of nodes to be used for validation\n",
    "    :return: data object with train_mask, val_mask, and test_mask attributes added\n",
    "    \"\"\"\n",
    "    # set a seed for reproducibility\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    train_size = int(train_percent * num_nodes)\n",
    "    val_size = int(val_percent * num_nodes)\n",
    "\n",
    "    # Create a random permutation of node indices\n",
    "    perm = torch.randperm(num_nodes)\n",
    "\n",
    "    # Create masks for training, validation, and testing nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[perm[:train_size]] = True\n",
    "    val_mask[perm[train_size:train_size + val_size]] = True\n",
    "    test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "    # Add masks to data object\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the subgraphs into train test and val \n",
    "# for i in range(0, 100):\n",
    "#     sub_data = sub_data_list[i]\n",
    "#     sub_data = transductive_split(sub_data)\n",
    "\n",
    "\n",
    "# print(torch.sum(sub_data_list[4].train_mask).item())  # Number of training nodes\n",
    "# print(torch.sum(sub_data_list[4].val_mask).item())    # Number of validation nodes\n",
    "# print(torch.sum(sub_data_list[4].test_mask).item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training) # p = 0.25\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots(10, 10, figsize=(50, 50))\n",
    "\n",
    "def train(sub_data, model, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out, sub_data.y)  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      return loss\n",
    "\n",
    "def test(test_data, criterion, model):\n",
    "      model.eval()\n",
    "      out = model(test_data.x, test_data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred == test_data.y # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / len(test_data.y)  # Derive ratio of correct predictions.\n",
    "      test_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "      \n",
    "      return test_loss, test_acc\n",
    "\n",
    "\n",
    "def validate(test_data, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Do not compute gradients during this step\n",
    "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get predicted classes\n",
    "        val_correct = pred == test_data.y # Compare with ground-truth\n",
    "        val_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "        val_acc = int(val_correct.sum()) / int(len(test_data.y))  # Compute validation accuracy\n",
    "    return val_loss.item(), val_acc  # Return validation loss and accuracy\n",
    "\n",
    "\n",
    "def initial_training(epochs):\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    dictionary_t_1 = {}\n",
    "    dictionary_t = {}\n",
    "\n",
    "    for i in range(len(sub_data_list)):\n",
    "        sub_data = sub_data_list[i]\n",
    "        \n",
    "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_losses = [] \n",
    "        val_losses = []    \n",
    "\n",
    "        # Training loop for each epoch (adjust the range as needed)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "            val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "        \n",
    "        test_loss, test_acc = test(test_data, criterion, model)\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accs.append(test_acc)\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "\n",
    "        model_weights = model.state_dict()\n",
    "        client_number_num = client_number[i]\n",
    "        dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return dictionary_t_1, test_losses, test_accs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.3434717321395873\n",
      "mean test accuracy before communication:  0.1466571428571427\n"
     ]
    }
   ],
   "source": [
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "\n",
    "# average test loss and accuracy before communication \n",
    "\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
    "    for k in global_model.keys():\n",
    "        global_model[k] = torch.stack([model[k].float() for model in models], 0).mean(0)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communication(dictionary_t_1_og, neighbors, epochs, rounds):\n",
    "    # make a copy of dictionary_t_1\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
    "    dictionary_t = {}\n",
    "    for k in range(1, rounds + 1):\n",
    "\n",
    "    # get the neighbprs of each client\n",
    "        for i in range(len(sub_data_list)):\n",
    "            sub_data = sub_data_list[i]\n",
    "            \n",
    "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_losses = [] \n",
    "            val_losses = []    \n",
    "\n",
    "            # Training loop for each epoch (adjust the range as needed)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "            \n",
    "            test_loss, test_acc = test(test_data, criterion, model)\n",
    "            if k == rounds:\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        \n",
    "            # add the model weights to the t -1 dictionary\n",
    "            model_weights = model.state_dict()\n",
    "            client_number_num = client_number[i]\n",
    "            dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "\n",
    "        for i in range(100):\n",
    "            client_number_num = client_number[i]\n",
    "            # go through neighbors of client_number\n",
    "            string_client_num = str(client_number_num)\n",
    "            client_neighbors = neighbors[string_client_num]\n",
    "            \n",
    "            neighbors_state_dicts = []\n",
    "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
    "            for j in range(len(client_neighbors)):\n",
    "                # get model weights of neighbor\n",
    "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
    "                neighbors_state_dicts.append(neighbor_model)\n",
    "            \n",
    "            #call fed_avg\n",
    "            average_state_dict = {}\n",
    "            average_state_dict = fed_avg(neighbors_state_dicts)\n",
    "            # average weights of client and neighbors\n",
    "            # average_state_dict = {}\n",
    "            # for param in neighbors_state_dicts[0]:\n",
    "            #     # num parameters\n",
    "            #     num_neighbors = len(neighbors_state_dicts)\n",
    "            #     sum_param = 0\n",
    "            #     for neighbor in range(num_neighbors):\n",
    "            #         sum_param += neighbors_state_dicts[neighbor][param]\n",
    "            #     average_param = sum_param / num_neighbors\n",
    "            #     average_state_dict[param] = average_param\n",
    "                \n",
    "                \n",
    "            dictionary_t[client_number_num] = average_state_dict    \n",
    "            \n",
    "        dictionary_t_1 = dictionary_t\n",
    "\n",
    "    return test_losses, test_accs\n",
    " \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss after communication:  3.1825060403347014\n",
      "mean test accuracy after communication:  0.14697142857142848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "\n",
    "# average test loss and accuracy after communication\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "\n",
    "#mean of test_accs\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a distriution of the accuracies of test_losses and test_accs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.9471930146217347\n",
      "mean test accuracy before communication:  0.15068571428571437\n",
      "mean test loss after communication:  2.0834278416633607\n",
      "mean test accuracy after communication:  0.1428571428571427\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.021461166143417\n",
      "mean test accuracy before communication:  0.14885714285714272\n",
      "mean test loss after communication:  2.9431652987003325\n",
      "mean test accuracy after communication:  0.15485714285714278\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7600278131337836\n",
      "mean test accuracy before communication:  0.7993333333333336\n",
      "mean test loss after communication:  0.7369266142822744\n",
      "mean test accuracy after communication:  0.7988333333333334\n"
     ]
    }
   ],
   "source": [
    "# 01 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.7469488608837127\n",
      "mean test accuracy before communication:  0.7307777777777779\n",
      "mean test loss after communication:  1.7391189473867417\n",
      "mean test accuracy after communication:  0.18033333333333332\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.0787764324247837\n",
      "mean test accuracy before communication:  0.7865555555555557\n",
      "mean test loss after communication:  0.9264291336201131\n",
      "mean test accuracy after communication:  0.7293333333333334\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7845644587208517\n",
      "mean test accuracy before communication:  0.786\n",
      "mean test loss after communication:  0.7951719699541718\n",
      "mean test accuracy after communication:  0.7826666666666666\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.8513602915725733\n",
      "mean test accuracy before communication:  0.7900833333333334\n",
      "mean test loss after communication:  0.911517560032782\n",
      "mean test accuracy after communication:  0.806527777777778\n"
     ]
    }
   ],
   "source": [
    "# 20 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(20)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 20, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.7462519562244416\n",
      "mean test accuracy before communication:  0.6965\n",
      "mean test loss after communication:  1.8439414560794831\n",
      "mean test accuracy after communication:  0.6918333333333332\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.0633930677175523\n",
      "mean test accuracy before communication:  0.7801666666666668\n",
      "mean test loss after communication:  1.1789896539971232\n",
      "mean test accuracy after communication:  0.731\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  0.7638495442969725\n",
      "mean test accuracy before communication:  0.7980000000000002\n",
      "mean test loss after communication:  0.798774417094537\n",
      "mean test accuracy after communication:  0.7501666666666668\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
