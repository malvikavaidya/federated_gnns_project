{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.utils import subgraph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 928])\n",
      "torch.Size([2, 292])\n",
      "torch.Size([2, 774])\n",
      "torch.Size([2, 330])\n",
      "torch.Size([2, 160])\n",
      "torch.Size([2, 376])\n",
      "torch.Size([2, 312])\n",
      "torch.Size([2, 570])\n",
      "torch.Size([2, 118])\n",
      "torch.Size([2, 776])\n",
      "torch.Size([2, 528])\n",
      "torch.Size([2, 194])\n",
      "torch.Size([2, 182])\n",
      "torch.Size([2, 166])\n",
      "torch.Size([2, 696])\n",
      "torch.Size([2, 1078])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 228])\n",
      "torch.Size([2, 616])\n",
      "torch.Size([2, 156])\n",
      "torch.Size([2, 120])\n",
      "torch.Size([2, 1462])\n",
      "torch.Size([2, 220])\n",
      "torch.Size([2, 790])\n",
      "torch.Size([2, 400])\n",
      "torch.Size([2, 246])\n",
      "torch.Size([2, 136])\n",
      "torch.Size([2, 148])\n",
      "torch.Size([2, 82])\n",
      "torch.Size([2, 144])\n",
      "torch.Size([2, 178])\n",
      "torch.Size([2, 890])\n",
      "torch.Size([2, 192])\n",
      "torch.Size([2, 132])\n",
      "torch.Size([2, 418])\n",
      "torch.Size([2, 414])\n",
      "torch.Size([2, 460])\n",
      "torch.Size([2, 350])\n",
      "torch.Size([2, 734])\n",
      "torch.Size([2, 862])\n",
      "torch.Size([2, 776])\n",
      "torch.Size([2, 296])\n",
      "torch.Size([2, 144])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 98])\n",
      "torch.Size([2, 190])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 316])\n",
      "torch.Size([2, 756])\n",
      "torch.Size([2, 134])\n",
      "torch.Size([2, 158])\n",
      "torch.Size([2, 374])\n",
      "torch.Size([2, 386])\n",
      "torch.Size([2, 98])\n",
      "torch.Size([2, 72])\n",
      "torch.Size([2, 570])\n",
      "torch.Size([2, 854])\n",
      "torch.Size([2, 144])\n",
      "torch.Size([2, 1230])\n",
      "torch.Size([2, 142])\n",
      "torch.Size([2, 136])\n",
      "torch.Size([2, 148])\n",
      "torch.Size([2, 92])\n",
      "torch.Size([2, 228])\n",
      "torch.Size([2, 856])\n",
      "torch.Size([2, 184])\n",
      "torch.Size([2, 92])\n",
      "torch.Size([2, 378])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2, 102])\n",
      "torch.Size([2, 774])\n",
      "torch.Size([2, 746])\n",
      "torch.Size([2, 756])\n",
      "torch.Size([2, 368])\n",
      "torch.Size([2, 238])\n",
      "torch.Size([2, 148])\n",
      "torch.Size([2, 138])\n",
      "torch.Size([2, 216])\n",
      "torch.Size([2, 730])\n",
      "torch.Size([2, 566])\n",
      "torch.Size([2, 544])\n",
      "torch.Size([2, 264])\n",
      "torch.Size([2, 1790])\n",
      "torch.Size([2, 124])\n",
      "torch.Size([2, 834])\n",
      "torch.Size([2, 200])\n",
      "torch.Size([2, 618])\n",
      "torch.Size([2, 242])\n",
      "torch.Size([2, 252])\n",
      "torch.Size([2, 164])\n",
      "torch.Size([2, 136])\n",
      "torch.Size([2, 304])\n",
      "torch.Size([2, 250])\n",
      "torch.Size([2, 746])\n",
      "torch.Size([2, 124])\n",
      "torch.Size([2, 222])\n",
      "torch.Size([2, 92])\n",
      "torch.Size([2, 340])\n",
      "torch.Size([2, 360])\n",
      "torch.Size([2, 164])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234567)\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "\n",
    "folder_path = 'second_order_client_neighbors'\n",
    "sub_data_list = []\n",
    "client_number = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.gml'):\n",
    "      \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        g = nx.read_gml(file_path)\n",
    "\n",
    "        subgraph_nodes = list(g.nodes)\n",
    "        subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "        sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "        print(sub_edge_index.shape)\n",
    "\n",
    "        sub_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "        sub_data_list.append(sub_data)\n",
    "        client_number.append(int(filename.split('.')[0].split('_')[1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = None\n",
    "\n",
    "g = nx.read_gml('second_order_test_graph.gml')\n",
    "subgraph_nodes = list(g.nodes)\n",
    "subgraph_nodes = [int(node) for node in subgraph_nodes]  # Convert to integer if they are not\n",
    "sub_edge_index, _ = subgraph(subgraph_nodes, data.edge_index, relabel_nodes=True)\n",
    "test_data = Data(x=data.x[subgraph_nodes], edge_index=sub_edge_index, y=data.y[subgraph_nodes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'828': ['713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '849', '718', '754', '760', '739', '856', '764', '687', '840', '847', '770', '797', '814', '727', '731', '708', '698', '817', '792', '845', '838', '848', '835', '807', '711', '779', '706', '772', '741', '709', '778', '737', '844', '693'], '713': ['828', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '842', '800', '819', '774', '726', '773', '766', '829', '780', '810', '696', '760', '787', '840', '847', '814', '731', '708', '698', '738', '817', '734', '845', '701', '848', '748', '706', '777', '772', '818', '778', '831', '833', '722', '844', '736', '794', '693'], '705': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '703', '784', '752', '728', '820', '842', '800', '819', '726', '773', '829', '780', '810', '849', '718', '754', '760', '739', '787', '764', '847', '770', '814', '731', '738', '845', '835', '807', '758', '803', '748', '755', '809', '720', '706', '772', '741', '778', '737', '831', '722', '844', '693', '763'], '719': ['828', '713', '705', '805', '824', '745', '747', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '800', '819', '774', '726', '773', '766', '829', '810', '696', '849', '718', '760', '787', '764', '840', '847', '814', '727', '731', '708', '698', '817', '734', '845', '848', '755', '720', '706', '772', '737', '722', '768', '794'], '805': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '703', '695', '815', '752', '728', '842', '800', '819', '774', '726', '766', '829', '780', '810', '696', '718', '754', '760', '739', '764', '687', '840', '847', '814', '727', '731', '738', '817', '792', '734', '838', '807', '706', '772', '709', '818', '737', '831', '844'], '824': ['828', '713', '705', '719', '805', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '728', '820', '842', '819', '774', '726', '773', '766', '829', '780', '696', '849', '754', '760', '739', '764', '840', '847', '770', '727', '708', '792', '838', '848', '835', '779', '777', '709', '737', '844', '693'], '745': ['828', '713', '705', '719', '805', '824', '747', '823', '694', '830', '781', '697', '724', '827', '853', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '829', '810', '696', '718', '760', '787', '847', '814', '731', '698', '738', '817', '845', '758', '711', '755', '720', '706', '795', '737', '722', '794'], '747': ['828', '713', '705', '719', '805', '745', '823', '830', '697', '688', '703', '815', '752', '728', '820', '800', '819', '774', '773', '780', '810', '696', '849', '718', '754', '739', '856', '764', '687', '840', '770', '797', '708', '698', '792', '838', '701', '848', '807', '793', '758', '803', '748', '783', '809', '741', '831', '730', '763', '765'], '823': ['828', '713', '705', '719', '805', '824', '745', '747', '694', '830', '781', '697', '724', '827', '688', '853', '834', '703', '815', '752', '728', '820', '800', '819', '774', '726', '773', '766', '780', '810', '696', '718', '754', '760', '739', '787', '856', '764', '687', '840', '708', '698', '792', '838', '848', '835', '807', '779', '741', '709', '693', '765'], '694': ['828', '713', '705', '719', '805', '824', '745', '823', '830', '781', '697', '724', '827', '688', '853', '834', '703', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '780', '810', '696', '754', '760', '847', '727', '731', '738', '845', '848', '711', '706', '795', '772', '737', '831', '722'], '830': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '697', '724', '827', '688', '853', '834', '695', '815', '752', '820', '800', '819', '774', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '847', '727', '731', '817', '792', '845', '838', '701', '748', '777', '709', '778', '737', '844'], '781': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '697', '724', '827', '853', '834', '703', '695', '784', '815', '752', '728', '842', '800', '726', '773', '829', '810', '849', '718', '760', '787', '764', '770', '814', '731', '708', '738', '817', '701', '793', '758', '755', '783', '809', '720', '772', '741', '794'], '697': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '834', '695', '815', '820', '842', '800', '819', '726', '766', '780', '696', '849', '754', '760', '856', '687', '840', '727', '731', '708', '698', '701', '848', '835', '748', '777', '772', '709', '818', '844', '693', '765'], '724': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '827', '688', '853', '834', '695', '784', '752', '820', '842', '819', '726', '773', '766', '829', '696', '754', '760', '814', '731', '708', '738', '734', '701', '848', '711', '795', '777', '778', '736', '794'], '827': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '853', '834', '703', '784', '752', '842', '800', '819', '773', '766', '810', '849', '718', '760', '787', '764', '797', '814', '731', '708', '817', '758', '755', '783', '809', '772', '741'], '688': ['828', '713', '719', '805', '824', '747', '823', '694', '830', '697', '724', '853', '834', '695', '815', '752', '800', '819', '774', '726', '766', '780', '696', '849', '754', '739', '856', '687', '840', '847', '770', '727', '792', '734', '845', '701', '777', '772', '771'], '853': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '724', '827', '688', '834', '695', '784', '815', '752', '820', '842', '800', '774', '726', '773', '766', '829', '810', '696', '847', '814', '727', '731', '738', '734', '711', '706', '795', '831', '722'], '834': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '688', '853', '695', '784', '815', '752', '820', '842', '800', '819', '726', '773', '766', '829', '780', '810', '696', '718', '760', '847', '814', '731', '701', '706', '778', '844', '693'], '703': ['828', '705', '719', '805', '824', '747', '823', '694', '781', '827', '815', '728', '820', '819', '718', '754', '739', '787', '856', '764', '687', '797', '698', '817', '792', '845', '838', '835', '807', '793', '758', '748', '779', '809', '741', '709', '831', '730', '765'], '695': ['713', '719', '805', '824', '745', '694', '830', '781', '697', '724', '688', '853', '834', '784', '815', '752', '842', '726', '766', '829', '780', '810', '696', '718', '754', '760', '840', '847', '738', '734', '701', '711', '706', '777', '778', '844', '794', '693'], '784': ['828', '713', '705', '719', '824', '745', '694', '781', '724', '827', '853', '834', '695', '752', '842', '800', '774', '726', '773', '766', '829', '810', '696', '760', '727', '731', '738', '734', '711', '706', '795', '722', '794'], '815': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '781', '697', '688', '853', '834', '703', '695', '752', '819', '726', '773', '766', '780', '810', '718', '754', '856', '847', '731', '792', '845', '838', '835', '706', '737'], '752': ['828', '713', '705', '719', '805', '824', '745', '747', '823', '694', '830', '781', '724', '827', '688', '853', '834', '695', '784', '815', '820', '842', '800', '774', '726', '773', '766', '829', '810', '847', '727', '731', '738', '711', '706', '831'], '728': ['828', '705', '719', '805', '824', '747', '823', '781', '703', '820', '819', '774', '773', '780', '754', '739', '787', '856', '764', '687', '797', '817', '792', '838', '835', '807', '803', '783', '779', '809', '741', '737', '730', '765'], '820': ['828', '705', '719', '824', '745', '747', '823', '694', '830', '697', '724', '853', '834', '703', '752', '728', '774', '726', '773', '766', '849', '760', '687', '770', '797', '845', '848', '803', '783', '795', '741', '737', '831', '722', '763'], '842': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '697', '724', '827', '853', '834', '695', '784', '752', '800', '773', '829', '810', '696', '760', '814', '727', '738', '734', '701', '711', '795', '794'], '800': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '830', '781', '697', '827', '688', '853', '834', '784', '752', '842', '774', '766', '810', '760', '856', '814', '727', '708', '698', '845', '772', '741'], '819': ['828', '713', '705', '719', '805', '824', '747', '823', '830', '697', '724', '827', '688', '834', '703', '815', '728', '774', '780', '739', '856', '687', '840', '708', '698', '817', '792', '838', '848', '835', '807', '709', '778'], '774': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '688', '853', '784', '752', '728', '820', '800', '819', '773', '810', '696', '739', '856', '687', '840', '731', '708', '698', '738', '701', '807', '720'], '726': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '688', '853', '834', '695', '784', '815', '752', '820', '773', '766', '780', '754', '760', '731', '845', '701', '778', '844', '693'], '773': ['828', '713', '705', '719', '824', '745', '747', '823', '694', '781', '724', '827', '853', '834', '784', '815', '752', '728', '820', '842', '774', '726', '829', '780', '810', '696', '754', '847', '731', '706', '737', '831'], '766': ['828', '713', '719', '805', '824', '823', '694', '830', '697', '724', '827', '688', '853', '834', '695', '784', '815', '752', '820', '800', '726', '780', '810', '849', '760', '847', '727', '731', '734', '711', '771'], '829': ['828', '713', '705', '719', '805', '824', '745', '694', '781', '724', '853', '834', '695', '784', '752', '842', '773', '696', '760', '847', '814', '738', '734', '711', '795', '777', '822', '722'], '780': ['828', '713', '705', '805', '824', '747', '823', '694', '830', '697', '688', '834', '695', '815', '728', '819', '726', '773', '766', '696', '754', '739', '687', '840', '792', '845', '838', '701', '835', '803', '779', '777', '765'], '810': ['828', '713', '705', '719', '805', '745', '747', '823', '694', '781', '827', '853', '834', '695', '784', '815', '752', '842', '800', '774', '773', '766', '856', '847', '814', '731', '698', '711', '706'], '696': ['828', '713', '719', '805', '824', '745', '747', '823', '694', '830', '697', '724', '688', '853', '834', '695', '784', '842', '774', '773', '829', '780', '739', '840', '727', '738', '845', '711', '795', '778'], '849': ['828', '705', '719', '824', '747', '830', '781', '697', '827', '688', '820', '766', '787', '770', '797', '727', '708', '734', '845', '793', '758', '748', '755', '783', '730', '763'], '718': ['828', '705', '719', '805', '745', '747', '823', '781', '827', '834', '703', '695', '815', '787', '764', '687', '770', '797', '814', '817', '793', '758', '803', '748', '809', '720', '730'], '754': ['828', '705', '805', '824', '747', '823', '694', '830', '697', '724', '688', '703', '695', '815', '728', '726', '773', '780', '739', '840', '792', '838', '701', '848', '835', '779', '777', '709'], '760': ['828', '713', '705', '719', '805', '824', '745', '823', '694', '830', '781', '697', '724', '827', '834', '695', '784', '820', '842', '800', '726', '766', '829', '814', '708', '738', '734', '701', '794'], '739': ['828', '705', '805', '824', '747', '823', '688', '703', '728', '819', '774', '780', '696', '754', '787', '764', '687', '840', '797', '792', '807', '793', '758', '720', '777', '709'], '787': ['713', '705', '719', '745', '823', '781', '827', '703', '728', '849', '718', '739', '764', '797', '814', '817', '793', '758', '803', '748', '755', '783', '809', '720', '730', '763'], '856': ['828', '747', '823', '830', '697', '688', '703', '815', '728', '800', '819', '774', '810', '687', '840', '708', '698', '838', '807', '772', '765'], '764': ['828', '705', '719', '805', '824', '747', '823', '781', '827', '703', '728', '718', '739', '787', '687', '797', '817', '838', '807', '793', '748', '783', '779', '809', '720', '730'], '687': ['828', '805', '747', '823', '830', '697', '688', '703', '728', '820', '819', '774', '780', '718', '739', '856', '764', '797', '817', '838', '807', '783', '779', '777', '730', '765'], '840': ['828', '713', '719', '805', '824', '747', '823', '830', '697', '688', '695', '819', '774', '780', '696', '754', '739', '856', '708', '698', '838', '848', '803', '779', '709'], '847': ['828', '713', '705', '719', '805', '824', '745', '694', '830', '688', '853', '834', '695', '815', '752', '773', '766', '829', '810', '727', '731', '734', '711', '706'], '770': ['828', '705', '824', '747', '781', '688', '820', '849', '718', '797', '727', '734', '845', '803', '748', '783', '777', '772', '741', '763'], '797': ['828', '747', '827', '703', '728', '820', '849', '718', '739', '787', '764', '687', '770', '708', '817', '793', '748', '755', '783', '809', '831', '730', '763'], '814': ['828', '713', '705', '719', '805', '745', '781', '724', '827', '853', '834', '842', '800', '829', '810', '718', '760', '787', '708', '758', '755', '772'], '727': ['828', '719', '805', '824', '694', '830', '697', '688', '853', '784', '752', '842', '800', '766', '696', '849', '847', '770', '845', '848', '711'], '731': ['828', '713', '705', '719', '805', '745', '694', '830', '781', '697', '724', '827', '853', '834', '784', '815', '752', '774', '726', '773', '766', '810', '847', '706'], '708': ['828', '713', '719', '824', '747', '823', '781', '697', '724', '827', '800', '819', '774', '849', '760', '856', '840', '797', '814', '755', '730'], '698': ['828', '713', '719', '745', '747', '823', '697', '703', '800', '819', '774', '810', '856', '840', '803', '772'], '738': ['713', '705', '805', '745', '694', '781', '724', '853', '695', '784', '752', '842', '774', '829', '696', '760', '711', '795', '722', '794'], '817': ['828', '713', '719', '805', '745', '830', '781', '827', '703', '728', '819', '718', '787', '764', '687', '797', '793', '758', '748', '783', '809'], '792': ['828', '805', '824', '747', '823', '830', '688', '703', '815', '728', '819', '780', '754', '739', '838', '835', '807', '803', '779', '765'], '734': ['713', '719', '805', '724', '688', '853', '695', '784', '842', '766', '829', '849', '760', '847', '770', '803', '778', '693'], '845': ['828', '713', '705', '719', '745', '694', '830', '688', '703', '815', '820', '800', '726', '780', '696', '849', '770', '727', '701', '755', '772'], '838': ['828', '805', '824', '747', '823', '830', '703', '815', '728', '819', '780', '754', '856', '764', '687', '840', '792', '835', '807', '779', '709'], '701': ['713', '747', '830', '781', '697', '724', '688', '834', '695', '842', '774', '726', '780', '754', '760', '845', '777', '778', '794'], '848': ['828', '713', '719', '824', '747', '823', '694', '697', '724', '820', '819', '754', '840', '727', '709', '844'], '835': ['828', '705', '824', '823', '697', '703', '815', '728', '819', '780', '754', '792', '838', '779', '741', '709', '765'], '807': ['828', '705', '805', '747', '823', '703', '728', '819', '774', '739', '856', '764', '687', '792', '838', '779', '741', '765'], '793': ['747', '781', '703', '849', '718', '739', '787', '764', '797', '817', '758', '748', '755', '783', '809', '720'], '758': ['705', '745', '747', '781', '827', '703', '849', '718', '739', '787', '814', '817', '793', '748', '755', '783', '809'], '711': ['828', '745', '694', '724', '853', '695', '784', '752', '842', '766', '829', '810', '696', '847', '727', '738', '795', '722'], '803': ['705', '747', '728', '820', '780', '718', '787', '840', '770', '698', '792', '734', '720', '730', '763'], '748': ['713', '705', '747', '830', '697', '703', '849', '718', '787', '764', '770', '797', '817', '793', '758', '779', '831'], '755': ['705', '719', '745', '781', '827', '849', '787', '797', '814', '708', '845', '793', '758', '783', '809', '720'], '783': ['747', '781', '827', '728', '820', '849', '787', '764', '687', '770', '797', '817', '793', '758', '755', '809', '730'], '779': ['828', '824', '823', '703', '728', '780', '754', '764', '687', '840', '792', '838', '835', '807', '748', '777', '765'], '809': ['705', '747', '781', '827', '703', '728', '718', '787', '764', '797', '817', '793', '758', '755', '783', '720'], '720': ['705', '719', '745', '781', '774', '718', '739', '787', '764', '793', '803', '755', '809', '730'], '706': ['828', '713', '705', '719', '805', '745', '694', '853', '834', '695', '784', '815', '752', '773', '810', '847', '731'], '795': ['745', '694', '724', '853', '784', '820', '842', '829', '696', '738', '711', '794'], '777': ['713', '824', '830', '697', '724', '688', '695', '829', '780', '754', '739', '687', '770', '701', '779', '709'], '772': ['828', '713', '705', '719', '805', '694', '781', '697', '827', '688', '800', '856', '770', '814', '698', '845'], '741': ['828', '705', '747', '823', '781', '827', '703', '728', '820', '800', '770', '835', '807', '763'], '709': ['828', '805', '824', '823', '830', '697', '703', '819', '754', '739', '840', '838', '848', '835', '777'], '818': ['713', '805', '697', '822', '806', '839', '771', '732', '736', '714'], '778': ['828', '713', '705', '830', '724', '834', '695', '819', '726', '696', '734', '701', '844', '693'], '737': ['828', '705', '719', '805', '824', '745', '694', '830', '815', '728', '820', '773', '722'], '831': ['713', '705', '805', '747', '694', '853', '703', '752', '820', '773', '797', '748'], '833': ['713', '806', '768', '736'], '822': ['829', '818', '806', '839', '768', '732', '714'], '806': ['818', '833', '822', '839', '771', '732', '714'], '730': ['747', '703', '728', '849', '718', '787', '764', '687', '797', '708', '803', '783', '720', '763'], '839': ['818', '822', '806', '771', '768', '732', '714'], '771': ['688', '766', '818', '806', '839', '732', '714'], '722': ['713', '705', '719', '745', '694', '853', '784', '820', '829', '738', '711', '737', '768'], '844': ['828', '713', '705', '805', '824', '830', '697', '834', '695', '726', '848', '778', '693'], '768': ['719', '833', '822', '839', '722'], '732': ['818', '822', '806', '839', '771', '714'], '736': ['713', '724', '818', '833'], '794': ['713', '719', '745', '781', '724', '695', '784', '842', '760', '738', '701', '795'], '693': ['828', '713', '705', '824', '823', '697', '834', '695', '726', '734', '778', '844'], '763': ['705', '747', '820', '849', '787', '770', '797', '803', '741', '730'], '765': ['747', '823', '697', '703', '728', '780', '856', '687', '792', '835', '807', '779'], '714': ['818', '822', '806', '839', '771', '732']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.read_gml('new_facebook_network.gml')\n",
    "neighbors = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors[node] = list(g.neighbors(node))\n",
    "\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new_facebook_network.gml and create a fully connected graph\n",
    "\n",
    "neighbors_fully_connected = {}\n",
    "\n",
    "for node in g.nodes:\n",
    "    neighbors_fully_connected[node] = list(g.nodes)\n",
    "    neighbors_fully_connected[node].remove(node)\n",
    "\n",
    "    \n",
    "# print(neighbors_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[233, 1433], edge_index=[2, 928], y=[233])\n",
      "torch.Size([233, 1433])\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(sub_data_list[0])\n",
    "print(sub_data_list[0].x.shape)\n",
    "print(type(client_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep a  list of training and validation loss per epoch for each subgraph\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def transductive_split(data, train_percent=0.8, val_percent=0.1):\n",
    "    \"\"\"\n",
    "    Split graph data into training, validation, and testing sets for transductive learning.\n",
    "    :param data: PyG Data object\n",
    "    :param train_percent: Percentage of nodes to be used for training\n",
    "    :param val_percent: Percentage of nodes to be used for validation\n",
    "    :return: data object with train_mask, val_mask, and test_mask attributes added\n",
    "    \"\"\"\n",
    "    # set a seed for reproducibility\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    train_size = int(train_percent * num_nodes)\n",
    "    val_size = int(val_percent * num_nodes)\n",
    "\n",
    "    # Create a random permutation of node indices\n",
    "    perm = torch.randperm(num_nodes)\n",
    "\n",
    "    # Create masks for training, validation, and testing nodes\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[perm[:train_size]] = True\n",
    "    val_mask[perm[train_size:train_size + val_size]] = True\n",
    "    test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "    # Add masks to data object\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the subgraphs into train test and val \n",
    "# for i in range(0, 100):\n",
    "#     sub_data = sub_data_list[i]\n",
    "#     sub_data = transductive_split(sub_data)\n",
    "\n",
    "\n",
    "# print(torch.sum(sub_data_list[4].train_mask).item())  # Number of training nodes\n",
    "# print(torch.sum(sub_data_list[4].val_mask).item())    # Number of validation nodes\n",
    "# print(torch.sum(sub_data_list[4].test_mask).item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training) # p = 0.25\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axs = plt.subplots(10, 10, figsize=(50, 50))\n",
    "\n",
    "def train(sub_data, model, optimizer, criterion):\n",
    "      model.train()\n",
    "      optimizer.zero_grad() \n",
    "      out = model(sub_data.x, sub_data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out, sub_data.y)  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      return loss\n",
    "\n",
    "def test(test_data, criterion, model):\n",
    "      model.eval()\n",
    "      out = model(test_data.x, test_data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred == test_data.y # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / len(test_data.y)  # Derive ratio of correct predictions.\n",
    "      test_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "      \n",
    "      return test_loss, test_acc\n",
    "\n",
    "\n",
    "def validate(test_data, model, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Do not compute gradients during this step\n",
    "        out = model(test_data.x, test_data.edge_index)  # Forward pass\n",
    "        pred = out.argmax(dim=1)  # Get predicted classes\n",
    "        val_correct = pred == test_data.y # Compare with ground-truth\n",
    "        val_loss = criterion(out, test_data.y)  # Compute validation loss\n",
    "        val_acc = int(val_correct.sum()) / int(len(test_data.y))  # Compute validation accuracy\n",
    "    return val_loss.item(), val_acc  # Return validation loss and accuracy\n",
    "\n",
    "\n",
    "def initial_training(epochs, learning_rate):\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    dictionary_t_1 = {}\n",
    "    dictionary_t = {}\n",
    "\n",
    "    for i in range(len(sub_data_list)):\n",
    "        sub_data = sub_data_list[i]\n",
    "        \n",
    "        model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        train_losses = [] \n",
    "        val_losses = []    \n",
    "\n",
    "        # Training loop for each epoch (adjust the range as needed)\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "            val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "        \n",
    "        test_loss, test_acc = test(test_data, criterion, model)\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accs.append(test_acc)\n",
    "        row = i // 10\n",
    "        col = i % 10\n",
    "\n",
    "        model_weights = model.state_dict()\n",
    "        client_number_num = client_number[i]\n",
    "        dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return dictionary_t_1, test_losses, test_accs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.7030368769168853\n",
      "mean test accuracy before communication:  0.15929712460063888\n"
     ]
    }
   ],
   "source": [
    "dictionary_t_1, test_losses, test_accs = initial_training(10, 0.01)\n",
    "\n",
    "# average test loss and accuracy before communication \n",
    "\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg(models):\n",
    "    global_model = copy.deepcopy(models[0]) # start with the first model\n",
    "    for k in global_model.keys():\n",
    "        global_model[k] = torch.stack([model[k].float() for model in models], 0).mean(0)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def communication(dictionary_t_1_og, neighbors, epochs, rounds, learning_rate):\n",
    "    # make a copy of dictionary_t_1\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    dictionary_t_1 = dictionary_t_1_og.copy()\n",
    "    dictionary_t = {}\n",
    "    for k in range(1, rounds + 1):\n",
    "\n",
    "    # get the neighbprs of each client\n",
    "        for i in range(len(sub_data_list)):\n",
    "            sub_data = sub_data_list[i]\n",
    "            \n",
    "            model = GCN(sub_data.num_node_features, dataset.num_classes).to(device)\n",
    "            model.load_state_dict(dictionary_t_1[client_number[i]])\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            train_losses = [] \n",
    "            val_losses = []    \n",
    "\n",
    "            # Training loop for each epoch (adjust the range as needed)\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                train_loss = train(sub_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "                val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "            \n",
    "            test_loss, test_acc = test(test_data, criterion, model)\n",
    "            if k == rounds:\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_accs.append(test_acc)\n",
    "\n",
    "        \n",
    "            # add the model weights to the t -1 dictionary\n",
    "            model_weights = model.state_dict()\n",
    "            client_number_num = client_number[i]\n",
    "            dictionary_t_1[client_number_num] = model_weights\n",
    "        \n",
    "\n",
    "        for i in range(100):\n",
    "            client_number_num = client_number[i]\n",
    "            # go through neighbors of client_number\n",
    "            string_client_num = str(client_number_num)\n",
    "            client_neighbors = neighbors[string_client_num]\n",
    "            \n",
    "            neighbors_state_dicts = []\n",
    "            neighbors_state_dicts.append(dictionary_t_1[client_number_num])\n",
    "            for j in range(len(client_neighbors)):\n",
    "                # get model weights of neighbor\n",
    "                neighbor_model = dictionary_t_1[int(client_neighbors[j])]\n",
    "                neighbors_state_dicts.append(neighbor_model)\n",
    "            \n",
    "            #call fed_avg\n",
    "            average_state_dict = {}\n",
    "            average_state_dict = fed_avg(neighbors_state_dicts)\n",
    "            # average weights of client and neighbors\n",
    "            # average_state_dict = {}\n",
    "            # for param in neighbors_state_dicts[0]:\n",
    "            #     # num parameters\n",
    "            #     num_neighbors = len(neighbors_state_dicts)\n",
    "            #     sum_param = 0\n",
    "            #     for neighbor in range(num_neighbors):\n",
    "            #         sum_param += neighbors_state_dicts[neighbor][param]\n",
    "            #     average_param = sum_param / num_neighbors\n",
    "            #     average_state_dict[param] = average_param\n",
    "                \n",
    "                \n",
    "            dictionary_t[client_number_num] = average_state_dict    \n",
    "            \n",
    "        dictionary_t_1 = dictionary_t\n",
    "\n",
    "    return test_losses, test_accs\n",
    " \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss after communication:  3.2485601675510405\n",
      "mean test accuracy after communication:  0.17137380191693283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10, 0.01)\n",
    "\n",
    "# average test loss and accuracy after communication\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "\n",
    "#mean of test_accs\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print a distriution of the accuracies of test_losses and test_accs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_accs)\n",
    "plt.title(\"Test accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.950941253900528\n",
      "mean test accuracy before communication:  0.15015974440894567\n",
      "mean test loss after communication:  2.0524680721759796\n",
      "mean test accuracy after communication:  0.1924281150159743\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.114197174310684\n",
      "mean test accuracy before communication:  0.15220447284345034\n",
      "mean test loss after communication:  2.6148978340625764\n",
      "mean test accuracy after communication:  0.25000000000000006\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.7938966619968415\n",
      "mean test accuracy before communication:  0.15690095846645355\n",
      "mean test loss after communication:  2.931734937429428\n",
      "mean test accuracy after communication:  0.29412140575079876\n"
     ]
    }
   ],
   "source": [
    "# 01 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors_fully_connected, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epoch, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.9492018187046052\n",
      "mean test accuracy before communication:  0.15316293929712457\n",
      "mean test loss after communication:  1.930002419948578\n",
      "mean test accuracy after communication:  0.19610223642172536\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.162765134572983\n",
      "mean test accuracy before communication:  0.15233226837060687\n",
      "mean test loss after communication:  2.285061997175217\n",
      "mean test accuracy after communication:  0.3179872204472844\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.7871898126602175\n",
      "mean test accuracy before communication:  0.1592651757188497\n",
      "mean test loss after communication:  2.938849595785141\n",
      "mean test accuracy after communication:  0.31345047923322694\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  3.4152511596679687\n",
      "mean test accuracy before communication:  0.1779233226837061\n",
      "mean test loss after communication:  3.4955796611309053\n",
      "mean test accuracy after communication:  0.2935463258785943\n"
     ]
    }
   ],
   "source": [
    "# 20 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(20)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 20, 100)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  1.9489406883716582\n",
      "mean test accuracy before communication:  0.1485623003194888\n",
      "mean test loss after communication:  1.9430880868434905\n",
      "mean test accuracy after communication:  0.1542811501597442\n"
     ]
    }
   ],
   "source": [
    "# 1 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(1)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.146751263141632\n",
      "mean test accuracy before communication:  0.1514057507987219\n",
      "mean test loss after communication:  2.396341060400009\n",
      "mean test accuracy after communication:  0.15214057507987205\n"
     ]
    }
   ],
   "source": [
    "# 5 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(5)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 epochs, 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test loss before communication:  2.69692032456398\n",
      "mean test accuracy before communication:  0.1590095846645366\n",
      "mean test loss after communication:  3.162060570716858\n",
      "mean test accuracy after communication:  0.17827476038338652\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "\n",
    "dictionary_t_1, test_losses, test_accs = initial_training(10)\n",
    "# print average test loss and average test accs\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss before communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy before communication: \", mean_test_accs)\n",
    "\n",
    "test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 10)\n",
    "mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "print(\"mean test loss after communication: \", mean_test_losses)\n",
    "print(\"mean test accuracy after communication: \", mean_test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Graph Results\n",
    "### (Training with original subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.07%                     | 14.29%                    | 1.947                  | 2.083                 |\n",
    "| 5      | 100                  | 14.89%                     | 15.49%                    | 2.021                  | 2.943                 |\n",
    "| 10     | 100                  | 14.73%                     | 14.90%                    | 2.387                  | 5.010                 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Graph Results\n",
    "### (Training with original subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.13%                     | 14.31%                    | 1.947                  | 1.996                 |\n",
    "| 1      | 10                   | 15.40%                     | 15.12%                    | 1.946                  | 1.945                 |\n",
    "| 5      | 100                  | 14.38%                     | 16.16%                    | 2.028                  | 2.730                 |\n",
    "| 5      | 10                   | 14.52%                     | 14.49%                    | 2.014                  | 2.282                 |\n",
    "| 10     | 100                  | 14.74%                     | 16.07%                    | 2.321                  | 4.402                 |\n",
    "| 10     | 10                   | 14.69%                     | 15.01%                    | 2.349                  | 3.084                 |\n",
    "| 20     | 100                  | 15.39%                     | 18.50%                    | 3.101                  | 4.654                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Graph Results\n",
    "### (Training with second order subgraphs)\n",
    "\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "| ------ | -------------------- | -------------------------- | ------------------------- | ---------------------- | --------------------- |\n",
    "| 1      | 100                  | 15.02%                     | 19.24%                    | 1.951                  | 2.052                 |\n",
    "| 5      | 100                  | 15.22%                     | 31.80%                    | 2.114                 | 2.614                |\n",
    "| 10     | 100                  | 15.69%                     | 29.41%                    | 2.794                 | 2.932              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Graphs Results\n",
    "### (Training with second order subgraphs)\n",
    "\n",
    "| Epochs | Communication Rounds | Avg Test Accuracy (Before) | Avg Test Accuracy (After) | Avg Test Loss (Before) | Avg Test Loss (After) |\n",
    "|--------|----------------------|----------------------------|---------------------------|-----------------------|-----------------------|\n",
    "| 1      | 100                  | 0.1532                     | 0.1961                    | 1.9492                | 1.9300                |\n",
    "| 5      | 100                  | 0.1523                     | 0.3180                    | 2.1628                | 2.2851                |\n",
    "| 10     | 100                  | 0.1593                     | 0.3135                    | 2.7872                | 2.9388                |\n",
    "| 20     | 100                  | 0.1779                     | 0.2935                    | 3.4153                | 3.4956                |\n",
    "| 1      | 10                   | 0.1486                     | 0.1543                    | 1.9489                | 1.9431                |\n",
    "| 5      | 10                   | 0.1514                     | 0.1521                    | 2.1468                | 2.3963                |\n",
    "| 10     | 10                   | 0.1590                     | 0.1783                    | 2.6969                | 3.1621                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized Training on Entire Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Dataset class\n",
    "\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, graph_data):\n",
    "        self.graph_data = graph_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graph_data.x[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.graph_data.x[idx,:]\n",
    "        y = self.graph_data.y[idx]\n",
    "        edge_index = self.graph_data.edge_index\n",
    "        # connected_edges = (self.graph_data.edge_index[0] == idx) | (self.graph_data.edge_index[1] == idx)\n",
    "        # edge_index = self.graph_data.edge_index[:, connected_edges]\n",
    "        return x, edge_index, y, idx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized learning test accuracy:  0.5846645367412141\n"
     ]
    }
   ],
   "source": [
    "# get cora_graph_training \n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "cora_graph_training = nx.read_gml('cora_graph_training.gml')\n",
    "test_graph = test_data\n",
    "\n",
    "\n",
    "graph_nodes = list(cora_graph_training.nodes)\n",
    "graph_nodes = [int(node) for node in graph_nodes]  # Convert to integer if they are not\n",
    "\n",
    "graph_edge_index, _ = subgraph(graph_nodes, data.edge_index, relabel_nodes=True)\n",
    "graph_data = Data(x=data.x[graph_nodes], edge_index=graph_edge_index, y=data.y[graph_nodes])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "\n",
    "def train_test(graph_data, epochs, dataset, test_data, device):\n",
    "    model = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    epochs = 10\n",
    "    # Training loop for each epoch (adjust the range as needed)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(graph_data, model, optimizer, criterion)  # Assuming 'train' returns a loss\n",
    "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy) \n",
    "\n",
    "    test_loss, test_acc = test(test_data, criterion, model)\n",
    "    \n",
    "    # print(\"Centralized learning test loss: \", test_loss)\n",
    "    print(\"Centralized learning test accuracy: \", test_acc)\n",
    "\n",
    "train_test(graph_data, 10, dataset, test_data, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized Learning with Different Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size:  10\n",
      "Centralized learning test accuracy:  0.6166134185303515\n",
      "Batch size:  16\n",
      "Centralized learning test accuracy:  0.610223642172524\n",
      "Batch size:  32\n",
      "Centralized learning test accuracy:  0.597444089456869\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "def train_test_batches(graph_data, epochs, dataset, test_data, device, batch_size):\n",
    "    model = GCN(graph_data.num_node_features, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    epochs = 10\n",
    "    # Training loop for each epoch (adjust the range as needed)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_batches(graph_data, model, optimizer, criterion, batch_size)  # Assuming 'train' returns a loss\n",
    "        val_loss, _ = validate(test_data, model, criterion)         # Assuming 'validate' returns a loss and something else (like accuracy) \n",
    "\n",
    "    test_loss, test_acc = test(test_data, criterion, model)\n",
    "    \n",
    "    # print(\"Centralized learning test loss: \", test_loss)\n",
    "    print(\"Batch size: \", batch_size)\n",
    "    print(\"Centralized learning test accuracy: \", test_acc)\n",
    "\n",
    "def train_batches(graph_data, model, optimizer, criterion, batch_size):\n",
    "    # graph_dataset = [graph_data.x, graph_data.edge_index, graph_data.y]\n",
    "    # print(graph_data.edge_index.shape)\n",
    "    graph_dataset = GraphDataset(graph_data)\n",
    "    graph_data_loader = DataLoader(graph_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # print(len(graph_data_loader.dataset))\n",
    "    \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(graph_data_loader):\n",
    "      x, edge_index, y, idx = data\n",
    "    #   print(idx)\n",
    "      nodes = list(idx)\n",
    "      sub_edge_index, _ = subgraph(nodes, edge_index[0], relabel_nodes=True)\n",
    "    #   print(sub_edge_index.shape)\n",
    "      optimizer.zero_grad() \n",
    "      out = model(x, sub_edge_index) \n",
    "      loss = criterion(out, y)  \n",
    "      loss.backward() \n",
    "      optimizer.step() \n",
    "      total_loss += loss.item()\n",
    "      \n",
    "    return total_loss/(i+1)\n",
    "\n",
    "print()\n",
    "batch_sizes = [10, 16, 32]\n",
    "for batch_size in batch_sizes:\n",
    "    train_test_batches(graph_data, 10, dataset, test_data, device, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Social Network\n",
    "\n",
    "### Adam Optimizer, changing learning rates\n",
    "### 1 epoch, 100 communication rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.1\n",
      "mean test accuracy after communication:  0.14613418530351427\n",
      "mean test loss after communication:  4.274308376312256\n",
      "\n",
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.1946964856230031\n",
      "mean test loss after communication:  1.9461461317539215\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.1764536741214057\n",
      "mean test loss after communication:  1.944579039812088\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.16022364217252363\n",
      "mean test loss after communication:  1.9454831516742705\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.11699680511182108\n",
      "mean test loss after communication:  1.9458110272884368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(1, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 1, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.2996166134185303\n",
      "mean test loss after communication:  2.341976307630539\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.21172523961661324\n",
      "mean test loss after communication:  1.9647659862041473\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.24108626198083066\n",
      "mean test loss after communication:  1.9449313080310822\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.22539936102236421\n",
      "mean test loss after communication:  1.94551837682724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(5, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 5, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses) # print(f\"{mean_test_losses:.4f},{}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 epochs, 100 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:  0.01\n",
      "mean test accuracy after communication:  0.30837060702875396\n",
      "mean test loss after communication:  2.900534151792526\n",
      "\n",
      "learning rate:  0.001\n",
      "mean test accuracy after communication:  0.23664536741214054\n",
      "mean test loss after communication:  1.9392705142498017\n",
      "\n",
      "learning rate:  0.0001\n",
      "mean test accuracy after communication:  0.20805111821086253\n",
      "mean test loss after communication:  1.9413844859600067\n",
      "\n",
      "learning rate:  1e-05\n",
      "mean test accuracy after communication:  0.20466453674121404\n",
      "mean test loss after communication:  1.945243377685547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    dictionary_t_1, test_losses, test_accs = initial_training(10, learning_rate)\n",
    "\n",
    "    test_losses, test_accs = communication(dictionary_t_1, neighbors, 10, 100, learning_rate)\n",
    "    mean_test_losses = sum(test_losses)/len(test_losses)\n",
    "    mean_test_accs = sum(test_accs)/len(test_accs)\n",
    "    print(\"learning rate: \", learning_rate)\n",
    "    print(\"mean test accuracy after communication: \", mean_test_accs)\n",
    "    print(\"mean test loss after communication: \", mean_test_losses)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Adam Optimizer, lr = , and varying batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
